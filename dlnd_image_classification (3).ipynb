{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 5:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1014, 1: 1014, 2: 952, 3: 1016, 4: 997, 5: 1025, 6: 980, 7: 977, 8: 1003, 9: 1022}\n",
      "First 20 Labels: [1, 8, 5, 1, 5, 7, 4, 3, 8, 2, 7, 2, 0, 1, 5, 9, 6, 2, 0, 8]\n",
      "\n",
      "Example of Image 7:\n",
      "Image - Min Value: 20 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 3 Name: cat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwCNCXoAaEzQA0Bjgh4AGhP0ANDY/wVHLp+Km5w66AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x272868c4160>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 5\n",
    "sample_id = 7\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.63921569  0.54509804  0.88627451]\n",
      "   [ 0.70980392  0.42745098  0.89411765]\n",
      "   [ 0.19607843  0.23921569  0.33333333]\n",
      "   ..., \n",
      "   [ 0.82352941  0.5372549   0.83529412]\n",
      "   [ 0.32156863  0.49411765  0.4       ]\n",
      "   [ 0.18039216  0.75294118  0.29803922]]\n",
      "\n",
      "  [[ 0.8745098   0.03921569  0.52941176]\n",
      "   [ 0.87058824  0.77647059  0.48627451]\n",
      "   [ 0.82745098  0.94117647  0.7254902 ]\n",
      "   ..., \n",
      "   [ 0.75294118  0.0627451   0.82745098]\n",
      "   [ 0.43529412  0.98039216  0.0627451 ]\n",
      "   [ 0.41176471  0.45882353  0.97647059]]\n",
      "\n",
      "  [[ 0.96470588  0.6627451   0.03529412]\n",
      "   [ 0.6         0.39215686  0.8627451 ]\n",
      "   [ 0.65490196  0.32941176  0.31372549]\n",
      "   ..., \n",
      "   [ 0.83921569  0.32941176  0.67843137]\n",
      "   [ 0.59215686  0.03137255  0.57254902]\n",
      "   [ 0.33333333  0.41960784  0.81960784]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.70588235  0.3372549   0.63921569]\n",
      "   [ 0.95294118  0.32156863  0.6627451 ]\n",
      "   [ 0.59215686  0.2627451   0.2745098 ]\n",
      "   ..., \n",
      "   [ 0.18039216  0.63921569  0.47058824]\n",
      "   [ 0.68235294  0.16078431  0.62745098]\n",
      "   [ 0.04313725  0.90588235  0.19215686]]\n",
      "\n",
      "  [[ 0.47843137  0.67058824  0.34117647]\n",
      "   [ 0.4627451   0.06666667  0.81568627]\n",
      "   [ 0.89803922  0.95294118  0.65098039]\n",
      "   ..., \n",
      "   [ 0.98823529  0.62745098  0.6627451 ]\n",
      "   [ 0.32941176  0.29803922  0.09803922]\n",
      "   [ 0.44313725  0.81960784  0.45882353]]\n",
      "\n",
      "  [[ 0.11764706  0.41176471  0.75686275]\n",
      "   [ 0.94509804  0.62352941  0.73333333]\n",
      "   [ 0.31764706  0.50196078  0.91372549]\n",
      "   ..., \n",
      "   [ 0.23137255  0.12156863  0.31372549]\n",
      "   [ 0.78431373  0.01960784  0.92156863]\n",
      "   [ 0.37254902  0.14509804  0.56470588]]]\n",
      "\n",
      "\n",
      " [[[ 0.21568627  0.90980392  0.88627451]\n",
      "   [ 0.12156863  0.06666667  0.22745098]\n",
      "   [ 0.36078431  0.19215686  0.7254902 ]\n",
      "   ..., \n",
      "   [ 0.39607843  0.67843137  0.2627451 ]\n",
      "   [ 0.25882353  0.68235294  0.01960784]\n",
      "   [ 0.99607843  0.16078431  0.80392157]]\n",
      "\n",
      "  [[ 0.41568627  0.09411765  0.06666667]\n",
      "   [ 0.2627451   0.18039216  0.39215686]\n",
      "   [ 0.89411765  0.16078431  0.45882353]\n",
      "   ..., \n",
      "   [ 0.01960784  0.24313725  0.68235294]\n",
      "   [ 0.58039216  0.42745098  0.61568627]\n",
      "   [ 0.14901961  0.52941176  0.01568627]]\n",
      "\n",
      "  [[ 0.47843137  1.          0.34509804]\n",
      "   [ 0.34901961  0.30588235  0.63137255]\n",
      "   [ 0.45882353  0.63529412  0.77647059]\n",
      "   ..., \n",
      "   [ 0.49019608  0.21960784  0.        ]\n",
      "   [ 0.72941176  0.57254902  0.11764706]\n",
      "   [ 0.71372549  0.70196078  0.21960784]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.48627451  0.14901961  0.50980392]\n",
      "   [ 0.01568627  0.80784314  0.45098039]\n",
      "   [ 0.05490196  0.34117647  0.83137255]\n",
      "   ..., \n",
      "   [ 0.20392157  0.9372549   0.43137255]\n",
      "   [ 0.44313725  0.53333333  0.08627451]\n",
      "   [ 0.65882353  0.34509804  0.42745098]]\n",
      "\n",
      "  [[ 0.82745098  0.45098039  0.60392157]\n",
      "   [ 0.44313725  0.63921569  0.14117647]\n",
      "   [ 0.75294118  0.50196078  0.50980392]\n",
      "   ..., \n",
      "   [ 0.38823529  0.38823529  0.59607843]\n",
      "   [ 0.94117647  0.60392157  0.92156863]\n",
      "   [ 0.2         0.00392157  0.47843137]]\n",
      "\n",
      "  [[ 0.16078431  0.83529412  0.94117647]\n",
      "   [ 0.75294118  0.86666667  0.67058824]\n",
      "   [ 0.29019608  0.19607843  0.63921569]\n",
      "   ..., \n",
      "   [ 0.43137255  0.30196078  0.71764706]\n",
      "   [ 0.01568627  0.62352941  0.64705882]\n",
      "   [ 0.6745098   0.93333333  0.03921569]]]\n",
      "\n",
      "\n",
      " [[[ 0.72156863  0.55294118  0.65098039]\n",
      "   [ 0.20784314  0.26666667  0.62745098]\n",
      "   [ 0.66666667  0.42352941  0.60784314]\n",
      "   ..., \n",
      "   [ 0.96078431  0.27058824  0.51764706]\n",
      "   [ 0.02352941  0.05098039  0.63137255]\n",
      "   [ 0.88627451  0.80784314  0.61568627]]\n",
      "\n",
      "  [[ 0.40784314  0.02352941  0.85882353]\n",
      "   [ 0.24705882  0.13333333  0.23921569]\n",
      "   [ 0.29019608  0.42745098  0.90980392]\n",
      "   ..., \n",
      "   [ 0.85098039  0.49019608  0.59607843]\n",
      "   [ 0.52156863  0.32156863  0.64705882]\n",
      "   [ 0.30196078  0.89019608  0.23529412]]\n",
      "\n",
      "  [[ 0.29411765  0.39215686  0.99215686]\n",
      "   [ 0.64313725  0.57647059  0.61568627]\n",
      "   [ 0.34509804  0.10196078  0.78431373]\n",
      "   ..., \n",
      "   [ 0.35686275  0.16862745  0.20784314]\n",
      "   [ 0.58039216  0.1254902   0.75294118]\n",
      "   [ 0.70980392  0.69803922  0.2627451 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.66666667  0.09803922  0.11372549]\n",
      "   [ 0.95294118  0.30196078  0.92941176]\n",
      "   [ 0.14509804  0.87058824  0.34901961]\n",
      "   ..., \n",
      "   [ 0.09019608  0.28235294  0.1254902 ]\n",
      "   [ 0.18039216  0.42745098  0.58431373]\n",
      "   [ 0.41176471  0.11372549  0.58039216]]\n",
      "\n",
      "  [[ 0.60392157  0.94117647  0.50980392]\n",
      "   [ 0.43529412  0.39607843  0.98823529]\n",
      "   [ 0.83137255  0.01568627  0.25098039]\n",
      "   ..., \n",
      "   [ 0.34509804  0.62352941  0.94117647]\n",
      "   [ 0.01568627  0.66666667  0.03921569]\n",
      "   [ 0.2627451   0.21568627  0.10588235]]\n",
      "\n",
      "  [[ 0.00784314  0.31764706  0.91764706]\n",
      "   [ 0.36862745  0.90588235  0.23921569]\n",
      "   [ 0.48235294  0.69411765  0.54509804]\n",
      "   ..., \n",
      "   [ 0.12941176  0.4627451   0.87843137]\n",
      "   [ 0.42745098  0.08235294  0.83529412]\n",
      "   [ 0.34509804  0.87058824  0.75294118]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.51372549  0.10588235  0.34901961]\n",
      "   [ 0.86666667  0.2745098   0.17647059]\n",
      "   [ 0.76078431  0.71764706  0.00392157]\n",
      "   ..., \n",
      "   [ 0.95294118  0.69411765  0.65098039]\n",
      "   [ 0.45882353  0.0627451   0.50980392]\n",
      "   [ 0.02352941  0.42745098  0.8745098 ]]\n",
      "\n",
      "  [[ 0.21176471  0.30196078  0.25490196]\n",
      "   [ 0.98823529  0.61568627  0.46666667]\n",
      "   [ 0.38431373  0.09019608  0.9254902 ]\n",
      "   ..., \n",
      "   [ 0.80784314  0.51372549  0.34117647]\n",
      "   [ 0.74901961  0.5254902   0.8745098 ]\n",
      "   [ 0.3254902   0.20392157  0.63921569]]\n",
      "\n",
      "  [[ 0.54117647  0.05098039  0.70588235]\n",
      "   [ 0.27058824  0.6627451   0.49411765]\n",
      "   [ 0.3372549   0.11372549  0.26666667]\n",
      "   ..., \n",
      "   [ 0.24313725  0.31372549  0.72941176]\n",
      "   [ 0.13333333  0.85098039  0.10196078]\n",
      "   [ 0.21568627  0.93333333  0.63137255]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.01568627  0.21960784  0.11764706]\n",
      "   [ 0.54117647  0.43529412  0.55294118]\n",
      "   [ 0.98039216  0.48627451  0.80392157]\n",
      "   ..., \n",
      "   [ 0.86666667  0.14509804  0.8745098 ]\n",
      "   [ 0.4         0.49803922  0.84313725]\n",
      "   [ 0.93333333  0.4745098   0.72156863]]\n",
      "\n",
      "  [[ 0.37647059  0.39607843  0.99607843]\n",
      "   [ 0.65098039  0.59607843  0.49411765]\n",
      "   [ 0.88235294  0.04313725  0.08627451]\n",
      "   ..., \n",
      "   [ 0.97647059  0.76078431  0.54117647]\n",
      "   [ 0.27843137  0.6         0.3254902 ]\n",
      "   [ 0.5254902   0.98431373  0.98823529]]\n",
      "\n",
      "  [[ 0.75686275  0.86666667  0.16470588]\n",
      "   [ 0.19607843  0.98431373  0.8745098 ]\n",
      "   [ 0.75686275  0.89411765  0.27843137]\n",
      "   ..., \n",
      "   [ 0.31372549  0.54509804  0.83921569]\n",
      "   [ 0.84313725  0.51372549  0.65098039]\n",
      "   [ 0.75686275  0.52941176  0.94509804]]]\n",
      "\n",
      "\n",
      " [[[ 0.21960784  0.18823529  0.00784314]\n",
      "   [ 0.58823529  0.45098039  0.08235294]\n",
      "   [ 0.54901961  0.85490196  0.50980392]\n",
      "   ..., \n",
      "   [ 0.76470588  0.38823529  0.63921569]\n",
      "   [ 0.00784314  0.38823529  0.11764706]\n",
      "   [ 0.49019608  0.74901961  0.97647059]]\n",
      "\n",
      "  [[ 0.15294118  0.03137255  0.89803922]\n",
      "   [ 0.61176471  0.98039216  0.10196078]\n",
      "   [ 0.27058824  0.70196078  0.88235294]\n",
      "   ..., \n",
      "   [ 0.82352941  0.70588235  0.4       ]\n",
      "   [ 0.97647059  0.94509804  0.91372549]\n",
      "   [ 0.03137255  0.87058824  0.03137255]]\n",
      "\n",
      "  [[ 0.87843137  0.14117647  0.81568627]\n",
      "   [ 0.95686275  0.89411765  0.81568627]\n",
      "   [ 0.94901961  0.50588235  0.14901961]\n",
      "   ..., \n",
      "   [ 0.65098039  0.3254902   0.90588235]\n",
      "   [ 0.54901961  0.55294118  0.7254902 ]\n",
      "   [ 0.36862745  0.90588235  0.99607843]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.08627451  0.6745098   0.49019608]\n",
      "   [ 0.43529412  0.17647059  0.08235294]\n",
      "   [ 0.64705882  0.72941176  0.0627451 ]\n",
      "   ..., \n",
      "   [ 0.61176471  0.35686275  0.90588235]\n",
      "   [ 0.09803922  0.45882353  0.01960784]\n",
      "   [ 0.29019608  0.74509804  0.65882353]]\n",
      "\n",
      "  [[ 0.98823529  0.32941176  0.93333333]\n",
      "   [ 0.62352941  0.53333333  0.28627451]\n",
      "   [ 0.97254902  0.35686275  0.92941176]\n",
      "   ..., \n",
      "   [ 0.71764706  0.0627451   0.87058824]\n",
      "   [ 0.51764706  0.78039216  0.67058824]\n",
      "   [ 0.6745098   0.87058824  0.49019608]]\n",
      "\n",
      "  [[ 0.59215686  0.67058824  0.15686275]\n",
      "   [ 0.85882353  0.62745098  0.68627451]\n",
      "   [ 0.25490196  0.03137255  0.81176471]\n",
      "   ..., \n",
      "   [ 0.7372549   0.91372549  0.50588235]\n",
      "   [ 0.02352941  0.04313725  0.50980392]\n",
      "   [ 0.32941176  0.54901961  0.80392157]]]\n",
      "\n",
      "\n",
      " [[[ 0.05098039  0.87058824  0.14901961]\n",
      "   [ 0.21176471  0.38823529  0.98039216]\n",
      "   [ 0.61176471  0.77254902  0.25098039]\n",
      "   ..., \n",
      "   [ 0.45882353  0.54509804  0.32941176]\n",
      "   [ 0.23529412  0.25098039  0.55686275]\n",
      "   [ 0.1254902   0.7254902   0.54117647]]\n",
      "\n",
      "  [[ 0.37647059  0.78039216  0.60784314]\n",
      "   [ 0.49411765  0.69411765  0.89803922]\n",
      "   [ 0.87058824  0.79215686  0.92941176]\n",
      "   ..., \n",
      "   [ 0.58823529  0.12941176  0.50196078]\n",
      "   [ 0.75686275  0.99607843  0.41176471]\n",
      "   [ 0.75294118  0.12941176  0.58039216]]\n",
      "\n",
      "  [[ 0.90196078  0.17647059  0.37647059]\n",
      "   [ 0.05490196  0.69803922  0.27058824]\n",
      "   [ 0.56862745  0.21568627  0.51764706]\n",
      "   ..., \n",
      "   [ 0.54509804  0.47058824  0.3372549 ]\n",
      "   [ 0.78431373  0.30980392  0.63921569]\n",
      "   [ 0.37254902  0.55294118  0.98039216]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.67058824  0.49019608  0.67058824]\n",
      "   [ 0.8745098   0.88627451  0.5254902 ]\n",
      "   [ 0.56470588  0.45882353  0.90980392]\n",
      "   ..., \n",
      "   [ 0.3372549   0.2627451   0.00392157]\n",
      "   [ 0.51764706  0.83529412  0.13333333]\n",
      "   [ 0.10196078  0.04313725  0.40784314]]\n",
      "\n",
      "  [[ 0.          0.58039216  0.90588235]\n",
      "   [ 0.70980392  0.09019608  0.02352941]\n",
      "   [ 0.48627451  0.94901961  0.34901961]\n",
      "   ..., \n",
      "   [ 0.45882353  0.29411765  0.45490196]\n",
      "   [ 0.6         0.44313725  0.98823529]\n",
      "   [ 0.09019608  0.32156863  0.83921569]]\n",
      "\n",
      "  [[ 0.20392157  0.49411765  0.97254902]\n",
      "   [ 0.57254902  0.50588235  0.82745098]\n",
      "   [ 0.80392157  0.58039216  0.65098039]\n",
      "   ..., \n",
      "   [ 0.98039216  0.1372549   0.02745098]\n",
      "   [ 0.73333333  0.72941176  0.02745098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [ 0.78039216  0.84313725  0.62745098]]]]\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function \n",
    "    normal=np.ndarray(x.shape,dtype=float)\n",
    "    normal[:] = x\n",
    "    for a in np.nditer(normal, op_flags=['readwrite']):\n",
    "        a[...] = a/255.0\n",
    "    print(normal)\n",
    "    ##########################################################\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)\n",
    "    return (x - x_min) / (x_max - x_min)\n",
    "    \n",
    "    \n",
    "    # return normal\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  1.  0.  0.]]\n",
      "[[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    one_hot = np.zeros(shape=(len(x), 10))\n",
    "    for i in range(len(x)):\n",
    "        for j in range(10):\n",
    "            one_hot[i][j] = (j == x[i])\n",
    "\n",
    "    print(one_hot)        \n",
    "    return one_hot\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.16862745  0.18039216  0.17647059]\n",
      "   [ 0.19607843  0.18823529  0.16862745]\n",
      "   ..., \n",
      "   [ 0.61960784  0.51764706  0.42352941]\n",
      "   [ 0.59607843  0.49019608  0.4       ]\n",
      "   [ 0.58039216  0.48627451  0.40392157]]\n",
      "\n",
      "  [[ 0.0627451   0.07843137  0.07843137]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.07058824  0.03137255  0.        ]\n",
      "   ..., \n",
      "   [ 0.48235294  0.34509804  0.21568627]\n",
      "   [ 0.46666667  0.3254902   0.19607843]\n",
      "   [ 0.47843137  0.34117647  0.22352941]]\n",
      "\n",
      "  [[ 0.09803922  0.09411765  0.08235294]\n",
      "   [ 0.0627451   0.02745098  0.        ]\n",
      "   [ 0.19215686  0.10588235  0.03137255]\n",
      "   ..., \n",
      "   [ 0.4627451   0.32941176  0.19607843]\n",
      "   [ 0.47058824  0.32941176  0.19607843]\n",
      "   [ 0.42745098  0.28627451  0.16470588]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.81568627  0.66666667  0.37647059]\n",
      "   [ 0.78823529  0.6         0.13333333]\n",
      "   [ 0.77647059  0.63137255  0.10196078]\n",
      "   ..., \n",
      "   [ 0.62745098  0.52156863  0.2745098 ]\n",
      "   [ 0.21960784  0.12156863  0.02745098]\n",
      "   [ 0.20784314  0.13333333  0.07843137]]\n",
      "\n",
      "  [[ 0.70588235  0.54509804  0.37647059]\n",
      "   [ 0.67843137  0.48235294  0.16470588]\n",
      "   [ 0.72941176  0.56470588  0.11764706]\n",
      "   ..., \n",
      "   [ 0.72156863  0.58039216  0.36862745]\n",
      "   [ 0.38039216  0.24313725  0.13333333]\n",
      "   [ 0.3254902   0.20784314  0.13333333]]\n",
      "\n",
      "  [[ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.65882353  0.50588235  0.36862745]\n",
      "   [ 0.70196078  0.55686275  0.34117647]\n",
      "   ..., \n",
      "   [ 0.84705882  0.72156863  0.54901961]\n",
      "   [ 0.59215686  0.4627451   0.32941176]\n",
      "   [ 0.48235294  0.36078431  0.28235294]]]\n",
      "\n",
      "\n",
      " [[[ 0.60392157  0.69411765  0.73333333]\n",
      "   [ 0.49411765  0.5372549   0.53333333]\n",
      "   [ 0.41176471  0.40784314  0.37254902]\n",
      "   ..., \n",
      "   [ 0.35686275  0.37254902  0.27843137]\n",
      "   [ 0.34117647  0.35294118  0.27843137]\n",
      "   [ 0.30980392  0.31764706  0.2745098 ]]\n",
      "\n",
      "  [[ 0.54901961  0.62745098  0.6627451 ]\n",
      "   [ 0.56862745  0.6         0.60392157]\n",
      "   [ 0.49019608  0.49019608  0.4627451 ]\n",
      "   ..., \n",
      "   [ 0.37647059  0.38823529  0.30588235]\n",
      "   [ 0.30196078  0.31372549  0.24313725]\n",
      "   [ 0.27843137  0.28627451  0.23921569]]\n",
      "\n",
      "  [[ 0.54901961  0.60784314  0.64313725]\n",
      "   [ 0.54509804  0.57254902  0.58431373]\n",
      "   [ 0.45098039  0.45098039  0.43921569]\n",
      "   ..., \n",
      "   [ 0.30980392  0.32156863  0.25098039]\n",
      "   [ 0.26666667  0.2745098   0.21568627]\n",
      "   [ 0.2627451   0.27058824  0.21568627]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.68627451  0.65490196  0.65098039]\n",
      "   [ 0.61176471  0.60392157  0.62745098]\n",
      "   [ 0.60392157  0.62745098  0.66666667]\n",
      "   ..., \n",
      "   [ 0.16470588  0.13333333  0.14117647]\n",
      "   [ 0.23921569  0.20784314  0.22352941]\n",
      "   [ 0.36470588  0.3254902   0.35686275]]\n",
      "\n",
      "  [[ 0.64705882  0.60392157  0.50196078]\n",
      "   [ 0.61176471  0.59607843  0.50980392]\n",
      "   [ 0.62352941  0.63137255  0.55686275]\n",
      "   ..., \n",
      "   [ 0.40392157  0.36470588  0.37647059]\n",
      "   [ 0.48235294  0.44705882  0.47058824]\n",
      "   [ 0.51372549  0.4745098   0.51372549]]\n",
      "\n",
      "  [[ 0.63921569  0.58039216  0.47058824]\n",
      "   [ 0.61960784  0.58039216  0.47843137]\n",
      "   [ 0.63921569  0.61176471  0.52156863]\n",
      "   ..., \n",
      "   [ 0.56078431  0.52156863  0.54509804]\n",
      "   [ 0.56078431  0.5254902   0.55686275]\n",
      "   [ 0.56078431  0.52156863  0.56470588]]]\n",
      "\n",
      "\n",
      " [[[ 1.          1.          1.        ]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 0.99607843  0.99607843  0.99607843]\n",
      "   [ 0.99607843  0.99607843  0.99607843]\n",
      "   ..., \n",
      "   [ 0.99607843  0.99607843  0.99607843]\n",
      "   [ 0.99607843  0.99607843  0.99607843]\n",
      "   [ 0.99607843  0.99607843  0.99607843]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.44313725  0.47058824  0.43921569]\n",
      "   [ 0.43529412  0.4627451   0.43529412]\n",
      "   [ 0.41176471  0.43921569  0.41568627]\n",
      "   ..., \n",
      "   [ 0.28235294  0.31764706  0.31372549]\n",
      "   [ 0.28235294  0.31372549  0.30980392]\n",
      "   [ 0.28235294  0.31372549  0.30980392]]\n",
      "\n",
      "  [[ 0.43529412  0.4627451   0.43137255]\n",
      "   [ 0.40784314  0.43529412  0.40784314]\n",
      "   [ 0.38823529  0.41568627  0.38431373]\n",
      "   ..., \n",
      "   [ 0.26666667  0.29411765  0.28627451]\n",
      "   [ 0.2745098   0.29803922  0.29411765]\n",
      "   [ 0.30588235  0.32941176  0.32156863]]\n",
      "\n",
      "  [[ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.38823529  0.41568627  0.38431373]\n",
      "   [ 0.37254902  0.4         0.36862745]\n",
      "   ..., \n",
      "   [ 0.30588235  0.33333333  0.3254902 ]\n",
      "   [ 0.30980392  0.33333333  0.3254902 ]\n",
      "   [ 0.31372549  0.3372549   0.32941176]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.27058824  0.27843137  0.20392157]\n",
      "   [ 0.24313725  0.24313725  0.19215686]\n",
      "   [ 0.22745098  0.22352941  0.18823529]\n",
      "   ..., \n",
      "   [ 0.4627451   0.49019608  0.31372549]\n",
      "   [ 0.4745098   0.49019608  0.28627451]\n",
      "   [ 0.48235294  0.50588235  0.29019608]]\n",
      "\n",
      "  [[ 0.2745098   0.27843137  0.19215686]\n",
      "   [ 0.23137255  0.22745098  0.18431373]\n",
      "   [ 0.2         0.19215686  0.16862745]\n",
      "   ..., \n",
      "   [ 0.48235294  0.48235294  0.3254902 ]\n",
      "   [ 0.45882353  0.47843137  0.29803922]\n",
      "   [ 0.41568627  0.43921569  0.25490196]]\n",
      "\n",
      "  [[ 0.28627451  0.28235294  0.18431373]\n",
      "   [ 0.25490196  0.24705882  0.17647059]\n",
      "   [ 0.20392157  0.19607843  0.17254902]\n",
      "   ..., \n",
      "   [ 0.47058824  0.46666667  0.30980392]\n",
      "   [ 0.45098039  0.45098039  0.27058824]\n",
      "   [ 0.42745098  0.43529412  0.26666667]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.76862745  0.82352941  0.37254902]\n",
      "   [ 0.79215686  0.82745098  0.42745098]\n",
      "   [ 0.76078431  0.78823529  0.41176471]\n",
      "   ..., \n",
      "   [ 0.77647059  0.84313725  0.35294118]\n",
      "   [ 0.81568627  0.85882353  0.42352941]\n",
      "   [ 0.83137255  0.88235294  0.43529412]]\n",
      "\n",
      "  [[ 0.74509804  0.80784314  0.36862745]\n",
      "   [ 0.74901961  0.80784314  0.37254902]\n",
      "   [ 0.74509804  0.80392157  0.36470588]\n",
      "   ..., \n",
      "   [ 0.77647059  0.83921569  0.36862745]\n",
      "   [ 0.76470588  0.81568627  0.37254902]\n",
      "   [ 0.80784314  0.8627451   0.41960784]]\n",
      "\n",
      "  [[ 0.71764706  0.76470588  0.36470588]\n",
      "   [ 0.72156863  0.77254902  0.37647059]\n",
      "   [ 0.71372549  0.75686275  0.36078431]\n",
      "   ..., \n",
      "   [ 0.75686275  0.81176471  0.35686275]\n",
      "   [ 0.74117647  0.8         0.34117647]\n",
      "   [ 0.77647059  0.82745098  0.39215686]]]\n",
      "\n",
      "\n",
      " [[[ 0.61960784  0.61960784  0.61960784]\n",
      "   [ 0.61960784  0.61960784  0.61568627]\n",
      "   [ 0.61960784  0.62352941  0.60392157]\n",
      "   ..., \n",
      "   [ 0.61176471  0.61568627  0.59607843]\n",
      "   [ 0.61176471  0.61568627  0.59607843]\n",
      "   [ 0.61176471  0.61176471  0.59215686]]\n",
      "\n",
      "  [[ 0.61568627  0.61568627  0.61568627]\n",
      "   [ 0.61960784  0.61960784  0.61568627]\n",
      "   [ 0.61568627  0.61568627  0.60784314]\n",
      "   ..., \n",
      "   [ 0.61176471  0.61568627  0.6       ]\n",
      "   [ 0.61176471  0.61568627  0.59607843]\n",
      "   [ 0.61176471  0.61176471  0.59607843]]\n",
      "\n",
      "  [[ 0.61176471  0.61176471  0.61176471]\n",
      "   [ 0.61568627  0.61568627  0.61176471]\n",
      "   [ 0.61568627  0.61568627  0.60784314]\n",
      "   ..., \n",
      "   [ 0.60784314  0.60784314  0.6       ]\n",
      "   [ 0.60784314  0.60784314  0.6       ]\n",
      "   [ 0.60784314  0.60784314  0.6       ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.22745098  0.26666667  0.26666667]\n",
      "   [ 0.24313725  0.28235294  0.29019608]\n",
      "   [ 0.21960784  0.25882353  0.2627451 ]\n",
      "   ..., \n",
      "   [ 0.24313725  0.2745098   0.30196078]\n",
      "   [ 0.18823529  0.22352941  0.23137255]\n",
      "   [ 0.22352941  0.25882353  0.26666667]]\n",
      "\n",
      "  [[ 0.20392157  0.24313725  0.23921569]\n",
      "   [ 0.23529412  0.27058824  0.27843137]\n",
      "   [ 0.16862745  0.20392157  0.20392157]\n",
      "   ..., \n",
      "   [ 0.25882353  0.29803922  0.30980392]\n",
      "   [ 0.21568627  0.25882353  0.2627451 ]\n",
      "   [ 0.23529412  0.2745098   0.29019608]]\n",
      "\n",
      "  [[ 0.19607843  0.22745098  0.23137255]\n",
      "   [ 0.2         0.21960784  0.21960784]\n",
      "   [ 0.20784314  0.23529412  0.23921569]\n",
      "   ..., \n",
      "   [ 0.18039216  0.21176471  0.21176471]\n",
      "   [ 0.22745098  0.25882353  0.26666667]\n",
      "   [ 0.23921569  0.28235294  0.29019608]]]\n",
      "\n",
      "\n",
      " [[[ 0.76862745  0.67058824  0.51372549]\n",
      "   [ 0.76862745  0.6745098   0.51372549]\n",
      "   [ 0.75686275  0.65882353  0.50196078]\n",
      "   ..., \n",
      "   [ 0.69411765  0.6         0.50980392]\n",
      "   [ 0.67058824  0.57647059  0.48627451]\n",
      "   [ 0.64705882  0.55294118  0.45882353]]\n",
      "\n",
      "  [[ 0.77647059  0.67843137  0.52156863]\n",
      "   [ 0.77647059  0.67843137  0.52156863]\n",
      "   [ 0.76470588  0.6627451   0.50588235]\n",
      "   ..., \n",
      "   [ 0.69803922  0.60784314  0.51764706]\n",
      "   [ 0.6745098   0.58431373  0.49411765]\n",
      "   [ 0.65490196  0.56470588  0.47058824]]\n",
      "\n",
      "  [[ 0.76862745  0.67058824  0.51764706]\n",
      "   [ 0.76862745  0.67058824  0.51764706]\n",
      "   [ 0.75294118  0.65490196  0.50196078]\n",
      "   ..., \n",
      "   [ 0.69019608  0.60392157  0.51764706]\n",
      "   [ 0.66666667  0.58431373  0.49411765]\n",
      "   [ 0.64705882  0.56078431  0.4745098 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.7372549   0.61960784  0.40392157]\n",
      "   [ 0.7372549   0.62745098  0.40392157]\n",
      "   [ 0.74117647  0.62745098  0.4       ]\n",
      "   ..., \n",
      "   [ 0.8         0.74509804  0.69803922]\n",
      "   [ 0.78431373  0.74117647  0.70196078]\n",
      "   [ 0.76862745  0.71764706  0.68235294]]\n",
      "\n",
      "  [[ 0.74117647  0.62352941  0.40392157]\n",
      "   [ 0.74117647  0.62745098  0.40784314]\n",
      "   [ 0.74509804  0.63137255  0.4       ]\n",
      "   ..., \n",
      "   [ 0.80392157  0.74509804  0.68627451]\n",
      "   [ 0.78431373  0.73333333  0.69019608]\n",
      "   [ 0.77254902  0.71764706  0.67843137]]\n",
      "\n",
      "  [[ 0.72156863  0.60392157  0.39215686]\n",
      "   [ 0.72156863  0.61176471  0.39215686]\n",
      "   [ 0.72156863  0.60784314  0.38039216]\n",
      "   ..., \n",
      "   [ 0.78039216  0.71372549  0.64705882]\n",
      "   [ 0.76862745  0.70588235  0.65490196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [ 0.75686275  0.69411765  0.65098039]]]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n",
      "[[[[ 0.1372549   0.09803922  0.10196078]\n",
      "   [ 0.10588235  0.08235294  0.08235294]\n",
      "   [ 0.09803922  0.07843137  0.0745098 ]\n",
      "   ..., \n",
      "   [ 0.51764706  0.50588235  0.50588235]\n",
      "   [ 0.52156863  0.4745098   0.45490196]\n",
      "   [ 0.49411765  0.45098039  0.44313725]]\n",
      "\n",
      "  [[ 0.24705882  0.21568627  0.19607843]\n",
      "   [ 0.1254902   0.10588235  0.08235294]\n",
      "   [ 0.06666667  0.05098039  0.03137255]\n",
      "   ..., \n",
      "   [ 0.4         0.37254902  0.34509804]\n",
      "   [ 0.41176471  0.34901961  0.29803922]\n",
      "   [ 0.39215686  0.3372549   0.30196078]]\n",
      "\n",
      "  [[ 0.38823529  0.35686275  0.32941176]\n",
      "   [ 0.19215686  0.17647059  0.14509804]\n",
      "   [ 0.05882353  0.04705882  0.01960784]\n",
      "   ..., \n",
      "   [ 0.18039216  0.16862745  0.15294118]\n",
      "   [ 0.20392157  0.16078431  0.13333333]\n",
      "   [ 0.20392157  0.17254902  0.16078431]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.65098039  0.64705882  0.67058824]\n",
      "   [ 0.64313725  0.63921569  0.65098039]\n",
      "   [ 0.64313725  0.64313725  0.64705882]\n",
      "   ..., \n",
      "   [ 0.67843137  0.6745098   0.66666667]\n",
      "   [ 0.66666667  0.66666667  0.65882353]\n",
      "   [ 0.65490196  0.65490196  0.65490196]]\n",
      "\n",
      "  [[ 0.6627451   0.65882353  0.69019608]\n",
      "   [ 0.6627451   0.65882353  0.67843137]\n",
      "   [ 0.65882353  0.65882353  0.67058824]\n",
      "   ..., \n",
      "   [ 0.6745098   0.67058824  0.66666667]\n",
      "   [ 0.65882353  0.65490196  0.65490196]\n",
      "   [ 0.64705882  0.64705882  0.65098039]]\n",
      "\n",
      "  [[ 0.67843137  0.6745098   0.70196078]\n",
      "   [ 0.68627451  0.68235294  0.69803922]\n",
      "   [ 0.67843137  0.67843137  0.68627451]\n",
      "   ..., \n",
      "   [ 0.66666667  0.65882353  0.6627451 ]\n",
      "   [ 0.65882353  0.65490196  0.65882353]\n",
      "   [ 0.65098039  0.65098039  0.65882353]]]\n",
      "\n",
      "\n",
      " [[[ 0.07843137  0.05882353  0.04705882]\n",
      "   [ 0.07843137  0.05882353  0.04705882]\n",
      "   [ 0.07058824  0.05098039  0.03921569]\n",
      "   ..., \n",
      "   [ 0.07843137  0.0627451   0.0627451 ]\n",
      "   [ 0.08235294  0.0627451   0.05490196]\n",
      "   [ 0.08235294  0.0627451   0.05098039]]\n",
      "\n",
      "  [[ 0.07843137  0.05882353  0.04705882]\n",
      "   [ 0.07843137  0.05882353  0.04705882]\n",
      "   [ 0.07058824  0.05098039  0.03921569]\n",
      "   ..., \n",
      "   [ 0.07843137  0.0627451   0.05882353]\n",
      "   [ 0.08235294  0.0627451   0.05098039]\n",
      "   [ 0.08235294  0.0627451   0.05098039]]\n",
      "\n",
      "  [[ 0.07843137  0.05882353  0.04705882]\n",
      "   [ 0.07843137  0.05882353  0.04705882]\n",
      "   [ 0.07058824  0.05098039  0.03921569]\n",
      "   ..., \n",
      "   [ 0.07843137  0.0627451   0.05490196]\n",
      "   [ 0.08235294  0.0627451   0.05098039]\n",
      "   [ 0.08235294  0.0627451   0.05098039]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.25882353  0.21176471  0.16078431]\n",
      "   [ 0.31372549  0.2627451   0.20784314]\n",
      "   [ 0.18431373  0.1372549   0.0745098 ]\n",
      "   ..., \n",
      "   [ 0.5254902   0.5254902   0.39215686]\n",
      "   [ 0.43137255  0.44313725  0.30196078]\n",
      "   [ 0.38431373  0.4         0.25882353]]\n",
      "\n",
      "  [[ 0.23529412  0.18823529  0.12941176]\n",
      "   [ 0.21568627  0.16862745  0.10588235]\n",
      "   [ 0.19607843  0.14901961  0.08627451]\n",
      "   ..., \n",
      "   [ 0.48235294  0.49019608  0.3254902 ]\n",
      "   [ 0.30980392  0.31764706  0.16470588]\n",
      "   [ 0.28235294  0.29019608  0.14901961]]\n",
      "\n",
      "  [[ 0.25098039  0.21176471  0.14901961]\n",
      "   [ 0.21568627  0.17647059  0.11372549]\n",
      "   [ 0.18823529  0.14901961  0.08235294]\n",
      "   ..., \n",
      "   [ 0.60784314  0.61568627  0.43529412]\n",
      "   [ 0.53333333  0.5372549   0.38039216]\n",
      "   [ 0.34509804  0.34901961  0.2       ]]]\n",
      "\n",
      "\n",
      " [[[ 0.45490196  0.40392157  0.21960784]\n",
      "   [ 0.45098039  0.41176471  0.23137255]\n",
      "   [ 0.60784314  0.50196078  0.32156863]\n",
      "   ..., \n",
      "   [ 0.68627451  0.51764706  0.30196078]\n",
      "   [ 0.6627451   0.52156863  0.28235294]\n",
      "   [ 0.55686275  0.46666667  0.20784314]]\n",
      "\n",
      "  [[ 0.45490196  0.4         0.22745098]\n",
      "   [ 0.47843137  0.42352941  0.25490196]\n",
      "   [ 0.6         0.4745098   0.30980392]\n",
      "   ..., \n",
      "   [ 0.58823529  0.43529412  0.22352941]\n",
      "   [ 0.56862745  0.4745098   0.23529412]\n",
      "   [ 0.52156863  0.48235294  0.21176471]]\n",
      "\n",
      "  [[ 0.37254902  0.3372549   0.16078431]\n",
      "   [ 0.38431373  0.32941176  0.17254902]\n",
      "   [ 0.55294118  0.41568627  0.2627451 ]\n",
      "   ..., \n",
      "   [ 0.56862745  0.43921569  0.22745098]\n",
      "   [ 0.49411765  0.43529412  0.2       ]\n",
      "   [ 0.49803922  0.49019608  0.24313725]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.30196078  0.24705882  0.11372549]\n",
      "   [ 0.34509804  0.28235294  0.14509804]\n",
      "   [ 0.2745098   0.23137255  0.10588235]\n",
      "   ..., \n",
      "   [ 0.18823529  0.15294118  0.07843137]\n",
      "   [ 0.45490196  0.42352941  0.32941176]\n",
      "   [ 0.62352941  0.55686275  0.47843137]]\n",
      "\n",
      "  [[ 0.21568627  0.14509804  0.0627451 ]\n",
      "   [ 0.25490196  0.18039216  0.09411765]\n",
      "   [ 0.26666667  0.20784314  0.11764706]\n",
      "   ..., \n",
      "   [ 0.16470588  0.11764706  0.05098039]\n",
      "   [ 0.49411765  0.44705882  0.35294118]\n",
      "   [ 0.62745098  0.57647059  0.49019608]]\n",
      "\n",
      "  [[ 0.30588235  0.22352941  0.14509804]\n",
      "   [ 0.28235294  0.19607843  0.11764706]\n",
      "   [ 0.2627451   0.19607843  0.1254902 ]\n",
      "   ..., \n",
      "   [ 0.20392157  0.14509804  0.07058824]\n",
      "   [ 0.48627451  0.43137255  0.32941176]\n",
      "   [ 0.60784314  0.56470588  0.48627451]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.41568627  0.3372549   0.61176471]\n",
      "   [ 0.48235294  0.4         0.50588235]\n",
      "   [ 0.43529412  0.33333333  0.49019608]\n",
      "   ..., \n",
      "   [ 0.51372549  0.4627451   0.61568627]\n",
      "   [ 0.42745098  0.39215686  0.55686275]\n",
      "   [ 0.55294118  0.52941176  0.61960784]]\n",
      "\n",
      "  [[ 0.60784314  0.5254902   0.63529412]\n",
      "   [ 0.6745098   0.57254902  0.44313725]\n",
      "   [ 0.51372549  0.43529412  0.48627451]\n",
      "   ..., \n",
      "   [ 0.51764706  0.46666667  0.60784314]\n",
      "   [ 0.39215686  0.34901961  0.50980392]\n",
      "   [ 0.56862745  0.5372549   0.63529412]]\n",
      "\n",
      "  [[ 0.63529412  0.5254902   0.68235294]\n",
      "   [ 0.62745098  0.49803922  0.43137255]\n",
      "   [ 0.44313725  0.34509804  0.5254902 ]\n",
      "   ..., \n",
      "   [ 0.73333333  0.71372549  0.65490196]\n",
      "   [ 0.69411765  0.6745098   0.65882353]\n",
      "   [ 0.78823529  0.77254902  0.71764706]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.35686275  0.03921569  0.5254902 ]\n",
      "   [ 0.34509804  0.03529412  0.49803922]\n",
      "   [ 0.34509804  0.05098039  0.49803922]\n",
      "   ..., \n",
      "   [ 0.40784314  0.24705882  0.49411765]\n",
      "   [ 0.43529412  0.28235294  0.52156863]\n",
      "   [ 0.43921569  0.25490196  0.53333333]]\n",
      "\n",
      "  [[ 0.29803922  0.02352941  0.50196078]\n",
      "   [ 0.30588235  0.01568627  0.47058824]\n",
      "   [ 0.35686275  0.08235294  0.51764706]\n",
      "   ..., \n",
      "   [ 0.42745098  0.27058824  0.49803922]\n",
      "   [ 0.41960784  0.26666667  0.50980392]\n",
      "   [ 0.44705882  0.24705882  0.54509804]]\n",
      "\n",
      "  [[ 0.2627451   0.03137255  0.50196078]\n",
      "   [ 0.26666667  0.02352941  0.47058824]\n",
      "   [ 0.30980392  0.07058824  0.49803922]\n",
      "   ..., \n",
      "   [ 0.45882353  0.28627451  0.5254902 ]\n",
      "   [ 0.43137255  0.25098039  0.52156863]\n",
      "   [ 0.38823529  0.16470588  0.49019608]]]\n",
      "\n",
      "\n",
      " [[[ 0.96862745  0.96470588  0.97254902]\n",
      "   [ 0.96078431  0.97647059  0.98823529]\n",
      "   [ 0.95686275  0.97254902  0.97647059]\n",
      "   ..., \n",
      "   [ 0.45882353  0.38039216  0.32941176]\n",
      "   [ 0.49803922  0.41960784  0.37647059]\n",
      "   [ 0.61960784  0.56470588  0.54117647]]\n",
      "\n",
      "  [[ 0.95294118  0.95686275  0.96862745]\n",
      "   [ 0.95294118  0.96862745  0.97647059]\n",
      "   [ 0.95294118  0.96078431  0.95686275]\n",
      "   ..., \n",
      "   [ 0.44313725  0.35686275  0.29803922]\n",
      "   [ 0.47843137  0.4         0.34509804]\n",
      "   [ 0.63137255  0.56862745  0.52941176]]\n",
      "\n",
      "  [[ 0.95686275  0.96078431  0.97647059]\n",
      "   [ 0.96078431  0.97647059  0.98039216]\n",
      "   [ 0.96862745  0.96862745  0.95686275]\n",
      "   ..., \n",
      "   [ 0.52941176  0.42745098  0.36470588]\n",
      "   [ 0.4745098   0.37647059  0.31764706]\n",
      "   [ 0.50588235  0.43137255  0.38823529]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.71372549  0.6627451   0.63529412]\n",
      "   [ 0.77647059  0.7254902   0.69803922]\n",
      "   [ 0.85490196  0.80392157  0.77647059]\n",
      "   ..., \n",
      "   [ 0.61568627  0.54901961  0.44313725]\n",
      "   [ 0.36862745  0.30588235  0.21960784]\n",
      "   [ 0.50980392  0.45882353  0.41176471]]\n",
      "\n",
      "  [[ 0.54509804  0.4627451   0.41960784]\n",
      "   [ 0.49411765  0.40392157  0.35686275]\n",
      "   [ 0.5254902   0.43529412  0.38431373]\n",
      "   ..., \n",
      "   [ 0.61960784  0.55686275  0.43921569]\n",
      "   [ 0.46666667  0.40784314  0.31372549]\n",
      "   [ 0.45490196  0.40784314  0.35294118]]\n",
      "\n",
      "  [[ 0.76862745  0.70196078  0.62745098]\n",
      "   [ 0.7254902   0.63921569  0.54509804]\n",
      "   [ 0.69019608  0.58823529  0.48235294]\n",
      "   ..., \n",
      "   [ 0.59607843  0.54901961  0.42352941]\n",
      "   [ 0.69411765  0.64313725  0.5372549 ]\n",
      "   [ 0.63529412  0.59607843  0.52156863]]]\n",
      "\n",
      "\n",
      " [[[ 0.74117647  0.89803922  0.94117647]\n",
      "   [ 0.76470588  0.90980392  0.94901961]\n",
      "   [ 0.79607843  0.93333333  0.96470588]\n",
      "   ..., \n",
      "   [ 0.65882353  0.75686275  0.81176471]\n",
      "   [ 0.65882353  0.74901961  0.79215686]\n",
      "   [ 0.65882353  0.7372549   0.78039216]]\n",
      "\n",
      "  [[ 0.79607843  0.9372549   0.96470588]\n",
      "   [ 0.83137255  0.96470588  0.98431373]\n",
      "   [ 0.82352941  0.94901961  0.96862745]\n",
      "   ..., \n",
      "   [ 0.58431373  0.67843137  0.76470588]\n",
      "   [ 0.59215686  0.6745098   0.76470588]\n",
      "   [ 0.60784314  0.67843137  0.77254902]]\n",
      "\n",
      "  [[ 0.83529412  0.96862745  0.98431373]\n",
      "   [ 0.81568627  0.94509804  0.96078431]\n",
      "   [ 0.82745098  0.94509804  0.95686275]\n",
      "   ..., \n",
      "   [ 0.58431373  0.6745098   0.76862745]\n",
      "   [ 0.57647059  0.65490196  0.76470588]\n",
      "   [ 0.56470588  0.63137255  0.75686275]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.29019608  0.31764706  0.35294118]\n",
      "   [ 0.21176471  0.32156863  0.47843137]\n",
      "   [ 0.15294118  0.40784314  0.62352941]\n",
      "   ..., \n",
      "   [ 0.18039216  0.15294118  0.18039216]\n",
      "   [ 0.19607843  0.16862745  0.2       ]\n",
      "   [ 0.27058824  0.24705882  0.25098039]]\n",
      "\n",
      "  [[ 0.25490196  0.2627451   0.28627451]\n",
      "   [ 0.16470588  0.22745098  0.35686275]\n",
      "   [ 0.17647059  0.36078431  0.50980392]\n",
      "   ..., \n",
      "   [ 0.14509804  0.08627451  0.17647059]\n",
      "   [ 0.17254902  0.10588235  0.18431373]\n",
      "   [ 0.22352941  0.17254902  0.2       ]]\n",
      "\n",
      "  [[ 0.20784314  0.22745098  0.24705882]\n",
      "   [ 0.15294118  0.2         0.25490196]\n",
      "   [ 0.24705882  0.30588235  0.36862745]\n",
      "   ..., \n",
      "   [ 0.18039216  0.10196078  0.19215686]\n",
      "   [ 0.23137255  0.14901961  0.18431373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [ 0.29411765  0.23921569  0.2       ]]]]\n",
      "[[ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  1.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]]\n",
      "[[[[ 0.10196078  0.09019608  0.1254902 ]\n",
      "   [ 0.06666667  0.05490196  0.09803922]\n",
      "   [ 0.05098039  0.03529412  0.09411765]\n",
      "   ..., \n",
      "   [ 0.05882353  0.05490196  0.10980392]\n",
      "   [ 0.09411765  0.09411765  0.14509804]\n",
      "   [ 0.08627451  0.08235294  0.13333333]]\n",
      "\n",
      "  [[ 0.07843137  0.06666667  0.10196078]\n",
      "   [ 0.05098039  0.03921569  0.08627451]\n",
      "   [ 0.05098039  0.03529412  0.09411765]\n",
      "   ..., \n",
      "   [ 0.0745098   0.06666667  0.1372549 ]\n",
      "   [ 0.08235294  0.07843137  0.1372549 ]\n",
      "   [ 0.11372549  0.11372549  0.15294118]]\n",
      "\n",
      "  [[ 0.05490196  0.04313725  0.07843137]\n",
      "   [ 0.05098039  0.03921569  0.08235294]\n",
      "   [ 0.05098039  0.03529412  0.09019608]\n",
      "   ..., \n",
      "   [ 0.06666667  0.0627451   0.1254902 ]\n",
      "   [ 0.09803922  0.09411765  0.14901961]\n",
      "   [ 0.12156863  0.12156863  0.16470588]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.35294118  0.42745098  0.5372549 ]\n",
      "   [ 0.13333333  0.25098039  0.37254902]\n",
      "   [ 0.10980392  0.21176471  0.35294118]\n",
      "   ..., \n",
      "   [ 0.09019608  0.07843137  0.14509804]\n",
      "   [ 0.0627451   0.05098039  0.11764706]\n",
      "   [ 0.03529412  0.02352941  0.09019608]]\n",
      "\n",
      "  [[ 0.30980392  0.41176471  0.55294118]\n",
      "   [ 0.22745098  0.37647059  0.54509804]\n",
      "   [ 0.1254902   0.26666667  0.43137255]\n",
      "   ..., \n",
      "   [ 0.05490196  0.04313725  0.10980392]\n",
      "   [ 0.0627451   0.05098039  0.11764706]\n",
      "   [ 0.03921569  0.02745098  0.09411765]]\n",
      "\n",
      "  [[ 0.50196078  0.61568627  0.76862745]\n",
      "   [ 0.22745098  0.36470588  0.58431373]\n",
      "   [ 0.09803922  0.23529412  0.41568627]\n",
      "   ..., \n",
      "   [ 0.05098039  0.03921569  0.10588235]\n",
      "   [ 0.04705882  0.03529412  0.10196078]\n",
      "   [ 0.05098039  0.03921569  0.10588235]]]\n",
      "\n",
      "\n",
      " [[[ 0.36862745  0.3372549   0.22745098]\n",
      "   [ 0.39607843  0.35686275  0.23921569]\n",
      "   [ 0.37254902  0.33333333  0.21176471]\n",
      "   ..., \n",
      "   [ 0.56862745  0.54117647  0.41568627]\n",
      "   [ 0.56862745  0.54901961  0.42352941]\n",
      "   [ 0.4745098   0.45882353  0.35294118]]\n",
      "\n",
      "  [[ 0.34901961  0.32941176  0.21568627]\n",
      "   [ 0.38039216  0.34901961  0.23137255]\n",
      "   [ 0.39607843  0.35686275  0.23529412]\n",
      "   ..., \n",
      "   [ 0.57254902  0.5372549   0.41568627]\n",
      "   [ 0.57254902  0.54509804  0.41960784]\n",
      "   [ 0.47843137  0.45882353  0.35294118]]\n",
      "\n",
      "  [[ 0.3372549   0.32941176  0.21176471]\n",
      "   [ 0.36862745  0.34509804  0.22352941]\n",
      "   [ 0.41960784  0.38431373  0.2627451 ]\n",
      "   ..., \n",
      "   [ 0.57254902  0.53333333  0.41568627]\n",
      "   [ 0.57647059  0.54117647  0.41960784]\n",
      "   [ 0.48235294  0.45490196  0.35294118]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.80392157  0.80392157  0.8       ]\n",
      "   [ 0.81568627  0.81568627  0.81176471]\n",
      "   [ 0.78823529  0.78823529  0.78431373]\n",
      "   ..., \n",
      "   [ 0.56862745  0.58431373  0.58431373]\n",
      "   [ 0.58431373  0.59607843  0.61568627]\n",
      "   [ 0.49019608  0.50196078  0.52941176]]\n",
      "\n",
      "  [[ 0.78823529  0.78823529  0.78823529]\n",
      "   [ 0.80392157  0.80392157  0.80392157]\n",
      "   [ 0.77647059  0.77647059  0.77647059]\n",
      "   ..., \n",
      "   [ 0.60392157  0.61960784  0.6627451 ]\n",
      "   [ 0.61960784  0.63529412  0.69411765]\n",
      "   [ 0.5254902   0.54117647  0.6       ]]\n",
      "\n",
      "  [[ 0.74509804  0.74509804  0.74117647]\n",
      "   [ 0.7372549   0.7372549   0.73333333]\n",
      "   [ 0.68627451  0.68627451  0.67843137]\n",
      "   ..., \n",
      "   [ 0.63529412  0.64313725  0.71372549]\n",
      "   [ 0.63921569  0.65098039  0.72156863]\n",
      "   [ 0.52941176  0.5372549   0.60784314]]]\n",
      "\n",
      "\n",
      " [[[ 0.71764706  0.72941176  0.69803922]\n",
      "   [ 0.61960784  0.65490196  0.59607843]\n",
      "   [ 0.65098039  0.6745098   0.62745098]\n",
      "   ..., \n",
      "   [ 0.55686275  0.57647059  0.56470588]\n",
      "   [ 0.5372549   0.57254902  0.55294118]\n",
      "   [ 0.56470588  0.58823529  0.57254902]]\n",
      "\n",
      "  [[ 0.49019608  0.5254902   0.47058824]\n",
      "   [ 0.38039216  0.43529412  0.35294118]\n",
      "   [ 0.39215686  0.43921569  0.37254902]\n",
      "   ..., \n",
      "   [ 0.24705882  0.29019608  0.26666667]\n",
      "   [ 0.23137255  0.29019608  0.2627451 ]\n",
      "   [ 0.2627451   0.30980392  0.28235294]]\n",
      "\n",
      "  [[ 0.41960784  0.4745098   0.40392157]\n",
      "   [ 0.33333333  0.40784314  0.30980392]\n",
      "   [ 0.34509804  0.40784314  0.3254902 ]\n",
      "   ..., \n",
      "   [ 0.24705882  0.30980392  0.27843137]\n",
      "   [ 0.20784314  0.28627451  0.25098039]\n",
      "   [ 0.23529412  0.30196078  0.27058824]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.42352941  0.45490196  0.40392157]\n",
      "   [ 0.38431373  0.41960784  0.34117647]\n",
      "   [ 0.46666667  0.50980392  0.41176471]\n",
      "   ..., \n",
      "   [ 0.44705882  0.49019608  0.44313725]\n",
      "   [ 0.40784314  0.45098039  0.40392157]\n",
      "   [ 0.35686275  0.39607843  0.35294118]]\n",
      "\n",
      "  [[ 0.78039216  0.80392157  0.77254902]\n",
      "   [ 0.77254902  0.79607843  0.74509804]\n",
      "   [ 0.81176471  0.83921569  0.76862745]\n",
      "   ..., \n",
      "   [ 0.79607843  0.81960784  0.79215686]\n",
      "   [ 0.78431373  0.80392157  0.78039216]\n",
      "   [ 0.74117647  0.76078431  0.7372549 ]]\n",
      "\n",
      "  [[ 0.98431373  1.          0.98823529]\n",
      "   [ 0.97254902  0.98823529  0.96470588]\n",
      "   [ 0.97647059  0.99215686  0.95686275]\n",
      "   ..., \n",
      "   [ 0.98039216  0.98431373  0.98039216]\n",
      "   [ 0.98039216  0.98039216  0.98039216]\n",
      "   [ 0.98039216  0.98431373  0.98039216]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.6745098   0.67843137  0.59607843]\n",
      "   [ 0.67058824  0.6745098   0.59607843]\n",
      "   [ 0.69803922  0.69803922  0.61960784]\n",
      "   ..., \n",
      "   [ 0.41960784  0.41176471  0.30196078]\n",
      "   [ 0.41568627  0.40392157  0.30980392]\n",
      "   [ 0.4         0.38823529  0.30588235]]\n",
      "\n",
      "  [[ 0.64705882  0.63921569  0.56078431]\n",
      "   [ 0.62352941  0.61568627  0.54117647]\n",
      "   [ 0.70588235  0.69803922  0.62352941]\n",
      "   ..., \n",
      "   [ 0.45882353  0.43921569  0.3254902 ]\n",
      "   [ 0.45882353  0.43921569  0.3372549 ]\n",
      "   [ 0.43529412  0.41568627  0.3254902 ]]\n",
      "\n",
      "  [[ 0.68235294  0.6627451   0.58823529]\n",
      "   [ 0.61176471  0.59215686  0.51764706]\n",
      "   [ 0.68235294  0.6627451   0.58823529]\n",
      "   ..., \n",
      "   [ 0.47058824  0.44705882  0.3254902 ]\n",
      "   [ 0.4745098   0.44705882  0.3372549 ]\n",
      "   [ 0.46666667  0.43921569  0.34509804]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.47843137  0.45882353  0.36862745]\n",
      "   [ 0.47058824  0.45098039  0.36470588]\n",
      "   [ 0.45490196  0.43921569  0.34901961]\n",
      "   ..., \n",
      "   [ 0.48627451  0.49803922  0.39215686]\n",
      "   [ 0.4745098   0.49411765  0.39215686]\n",
      "   [ 0.45882353  0.47843137  0.38039216]]\n",
      "\n",
      "  [[ 0.43529412  0.41176471  0.30588235]\n",
      "   [ 0.43921569  0.41960784  0.3254902 ]\n",
      "   [ 0.48235294  0.48627451  0.39607843]\n",
      "   ..., \n",
      "   [ 0.47843137  0.45490196  0.32941176]\n",
      "   [ 0.45882353  0.4627451   0.35294118]\n",
      "   [ 0.44313725  0.45882353  0.35294118]]\n",
      "\n",
      "  [[ 0.43921569  0.41176471  0.30196078]\n",
      "   [ 0.45098039  0.42352941  0.32941176]\n",
      "   [ 0.4627451   0.47058824  0.37647059]\n",
      "   ..., \n",
      "   [ 0.48627451  0.45098039  0.31372549]\n",
      "   [ 0.43137255  0.43137255  0.31764706]\n",
      "   [ 0.4         0.41568627  0.30980392]]]\n",
      "\n",
      "\n",
      " [[[ 0.37254902  0.34509804  0.2       ]\n",
      "   [ 0.36078431  0.34509804  0.19215686]\n",
      "   [ 0.35686275  0.34117647  0.19607843]\n",
      "   ..., \n",
      "   [ 0.20784314  0.20392157  0.11764706]\n",
      "   [ 0.20392157  0.2         0.11764706]\n",
      "   [ 0.21176471  0.21176471  0.1254902 ]]\n",
      "\n",
      "  [[ 0.4         0.36862745  0.20784314]\n",
      "   [ 0.41568627  0.38039216  0.2       ]\n",
      "   [ 0.41960784  0.38431373  0.21176471]\n",
      "   ..., \n",
      "   [ 0.20392157  0.20392157  0.1254902 ]\n",
      "   [ 0.19215686  0.18823529  0.10588235]\n",
      "   [ 0.23137255  0.22745098  0.1254902 ]]\n",
      "\n",
      "  [[ 0.41960784  0.38431373  0.20392157]\n",
      "   [ 0.42745098  0.38823529  0.20392157]\n",
      "   [ 0.41176471  0.38039216  0.20392157]\n",
      "   ..., \n",
      "   [ 0.20784314  0.20784314  0.1254902 ]\n",
      "   [ 0.21568627  0.20784314  0.11764706]\n",
      "   [ 0.24313725  0.23529412  0.1254902 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.37647059  0.36078431  0.23529412]\n",
      "   [ 0.24313725  0.23921569  0.15686275]\n",
      "   [ 0.20784314  0.21176471  0.14117647]\n",
      "   ..., \n",
      "   [ 0.19607843  0.19607843  0.12941176]\n",
      "   [ 0.21568627  0.21568627  0.14117647]\n",
      "   [ 0.23529412  0.22745098  0.15294118]]\n",
      "\n",
      "  [[ 0.31372549  0.29803922  0.2       ]\n",
      "   [ 0.23137255  0.22745098  0.15294118]\n",
      "   [ 0.19607843  0.2         0.12941176]\n",
      "   ..., \n",
      "   [ 0.21960784  0.20392157  0.13333333]\n",
      "   [ 0.25098039  0.23529412  0.15294118]\n",
      "   [ 0.25098039  0.23529412  0.14901961]]\n",
      "\n",
      "  [[ 0.18431373  0.18039216  0.1254902 ]\n",
      "   [ 0.15294118  0.15686275  0.10980392]\n",
      "   [ 0.15294118  0.15686275  0.09803922]\n",
      "   ..., \n",
      "   [ 0.30980392  0.29019608  0.17647059]\n",
      "   [ 0.25098039  0.23137255  0.14901961]\n",
      "   [ 0.23921569  0.22352941  0.14901961]]]\n",
      "\n",
      "\n",
      " [[[ 0.60784314  0.40392157  0.43137255]\n",
      "   [ 0.59607843  0.39215686  0.41960784]\n",
      "   [ 0.60784314  0.40392157  0.43137255]\n",
      "   ..., \n",
      "   [ 0.23137255  0.14901961  0.17254902]\n",
      "   [ 0.22352941  0.15686275  0.18039216]\n",
      "   [ 0.22352941  0.16078431  0.19607843]]\n",
      "\n",
      "  [[ 0.60784314  0.40784314  0.43529412]\n",
      "   [ 0.58039216  0.38039216  0.40784314]\n",
      "   [ 0.6         0.4         0.42745098]\n",
      "   ..., \n",
      "   [ 0.28627451  0.18823529  0.20784314]\n",
      "   [ 0.21960784  0.15294118  0.17647059]\n",
      "   [ 0.21960784  0.16078431  0.19215686]]\n",
      "\n",
      "  [[ 0.61176471  0.41176471  0.43921569]\n",
      "   [ 0.58823529  0.38823529  0.41568627]\n",
      "   [ 0.58039216  0.38039216  0.40784314]\n",
      "   ..., \n",
      "   [ 0.41176471  0.30980392  0.3254902 ]\n",
      "   [ 0.23137255  0.16470588  0.18823529]\n",
      "   [ 0.2         0.14117647  0.17254902]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.45490196  0.43921569  0.5254902 ]\n",
      "   [ 0.44313725  0.43529412  0.50980392]\n",
      "   [ 0.44313725  0.44313725  0.50196078]\n",
      "   ..., \n",
      "   [ 0.42745098  0.38039216  0.44705882]\n",
      "   [ 0.28235294  0.23921569  0.29803922]\n",
      "   [ 0.42352941  0.37647059  0.43529412]]\n",
      "\n",
      "  [[ 0.45490196  0.44313725  0.52156863]\n",
      "   [ 0.44705882  0.43529412  0.50980392]\n",
      "   [ 0.45098039  0.43921569  0.51372549]\n",
      "   ..., \n",
      "   [ 0.43137255  0.41176471  0.48627451]\n",
      "   [ 0.23137255  0.19607843  0.26666667]\n",
      "   [ 0.29411765  0.23921569  0.30980392]]\n",
      "\n",
      "  [[ 0.46666667  0.45490196  0.52941176]\n",
      "   [ 0.45490196  0.44313725  0.51764706]\n",
      "   [ 0.45490196  0.44313725  0.51764706]\n",
      "   ..., \n",
      "   [ 0.47058824  0.45882353  0.5372549 ]\n",
      "   [ 0.39607843  0.37254902  0.44705882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [ 0.24705882  0.19607843  0.26666667]]]]\n",
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[[[ 0.69803922  0.69019608  0.74117647]\n",
      "   [ 0.69803922  0.69019608  0.74117647]\n",
      "   [ 0.69803922  0.69019608  0.74117647]\n",
      "   ..., \n",
      "   [ 0.66666667  0.65882353  0.70588235]\n",
      "   [ 0.65882353  0.65098039  0.69411765]\n",
      "   [ 0.64705882  0.63921569  0.68235294]]\n",
      "\n",
      "  [[ 0.70588235  0.69803922  0.74901961]\n",
      "   [ 0.70196078  0.69411765  0.74509804]\n",
      "   [ 0.70588235  0.69803922  0.74901961]\n",
      "   ..., \n",
      "   [ 0.67843137  0.67058824  0.71372549]\n",
      "   [ 0.67058824  0.6627451   0.70588235]\n",
      "   [ 0.65882353  0.65098039  0.69411765]]\n",
      "\n",
      "  [[ 0.69411765  0.68627451  0.7372549 ]\n",
      "   [ 0.69411765  0.68627451  0.7372549 ]\n",
      "   [ 0.69803922  0.69019608  0.74117647]\n",
      "   ..., \n",
      "   [ 0.67058824  0.6627451   0.70588235]\n",
      "   [ 0.6627451   0.65490196  0.69803922]\n",
      "   [ 0.65490196  0.64705882  0.69019608]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.43921569  0.41960784  0.41960784]\n",
      "   [ 0.44313725  0.42745098  0.42352941]\n",
      "   [ 0.44705882  0.43137255  0.43137255]\n",
      "   ..., \n",
      "   [ 0.39215686  0.38039216  0.36862745]\n",
      "   [ 0.38431373  0.36862745  0.36470588]\n",
      "   [ 0.39607843  0.37254902  0.37254902]]\n",
      "\n",
      "  [[ 0.43921569  0.4         0.39607843]\n",
      "   [ 0.43921569  0.40392157  0.4       ]\n",
      "   [ 0.44313725  0.40392157  0.40392157]\n",
      "   ..., \n",
      "   [ 0.4         0.37254902  0.36470588]\n",
      "   [ 0.4         0.36470588  0.35686275]\n",
      "   [ 0.4         0.36078431  0.35686275]]\n",
      "\n",
      "  [[ 0.40392157  0.37647059  0.36078431]\n",
      "   [ 0.39215686  0.36470588  0.35294118]\n",
      "   [ 0.40392157  0.37254902  0.36862745]\n",
      "   ..., \n",
      "   [ 0.36078431  0.32941176  0.31372549]\n",
      "   [ 0.36470588  0.3372549   0.31372549]\n",
      "   [ 0.35686275  0.32941176  0.30196078]]]\n",
      "\n",
      "\n",
      " [[[ 0.11372549  0.16862745  0.03921569]\n",
      "   [ 0.08627451  0.14117647  0.01568627]\n",
      "   [ 0.09803922  0.14509804  0.0627451 ]\n",
      "   ..., \n",
      "   [ 0.77254902  0.85882353  0.5372549 ]\n",
      "   [ 0.77647059  0.85882353  0.5372549 ]\n",
      "   [ 0.78039216  0.87058824  0.54901961]]\n",
      "\n",
      "  [[ 0.12156863  0.18039216  0.03529412]\n",
      "   [ 0.10588235  0.16078431  0.02352941]\n",
      "   [ 0.06666667  0.11372549  0.02352941]\n",
      "   ..., \n",
      "   [ 0.82352941  0.90980392  0.58039216]\n",
      "   [ 0.81960784  0.90588235  0.58039216]\n",
      "   [ 0.81960784  0.90588235  0.58039216]]\n",
      "\n",
      "  [[ 0.15686275  0.21568627  0.0627451 ]\n",
      "   [ 0.12156863  0.17647059  0.03137255]\n",
      "   [ 0.07843137  0.12941176  0.02745098]\n",
      "   ..., \n",
      "   [ 0.82352941  0.90980392  0.58823529]\n",
      "   [ 0.82352941  0.90980392  0.58431373]\n",
      "   [ 0.82352941  0.90980392  0.58431373]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.17647059  0.14901961  0.09019608]\n",
      "   [ 0.09411765  0.08235294  0.04313725]\n",
      "   [ 0.0627451   0.05490196  0.02745098]\n",
      "   ..., \n",
      "   [ 0.09803922  0.11372549  0.1254902 ]\n",
      "   [ 0.09411765  0.10980392  0.12156863]\n",
      "   [ 0.09411765  0.10980392  0.12156863]]\n",
      "\n",
      "  [[ 0.08235294  0.07058824  0.02745098]\n",
      "   [ 0.07058824  0.05098039  0.01176471]\n",
      "   [ 0.10588235  0.0627451   0.01960784]\n",
      "   ..., \n",
      "   [ 0.10196078  0.11764706  0.12941176]\n",
      "   [ 0.11372549  0.12941176  0.14117647]\n",
      "   [ 0.10980392  0.1254902   0.1372549 ]]\n",
      "\n",
      "  [[ 0.20784314  0.15686275  0.09019608]\n",
      "   [ 0.31764706  0.24313725  0.14901961]\n",
      "   [ 0.38039216  0.2745098   0.16862745]\n",
      "   ..., \n",
      "   [ 0.08627451  0.10196078  0.11372549]\n",
      "   [ 0.09411765  0.10980392  0.12156863]\n",
      "   [ 0.09019608  0.10588235  0.11764706]]]\n",
      "\n",
      "\n",
      " [[[ 0.14117647  0.25490196  0.4       ]\n",
      "   [ 0.12941176  0.21568627  0.42352941]\n",
      "   [ 0.08235294  0.18431373  0.4627451 ]\n",
      "   ..., \n",
      "   [ 0.10196078  0.1254902   0.15686275]\n",
      "   [ 0.10196078  0.12156863  0.12156863]\n",
      "   [ 0.11372549  0.11372549  0.12156863]]\n",
      "\n",
      "  [[ 0.21568627  0.41960784  0.47058824]\n",
      "   [ 0.18431373  0.36862745  0.42352941]\n",
      "   [ 0.05882353  0.24705882  0.44313725]\n",
      "   ..., \n",
      "   [ 0.08627451  0.2         0.41176471]\n",
      "   [ 0.09019608  0.19215686  0.39215686]\n",
      "   [ 0.08235294  0.18039216  0.38039216]]\n",
      "\n",
      "  [[ 0.32156863  0.45490196  0.44705882]\n",
      "   [ 0.36862745  0.49803922  0.4       ]\n",
      "   [ 0.30980392  0.45882353  0.42352941]\n",
      "   ..., \n",
      "   [ 0.18431373  0.3254902   0.6       ]\n",
      "   [ 0.18431373  0.3372549   0.61176471]\n",
      "   [ 0.17647059  0.33333333  0.6       ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.62352941  0.62745098  0.58039216]\n",
      "   [ 0.63529412  0.62352941  0.58431373]\n",
      "   [ 0.65098039  0.62745098  0.59215686]\n",
      "   ..., \n",
      "   [ 0.73333333  0.70588235  0.69411765]\n",
      "   [ 0.7254902   0.69019608  0.68235294]\n",
      "   [ 0.71764706  0.68235294  0.6745098 ]]\n",
      "\n",
      "  [[ 0.65098039  0.6627451   0.62745098]\n",
      "   [ 0.66666667  0.6627451   0.63137255]\n",
      "   [ 0.67843137  0.6627451   0.63529412]\n",
      "   ..., \n",
      "   [ 0.71764706  0.69019608  0.68235294]\n",
      "   [ 0.70980392  0.67843137  0.67058824]\n",
      "   [ 0.70588235  0.6745098   0.67058824]]\n",
      "\n",
      "  [[ 0.65882353  0.68235294  0.65098039]\n",
      "   [ 0.67058824  0.67843137  0.65490196]\n",
      "   [ 0.68627451  0.67843137  0.65882353]\n",
      "   ..., \n",
      "   [ 0.71372549  0.69019608  0.67843137]\n",
      "   [ 0.70980392  0.6745098   0.66666667]\n",
      "   [ 0.70588235  0.6745098   0.66666667]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.27058824  0.34509804  0.44705882]\n",
      "   [ 0.35294118  0.4745098   0.58823529]\n",
      "   [ 0.35294118  0.49803922  0.61960784]\n",
      "   ..., \n",
      "   [ 0.00784314  0.01176471  0.07058824]\n",
      "   [ 0.00784314  0.00784314  0.0627451 ]\n",
      "   [ 0.00784314  0.00784314  0.05882353]]\n",
      "\n",
      "  [[ 0.11372549  0.15294118  0.25098039]\n",
      "   [ 0.05882353  0.10588235  0.20784314]\n",
      "   [ 0.05098039  0.09803922  0.2       ]\n",
      "   ..., \n",
      "   [ 0.00392157  0.          0.00784314]\n",
      "   [ 0.          0.          0.00392157]\n",
      "   [ 0.          0.00392157  0.00784314]]\n",
      "\n",
      "  [[ 0.01568627  0.01176471  0.01960784]\n",
      "   [ 0.01568627  0.00392157  0.00784314]\n",
      "   [ 0.01176471  0.00392157  0.00784314]\n",
      "   ..., \n",
      "   [ 0.          0.          0.00392157]\n",
      "   [ 0.          0.          0.00784314]\n",
      "   [ 0.          0.          0.01176471]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.00392157  0.00392157  0.01960784]\n",
      "   [ 0.          0.          0.00392157]\n",
      "   [ 0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.03921569  0.03137255  0.04313725]\n",
      "   [ 0.00784314  0.00784314  0.01568627]\n",
      "   [ 0.00392157  0.00392157  0.01568627]]\n",
      "\n",
      "  [[ 0.03137255  0.0627451   0.12941176]\n",
      "   [ 0.00392157  0.01568627  0.05098039]\n",
      "   [ 0.          0.00392157  0.01176471]\n",
      "   ..., \n",
      "   [ 0.02745098  0.03921569  0.09019608]\n",
      "   [ 0.01176471  0.01568627  0.03921569]\n",
      "   [ 0.00392157  0.00392157  0.01176471]]\n",
      "\n",
      "  [[ 0.14509804  0.25098039  0.42352941]\n",
      "   [ 0.09411765  0.16862745  0.30196078]\n",
      "   [ 0.03921569  0.0745098   0.15294118]\n",
      "   ..., \n",
      "   [ 0.07843137  0.11764706  0.23921569]\n",
      "   [ 0.05098039  0.07843137  0.16862745]\n",
      "   [ 0.02352941  0.03921569  0.09019608]]]\n",
      "\n",
      "\n",
      " [[[ 0.7254902   0.79215686  0.81176471]\n",
      "   [ 0.67843137  0.77647059  0.80392157]\n",
      "   [ 0.69019608  0.81176471  0.85098039]\n",
      "   ..., \n",
      "   [ 0.14509804  0.17647059  0.24313725]\n",
      "   [ 0.10196078  0.1372549   0.2       ]\n",
      "   [ 0.12941176  0.19607843  0.27058824]]\n",
      "\n",
      "  [[ 0.42745098  0.47058824  0.46666667]\n",
      "   [ 0.4627451   0.52941176  0.52941176]\n",
      "   [ 0.4745098   0.56078431  0.56470588]\n",
      "   ..., \n",
      "   [ 0.16862745  0.19607843  0.23529412]\n",
      "   [ 0.12941176  0.13333333  0.16862745]\n",
      "   [ 0.15686275  0.18823529  0.22745098]]\n",
      "\n",
      "  [[ 0.20392157  0.22745098  0.21568627]\n",
      "   [ 0.22745098  0.26666667  0.25098039]\n",
      "   [ 0.22745098  0.28235294  0.2627451 ]\n",
      "   ..., \n",
      "   [ 0.18039216  0.22745098  0.26666667]\n",
      "   [ 0.15686275  0.18431373  0.22745098]\n",
      "   [ 0.18431373  0.22745098  0.26666667]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.63529412  0.62745098  0.6745098 ]\n",
      "   [ 0.61960784  0.61176471  0.65490196]\n",
      "   [ 0.62352941  0.61568627  0.65882353]\n",
      "   ..., \n",
      "   [ 0.05882353  0.05098039  0.09019608]\n",
      "   [ 0.05490196  0.04705882  0.09019608]\n",
      "   [ 0.07058824  0.0627451   0.10588235]]\n",
      "\n",
      "  [[ 0.61176471  0.60392157  0.65882353]\n",
      "   [ 0.59607843  0.58823529  0.63921569]\n",
      "   [ 0.59607843  0.58823529  0.63921569]\n",
      "   ..., \n",
      "   [ 0.05098039  0.04313725  0.08235294]\n",
      "   [ 0.05882353  0.05098039  0.09411765]\n",
      "   [ 0.1254902   0.11764706  0.16078431]]\n",
      "\n",
      "  [[ 0.58431373  0.57647059  0.63137255]\n",
      "   [ 0.56470588  0.55686275  0.61176471]\n",
      "   [ 0.57254902  0.56470588  0.61960784]\n",
      "   ..., \n",
      "   [ 0.0627451   0.05490196  0.09411765]\n",
      "   [ 0.20392157  0.19607843  0.23921569]\n",
      "   [ 0.38431373  0.37647059  0.41960784]]]\n",
      "\n",
      "\n",
      " [[[ 0.76470588  0.71764706  0.67058824]\n",
      "   [ 0.75686275  0.70980392  0.6627451 ]\n",
      "   [ 0.76078431  0.71372549  0.66666667]\n",
      "   ..., \n",
      "   [ 0.22352941  0.22352941  0.22352941]\n",
      "   [ 0.20392157  0.20392157  0.20392157]\n",
      "   [ 0.03137255  0.03137255  0.03137255]]\n",
      "\n",
      "  [[ 0.77254902  0.72156863  0.67843137]\n",
      "   [ 0.76470588  0.71764706  0.6745098 ]\n",
      "   [ 0.77254902  0.7254902   0.68235294]\n",
      "   ..., \n",
      "   [ 0.34117647  0.34117647  0.34117647]\n",
      "   [ 0.31372549  0.31372549  0.31372549]\n",
      "   [ 0.03921569  0.03921569  0.03921569]]\n",
      "\n",
      "  [[ 0.77254902  0.72156863  0.68627451]\n",
      "   [ 0.76862745  0.71764706  0.68235294]\n",
      "   [ 0.77647059  0.7254902   0.69411765]\n",
      "   ..., \n",
      "   [ 0.43137255  0.43137255  0.43137255]\n",
      "   [ 0.41568627  0.41568627  0.41568627]\n",
      "   [ 0.04705882  0.04705882  0.04705882]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.78039216  0.7254902   0.69411765]\n",
      "   [ 0.76862745  0.72156863  0.68627451]\n",
      "   [ 0.78039216  0.74117647  0.69803922]\n",
      "   ..., \n",
      "   [ 0.13333333  0.10980392  0.08235294]\n",
      "   [ 0.10980392  0.09019608  0.07058824]\n",
      "   [ 0.08627451  0.0745098   0.0627451 ]]\n",
      "\n",
      "  [[ 0.77254902  0.7254902   0.69019608]\n",
      "   [ 0.76470588  0.71764706  0.68235294]\n",
      "   [ 0.77254902  0.72941176  0.69411765]\n",
      "   ..., \n",
      "   [ 0.15294118  0.12156863  0.08235294]\n",
      "   [ 0.14509804  0.12156863  0.08627451]\n",
      "   [ 0.1372549   0.11372549  0.08627451]]\n",
      "\n",
      "  [[ 0.75686275  0.71764706  0.68235294]\n",
      "   [ 0.75686275  0.70588235  0.6745098 ]\n",
      "   [ 0.76470588  0.70980392  0.67843137]\n",
      "   ..., \n",
      "   [ 0.16470588  0.12941176  0.08235294]\n",
      "   [ 0.16862745  0.12941176  0.09019608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [ 0.16078431  0.1254902   0.09411765]]]]\n",
      "[[ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[[[ 1.          1.          0.99607843]\n",
      "   [ 0.98823529  0.98823529  0.98823529]\n",
      "   [ 0.99215686  0.98823529  0.99607843]\n",
      "   ..., \n",
      "   [ 0.64705882  0.69411765  0.72156863]\n",
      "   [ 0.95294118  0.96470588  0.96862745]\n",
      "   [ 0.99607843  0.99215686  0.98823529]]\n",
      "\n",
      "  [[ 1.          1.          0.99607843]\n",
      "   [ 0.98823529  0.98823529  0.98823529]\n",
      "   [ 0.99607843  0.99607843  1.        ]\n",
      "   ..., \n",
      "   [ 0.50980392  0.56470588  0.63137255]\n",
      "   [ 0.88235294  0.90980392  0.9372549 ]\n",
      "   [ 0.99215686  1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 0.99607843  0.99607843  0.99607843]\n",
      "   [ 0.97254902  0.96862745  0.97647059]\n",
      "   ..., \n",
      "   [ 0.55294118  0.60784314  0.68627451]\n",
      "   [ 0.8627451   0.89019608  0.92156863]\n",
      "   [ 0.99215686  1.          1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.91372549  0.91764706  0.91764706]\n",
      "   [ 0.84705882  0.84705882  0.84705882]\n",
      "   [ 0.94509804  0.94509804  0.94509804]\n",
      "   ..., \n",
      "   [ 0.03529412  0.04313725  0.04313725]\n",
      "   [ 0.07058824  0.0745098   0.0745098 ]\n",
      "   [ 0.6627451   0.67058824  0.66666667]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.08235294  0.09019608  0.08627451]\n",
      "   [ 0.44313725  0.45098039  0.44705882]\n",
      "   [ 0.92156863  0.92941176  0.9254902 ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 0.98431373  0.98431373  0.98431373]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.6745098   0.68235294  0.67843137]\n",
      "   [ 0.90196078  0.90980392  0.90588235]\n",
      "   [ 0.96862745  0.97254902  0.97254902]]]\n",
      "\n",
      "\n",
      " [[[ 0.49803922  0.56862745  0.65490196]\n",
      "   [ 0.49411765  0.56470588  0.65098039]\n",
      "   [ 0.49803922  0.56862745  0.65490196]\n",
      "   ..., \n",
      "   [ 0.49019608  0.55686275  0.62352941]\n",
      "   [ 0.49019608  0.55686275  0.62352941]\n",
      "   [ 0.48627451  0.55294118  0.61960784]]\n",
      "\n",
      "  [[ 0.49019608  0.56078431  0.64313725]\n",
      "   [ 0.49019608  0.56078431  0.63921569]\n",
      "   [ 0.49411765  0.56470588  0.64313725]\n",
      "   ..., \n",
      "   [ 0.49019608  0.55686275  0.61568627]\n",
      "   [ 0.48627451  0.55686275  0.61176471]\n",
      "   [ 0.48627451  0.55294118  0.61176471]]\n",
      "\n",
      "  [[ 0.49411765  0.56862745  0.63529412]\n",
      "   [ 0.48627451  0.56078431  0.62745098]\n",
      "   [ 0.49411765  0.56862745  0.63529412]\n",
      "   ..., \n",
      "   [ 0.48627451  0.56078431  0.61176471]\n",
      "   [ 0.48235294  0.55294118  0.60784314]\n",
      "   [ 0.48235294  0.55294118  0.60784314]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.32941176  0.40784314  0.4627451 ]\n",
      "   [ 0.33333333  0.40784314  0.4627451 ]\n",
      "   [ 0.34117647  0.41568627  0.47058824]\n",
      "   ..., \n",
      "   [ 0.25490196  0.3254902   0.37254902]\n",
      "   [ 0.30980392  0.38039216  0.42745098]\n",
      "   [ 0.34509804  0.41568627  0.4627451 ]]\n",
      "\n",
      "  [[ 0.3372549   0.41176471  0.47058824]\n",
      "   [ 0.3254902   0.4         0.45490196]\n",
      "   [ 0.3254902   0.4         0.45490196]\n",
      "   ..., \n",
      "   [ 0.28627451  0.35686275  0.40392157]\n",
      "   [ 0.3254902   0.39607843  0.44313725]\n",
      "   [ 0.34117647  0.41176471  0.45882353]]\n",
      "\n",
      "  [[ 0.33333333  0.40784314  0.4627451 ]\n",
      "   [ 0.33333333  0.40392157  0.45882353]\n",
      "   [ 0.3254902   0.4         0.45490196]\n",
      "   ..., \n",
      "   [ 0.28235294  0.35294118  0.4       ]\n",
      "   [ 0.30588235  0.37647059  0.42352941]\n",
      "   [ 0.32156863  0.39215686  0.43921569]]]\n",
      "\n",
      "\n",
      " [[[ 0.45490196  0.27843137  0.10196078]\n",
      "   [ 0.25098039  0.13333333  0.03921569]\n",
      "   [ 0.0745098   0.02352941  0.00784314]\n",
      "   ..., \n",
      "   [ 0.58039216  0.32941176  0.14901961]\n",
      "   [ 0.6627451   0.37647059  0.18039216]\n",
      "   [ 0.7372549   0.44705882  0.23137255]]\n",
      "\n",
      "  [[ 0.44705882  0.26666667  0.08627451]\n",
      "   [ 0.25098039  0.1372549   0.04313725]\n",
      "   [ 0.07058824  0.02352941  0.00784314]\n",
      "   ..., \n",
      "   [ 0.58431373  0.32941176  0.16862745]\n",
      "   [ 0.63921569  0.36862745  0.17647059]\n",
      "   [ 0.7254902   0.44705882  0.23137255]]\n",
      "\n",
      "  [[ 0.44705882  0.25882353  0.09019608]\n",
      "   [ 0.24313725  0.13333333  0.04313725]\n",
      "   [ 0.06666667  0.02352941  0.00784314]\n",
      "   ..., \n",
      "   [ 0.61568627  0.35294118  0.18431373]\n",
      "   [ 0.68627451  0.4         0.2       ]\n",
      "   [ 0.7254902   0.44705882  0.22745098]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.94509804  0.94117647  0.91764706]\n",
      "   [ 0.95294118  0.94901961  0.9254902 ]\n",
      "   [ 0.94509804  0.94509804  0.9254902 ]\n",
      "   ..., \n",
      "   [ 0.12156863  0.07058824  0.01568627]\n",
      "   [ 0.1372549   0.07843137  0.01960784]\n",
      "   [ 0.15294118  0.07843137  0.01960784]]\n",
      "\n",
      "  [[ 0.84313725  0.82745098  0.78823529]\n",
      "   [ 0.90196078  0.89019608  0.8627451 ]\n",
      "   [ 0.92941176  0.92156863  0.90196078]\n",
      "   ..., \n",
      "   [ 0.09019608  0.05098039  0.01176471]\n",
      "   [ 0.09803922  0.05098039  0.00784314]\n",
      "   [ 0.10196078  0.05098039  0.01176471]]\n",
      "\n",
      "  [[ 0.47058824  0.42352941  0.37254902]\n",
      "   [ 0.54117647  0.49803922  0.45098039]\n",
      "   [ 0.60784314  0.57254902  0.5254902 ]\n",
      "   ..., \n",
      "   [ 0.17254902  0.09803922  0.02745098]\n",
      "   [ 0.16078431  0.08627451  0.02352941]\n",
      "   [ 0.14901961  0.0745098   0.01960784]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.23921569  0.28627451  0.29803922]\n",
      "   [ 0.18039216  0.22745098  0.26666667]\n",
      "   [ 0.15294118  0.19215686  0.25882353]\n",
      "   ..., \n",
      "   [ 0.27843137  0.35294118  0.31372549]\n",
      "   [ 0.24313725  0.30588235  0.29411765]\n",
      "   [ 0.17647059  0.22745098  0.23921569]]\n",
      "\n",
      "  [[ 0.24705882  0.29411765  0.30196078]\n",
      "   [ 0.17647059  0.22745098  0.2627451 ]\n",
      "   [ 0.1254902   0.16862745  0.22745098]\n",
      "   ..., \n",
      "   [ 0.28627451  0.34901961  0.32156863]\n",
      "   [ 0.27843137  0.32941176  0.31372549]\n",
      "   [ 0.19607843  0.23529412  0.24313725]]\n",
      "\n",
      "  [[ 0.24705882  0.31372549  0.30196078]\n",
      "   [ 0.22352941  0.29411765  0.29411765]\n",
      "   [ 0.24705882  0.30980392  0.31764706]\n",
      "   ..., \n",
      "   [ 0.32156863  0.37647059  0.35686275]\n",
      "   [ 0.29803922  0.34509804  0.32156863]\n",
      "   [ 0.20784314  0.24705882  0.24313725]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.51372549  0.52156863  0.4       ]\n",
      "   [ 0.61176471  0.60392157  0.4627451 ]\n",
      "   [ 0.63137255  0.61568627  0.4745098 ]\n",
      "   ..., \n",
      "   [ 0.91764706  0.8745098   0.67843137]\n",
      "   [ 0.8627451   0.8         0.61176471]\n",
      "   [ 0.70980392  0.65098039  0.49411765]]\n",
      "\n",
      "  [[ 0.41176471  0.42352941  0.3254902 ]\n",
      "   [ 0.41960784  0.42352941  0.30980392]\n",
      "   [ 0.45098039  0.45098039  0.32941176]\n",
      "   ..., \n",
      "   [ 0.92156863  0.86666667  0.6745098 ]\n",
      "   [ 0.89803922  0.81568627  0.63137255]\n",
      "   [ 0.74901961  0.66666667  0.51372549]]\n",
      "\n",
      "  [[ 0.2627451   0.29019608  0.23921569]\n",
      "   [ 0.30588235  0.3254902   0.26666667]\n",
      "   [ 0.43921569  0.45098039  0.35294118]\n",
      "   ..., \n",
      "   [ 0.89019608  0.80784314  0.58823529]\n",
      "   [ 0.85098039  0.75294118  0.54509804]\n",
      "   [ 0.72156863  0.62745098  0.45882353]]]\n",
      "\n",
      "\n",
      " [[[ 0.03921569  0.01568627  0.05490196]\n",
      "   [ 0.04313725  0.02352941  0.05882353]\n",
      "   [ 0.07843137  0.08627451  0.09019608]\n",
      "   ..., \n",
      "   [ 0.23137255  0.27843137  0.21568627]\n",
      "   [ 0.22352941  0.2745098   0.21568627]\n",
      "   [ 0.20784314  0.26666667  0.23137255]]\n",
      "\n",
      "  [[ 0.03921569  0.01568627  0.05490196]\n",
      "   [ 0.04313725  0.03529412  0.05882353]\n",
      "   [ 0.09803922  0.1254902   0.10980392]\n",
      "   ..., \n",
      "   [ 0.21568627  0.23921569  0.18823529]\n",
      "   [ 0.25882353  0.29803922  0.22745098]\n",
      "   [ 0.18823529  0.24705882  0.21176471]]\n",
      "\n",
      "  [[ 0.04705882  0.02352941  0.0627451 ]\n",
      "   [ 0.04313725  0.03921569  0.05882353]\n",
      "   [ 0.14901961  0.18431373  0.14901961]\n",
      "   ..., \n",
      "   [ 0.18431373  0.20392157  0.16470588]\n",
      "   [ 0.22352941  0.25882353  0.19215686]\n",
      "   [ 0.20392157  0.25098039  0.2       ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.69411765  0.6627451   0.71764706]\n",
      "   [ 0.70588235  0.6627451   0.72156863]\n",
      "   [ 0.72156863  0.6745098   0.74509804]\n",
      "   ..., \n",
      "   [ 0.6745098   0.62352941  0.68235294]\n",
      "   [ 0.66666667  0.61568627  0.67058824]\n",
      "   [ 0.64313725  0.58823529  0.64705882]]\n",
      "\n",
      "  [[ 0.62352941  0.61568627  0.69019608]\n",
      "   [ 0.63529412  0.61568627  0.69411765]\n",
      "   [ 0.65490196  0.63529412  0.71764706]\n",
      "   ..., \n",
      "   [ 0.72156863  0.69803922  0.78431373]\n",
      "   [ 0.70980392  0.68627451  0.77254902]\n",
      "   [ 0.69803922  0.67843137  0.76470588]]\n",
      "\n",
      "  [[ 0.61960784  0.61960784  0.72941176]\n",
      "   [ 0.62352941  0.62352941  0.73333333]\n",
      "   [ 0.63921569  0.63921569  0.74509804]\n",
      "   ..., \n",
      "   [ 0.70980392  0.70588235  0.82745098]\n",
      "   [ 0.70196078  0.69411765  0.81568627]\n",
      "   [ 0.68627451  0.68235294  0.80392157]]]\n",
      "\n",
      "\n",
      " [[[ 0.68627451  0.75686275  0.89803922]\n",
      "   [ 0.6745098   0.75294118  0.9254902 ]\n",
      "   [ 0.67058824  0.75686275  0.94117647]\n",
      "   ..., \n",
      "   [ 0.75686275  0.80784314  0.93333333]\n",
      "   [ 0.76862745  0.80784314  0.90588235]\n",
      "   [ 0.76078431  0.79607843  0.89019608]]\n",
      "\n",
      "  [[ 0.65490196  0.73333333  0.88627451]\n",
      "   [ 0.64313725  0.73333333  0.90196078]\n",
      "   [ 0.64313725  0.7372549   0.90980392]\n",
      "   ..., \n",
      "   [ 0.70196078  0.75686275  0.88235294]\n",
      "   [ 0.69803922  0.74901961  0.85098039]\n",
      "   [ 0.69019608  0.73333333  0.83137255]]\n",
      "\n",
      "  [[ 0.65490196  0.72156863  0.86666667]\n",
      "   [ 0.65490196  0.72941176  0.87058824]\n",
      "   [ 0.67058824  0.72941176  0.85098039]\n",
      "   ..., \n",
      "   [ 0.69019608  0.74901961  0.87843137]\n",
      "   [ 0.68235294  0.74117647  0.85098039]\n",
      "   [ 0.67058824  0.72156863  0.82745098]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.33333333  0.32941176  0.39607843]\n",
      "   [ 0.33333333  0.32156863  0.36470588]\n",
      "   [ 0.36078431  0.32941176  0.32156863]\n",
      "   ..., \n",
      "   [ 0.4745098   0.44313725  0.47058824]\n",
      "   [ 0.41960784  0.40392157  0.46666667]\n",
      "   [ 0.45882353  0.43921569  0.50588235]]\n",
      "\n",
      "  [[ 0.33333333  0.34117647  0.4       ]\n",
      "   [ 0.32941176  0.31764706  0.34901961]\n",
      "   [ 0.34117647  0.30980392  0.30588235]\n",
      "   ..., \n",
      "   [ 0.30196078  0.28235294  0.32941176]\n",
      "   [ 0.43137255  0.40392157  0.47058824]\n",
      "   [ 0.44705882  0.41960784  0.48627451]]\n",
      "\n",
      "  [[ 0.32156863  0.32941176  0.37647059]\n",
      "   [ 0.29411765  0.29019608  0.32156863]\n",
      "   [ 0.22352941  0.19607843  0.21568627]\n",
      "   ..., \n",
      "   [ 0.30196078  0.26666667  0.30588235]\n",
      "   [ 0.35686275  0.30588235  0.35294118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [ 0.35686275  0.30588235  0.35294118]]]]\n",
      "[[ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[[[ 0.54901961  0.49019608  0.45098039]\n",
      "   [ 0.57254902  0.50980392  0.47843137]\n",
      "   [ 0.56078431  0.49803922  0.47843137]\n",
      "   ..., \n",
      "   [ 0.66666667  0.56862745  0.51372549]\n",
      "   [ 0.69019608  0.58823529  0.5254902 ]\n",
      "   [ 0.66666667  0.57647059  0.52156863]]\n",
      "\n",
      "  [[ 0.4745098   0.42352941  0.50588235]\n",
      "   [ 0.50980392  0.4627451   0.54509804]\n",
      "   [ 0.5254902   0.4745098   0.56078431]\n",
      "   ..., \n",
      "   [ 0.63921569  0.55294118  0.61568627]\n",
      "   [ 0.66666667  0.57254902  0.63137255]\n",
      "   [ 0.66666667  0.58039216  0.63137255]]\n",
      "\n",
      "  [[ 0.59607843  0.54509804  0.68235294]\n",
      "   [ 0.61568627  0.56862745  0.70196078]\n",
      "   [ 0.60784314  0.56078431  0.68627451]\n",
      "   ..., \n",
      "   [ 0.69411765  0.60392157  0.75686275]\n",
      "   [ 0.70980392  0.61176471  0.76078431]\n",
      "   [ 0.71764706  0.62745098  0.76078431]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.49019608  0.43137255  0.4       ]\n",
      "   [ 0.50588235  0.43921569  0.40392157]\n",
      "   [ 0.29803922  0.2627451   0.18431373]\n",
      "   ..., \n",
      "   [ 0.65882353  0.5372549   0.47058824]\n",
      "   [ 0.61960784  0.49411765  0.40392157]\n",
      "   [ 0.57254902  0.45490196  0.34117647]]\n",
      "\n",
      "  [[ 0.33333333  0.30196078  0.2745098 ]\n",
      "   [ 0.36862745  0.31764706  0.27843137]\n",
      "   [ 0.29019608  0.25490196  0.17647059]\n",
      "   ..., \n",
      "   [ 0.63529412  0.51764706  0.41568627]\n",
      "   [ 0.65098039  0.5254902   0.39215686]\n",
      "   [ 0.61960784  0.50196078  0.36078431]]\n",
      "\n",
      "  [[ 0.49019608  0.43921569  0.43529412]\n",
      "   [ 0.50980392  0.44313725  0.43529412]\n",
      "   [ 0.41176471  0.35686275  0.29411765]\n",
      "   ..., \n",
      "   [ 0.51764706  0.41568627  0.30588235]\n",
      "   [ 0.50980392  0.39607843  0.25098039]\n",
      "   [ 0.55686275  0.45098039  0.30588235]]]\n",
      "\n",
      "\n",
      " [[[ 0.39215686  0.42745098  0.32941176]\n",
      "   [ 0.47843137  0.49411765  0.42745098]\n",
      "   [ 0.34117647  0.34117647  0.29803922]\n",
      "   ..., \n",
      "   [ 0.29411765  0.30588235  0.27058824]\n",
      "   [ 0.2745098   0.28627451  0.25098039]\n",
      "   [ 0.2745098   0.28627451  0.25098039]]\n",
      "\n",
      "  [[ 0.3372549   0.38823529  0.27843137]\n",
      "   [ 0.29803922  0.32941176  0.25882353]\n",
      "   [ 0.23529412  0.25098039  0.21176471]\n",
      "   ..., \n",
      "   [ 0.30588235  0.31764706  0.28235294]\n",
      "   [ 0.29803922  0.30980392  0.2745098 ]\n",
      "   [ 0.32156863  0.33333333  0.29803922]]\n",
      "\n",
      "  [[ 0.32941176  0.39215686  0.28627451]\n",
      "   [ 0.3254902   0.37254902  0.29411765]\n",
      "   [ 0.30196078  0.3372549   0.28235294]\n",
      "   ..., \n",
      "   [ 0.29019608  0.30196078  0.26666667]\n",
      "   [ 0.28627451  0.29803922  0.2627451 ]\n",
      "   [ 0.3254902   0.3372549   0.30196078]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.25098039  0.30196078  0.30980392]\n",
      "   [ 0.47843137  0.52156863  0.56470588]\n",
      "   [ 0.5254902   0.56862745  0.61176471]\n",
      "   ..., \n",
      "   [ 0.41176471  0.48235294  0.47058824]\n",
      "   [ 0.32941176  0.40392157  0.35686275]\n",
      "   [ 0.23529412  0.34509804  0.24705882]]\n",
      "\n",
      "  [[ 0.17254902  0.2         0.21960784]\n",
      "   [ 0.30588235  0.32941176  0.36862745]\n",
      "   [ 0.37647059  0.39607843  0.43137255]\n",
      "   ..., \n",
      "   [ 0.57647059  0.64705882  0.69803922]\n",
      "   [ 0.49411765  0.56078431  0.58431373]\n",
      "   [ 0.36862745  0.45882353  0.44313725]]\n",
      "\n",
      "  [[ 0.14117647  0.1372549   0.15294118]\n",
      "   [ 0.23137255  0.22745098  0.25882353]\n",
      "   [ 0.32156863  0.31764706  0.33333333]\n",
      "   ..., \n",
      "   [ 0.5254902   0.6         0.62745098]\n",
      "   [ 0.54117647  0.59607843  0.61960784]\n",
      "   [ 0.50980392  0.58039216  0.58823529]]]\n",
      "\n",
      "\n",
      " [[[ 0.0745098   0.1254902   0.05882353]\n",
      "   [ 0.08235294  0.14901961  0.08235294]\n",
      "   [ 0.10588235  0.19215686  0.1254902 ]\n",
      "   ..., \n",
      "   [ 0.29411765  0.48627451  0.51372549]\n",
      "   [ 0.29803922  0.48627451  0.50980392]\n",
      "   [ 0.27843137  0.4627451   0.48627451]]\n",
      "\n",
      "  [[ 0.09019608  0.12156863  0.05490196]\n",
      "   [ 0.08235294  0.11764706  0.04705882]\n",
      "   [ 0.09019608  0.1372549   0.05490196]\n",
      "   ..., \n",
      "   [ 0.28235294  0.4627451   0.49411765]\n",
      "   [ 0.29411765  0.46666667  0.48627451]\n",
      "   [ 0.26666667  0.43529412  0.44705882]]\n",
      "\n",
      "  [[ 0.09411765  0.14509804  0.06666667]\n",
      "   [ 0.08627451  0.1372549   0.0627451 ]\n",
      "   [ 0.09411765  0.14117647  0.07058824]\n",
      "   ..., \n",
      "   [ 0.25098039  0.42745098  0.43921569]\n",
      "   [ 0.2627451   0.42745098  0.43529412]\n",
      "   [ 0.25098039  0.41176471  0.41176471]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.24313725  0.18039216  0.09019608]\n",
      "   [ 0.23529412  0.18039216  0.10588235]\n",
      "   [ 0.21568627  0.18823529  0.10980392]\n",
      "   ..., \n",
      "   [ 0.05098039  0.02352941  0.01568627]\n",
      "   [ 0.04705882  0.05490196  0.03137255]\n",
      "   [ 0.09803922  0.15686275  0.11764706]]\n",
      "\n",
      "  [[ 0.24705882  0.20784314  0.11764706]\n",
      "   [ 0.19215686  0.17647059  0.08627451]\n",
      "   [ 0.17647059  0.18039216  0.09019608]\n",
      "   ..., \n",
      "   [ 0.11372549  0.1372549   0.12156863]\n",
      "   [ 0.11764706  0.16470588  0.14509804]\n",
      "   [ 0.10588235  0.19607843  0.16862745]]\n",
      "\n",
      "  [[ 0.27058824  0.20392157  0.11372549]\n",
      "   [ 0.19215686  0.14901961  0.07843137]\n",
      "   [ 0.21176471  0.18039216  0.10588235]\n",
      "   ..., \n",
      "   [ 0.25882353  0.34509804  0.33333333]\n",
      "   [ 0.15686275  0.26666667  0.25098039]\n",
      "   [ 0.11372549  0.24313725  0.22745098]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.1372549   0.69803922  0.92156863]\n",
      "   [ 0.15686275  0.69019608  0.9372549 ]\n",
      "   [ 0.16470588  0.69019608  0.94509804]\n",
      "   ..., \n",
      "   [ 0.38823529  0.69411765  0.85882353]\n",
      "   [ 0.30980392  0.57647059  0.77254902]\n",
      "   [ 0.34901961  0.58039216  0.74117647]]\n",
      "\n",
      "  [[ 0.22352941  0.71372549  0.91764706]\n",
      "   [ 0.17254902  0.72156863  0.98039216]\n",
      "   [ 0.19607843  0.71764706  0.94117647]\n",
      "   ..., \n",
      "   [ 0.61176471  0.71372549  0.78431373]\n",
      "   [ 0.55294118  0.69411765  0.80784314]\n",
      "   [ 0.45490196  0.58431373  0.68627451]]\n",
      "\n",
      "  [[ 0.38431373  0.77254902  0.92941176]\n",
      "   [ 0.25098039  0.74117647  0.98823529]\n",
      "   [ 0.27058824  0.75294118  0.96078431]\n",
      "   ..., \n",
      "   [ 0.7372549   0.76470588  0.80784314]\n",
      "   [ 0.46666667  0.52941176  0.57647059]\n",
      "   [ 0.23921569  0.30980392  0.35294118]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.28627451  0.30980392  0.30196078]\n",
      "   [ 0.20784314  0.24705882  0.26666667]\n",
      "   [ 0.21176471  0.26666667  0.31372549]\n",
      "   ..., \n",
      "   [ 0.06666667  0.15686275  0.25098039]\n",
      "   [ 0.08235294  0.14117647  0.2       ]\n",
      "   [ 0.12941176  0.18823529  0.19215686]]\n",
      "\n",
      "  [[ 0.23921569  0.26666667  0.29411765]\n",
      "   [ 0.21568627  0.2745098   0.3372549 ]\n",
      "   [ 0.22352941  0.30980392  0.40392157]\n",
      "   ..., \n",
      "   [ 0.09411765  0.18823529  0.28235294]\n",
      "   [ 0.06666667  0.1372549   0.20784314]\n",
      "   [ 0.02745098  0.09019608  0.1254902 ]]\n",
      "\n",
      "  [[ 0.17254902  0.21960784  0.28627451]\n",
      "   [ 0.18039216  0.25882353  0.34509804]\n",
      "   [ 0.19215686  0.30196078  0.41176471]\n",
      "   ..., \n",
      "   [ 0.10588235  0.20392157  0.30196078]\n",
      "   [ 0.08235294  0.16862745  0.25882353]\n",
      "   [ 0.04705882  0.12156863  0.19607843]]]\n",
      "\n",
      "\n",
      " [[[ 0.74117647  0.82745098  0.94117647]\n",
      "   [ 0.72941176  0.81568627  0.9254902 ]\n",
      "   [ 0.7254902   0.81176471  0.92156863]\n",
      "   ..., \n",
      "   [ 0.68627451  0.76470588  0.87843137]\n",
      "   [ 0.6745098   0.76078431  0.87058824]\n",
      "   [ 0.6627451   0.76078431  0.8627451 ]]\n",
      "\n",
      "  [[ 0.76078431  0.82352941  0.9372549 ]\n",
      "   [ 0.74901961  0.81176471  0.9254902 ]\n",
      "   [ 0.74509804  0.80784314  0.92156863]\n",
      "   ..., \n",
      "   [ 0.67843137  0.75294118  0.8627451 ]\n",
      "   [ 0.67058824  0.74901961  0.85490196]\n",
      "   [ 0.65490196  0.74509804  0.84705882]]\n",
      "\n",
      "  [[ 0.81568627  0.85882353  0.95686275]\n",
      "   [ 0.80392157  0.84705882  0.94117647]\n",
      "   [ 0.8         0.84313725  0.9372549 ]\n",
      "   ..., \n",
      "   [ 0.68627451  0.74901961  0.85098039]\n",
      "   [ 0.6745098   0.74509804  0.84705882]\n",
      "   [ 0.6627451   0.74901961  0.84313725]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.81176471  0.78039216  0.70980392]\n",
      "   [ 0.79607843  0.76470588  0.68627451]\n",
      "   [ 0.79607843  0.76862745  0.67843137]\n",
      "   ..., \n",
      "   [ 0.52941176  0.51764706  0.49803922]\n",
      "   [ 0.63529412  0.61960784  0.58823529]\n",
      "   [ 0.65882353  0.63921569  0.59215686]]\n",
      "\n",
      "  [[ 0.77647059  0.74509804  0.66666667]\n",
      "   [ 0.74117647  0.70980392  0.62352941]\n",
      "   [ 0.70588235  0.6745098   0.57647059]\n",
      "   ..., \n",
      "   [ 0.69803922  0.67058824  0.62745098]\n",
      "   [ 0.68627451  0.6627451   0.61176471]\n",
      "   [ 0.68627451  0.6627451   0.60392157]]\n",
      "\n",
      "  [[ 0.77647059  0.74117647  0.67843137]\n",
      "   [ 0.74117647  0.70980392  0.63529412]\n",
      "   [ 0.69803922  0.66666667  0.58431373]\n",
      "   ..., \n",
      "   [ 0.76470588  0.72156863  0.6627451 ]\n",
      "   [ 0.76862745  0.74117647  0.67058824]\n",
      "   [ 0.76470588  0.74509804  0.67058824]]]\n",
      "\n",
      "\n",
      " [[[ 0.89803922  0.89803922  0.9372549 ]\n",
      "   [ 0.9254902   0.92941176  0.96862745]\n",
      "   [ 0.91764706  0.9254902   0.96862745]\n",
      "   ..., \n",
      "   [ 0.85098039  0.85882353  0.91372549]\n",
      "   [ 0.86666667  0.8745098   0.91764706]\n",
      "   [ 0.87058824  0.8745098   0.91372549]]\n",
      "\n",
      "  [[ 0.87058824  0.86666667  0.89803922]\n",
      "   [ 0.9372549   0.9372549   0.97647059]\n",
      "   [ 0.91372549  0.91764706  0.96470588]\n",
      "   ..., \n",
      "   [ 0.8745098   0.8745098   0.9254902 ]\n",
      "   [ 0.89019608  0.89411765  0.93333333]\n",
      "   [ 0.82352941  0.82745098  0.8627451 ]]\n",
      "\n",
      "  [[ 0.83529412  0.80784314  0.82745098]\n",
      "   [ 0.91764706  0.90980392  0.9372549 ]\n",
      "   [ 0.90588235  0.91372549  0.95686275]\n",
      "   ..., \n",
      "   [ 0.8627451   0.8627451   0.90980392]\n",
      "   [ 0.8627451   0.85882353  0.90980392]\n",
      "   [ 0.79215686  0.79607843  0.84313725]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.58823529  0.56078431  0.52941176]\n",
      "   [ 0.54901961  0.52941176  0.49803922]\n",
      "   [ 0.51764706  0.49803922  0.47058824]\n",
      "   ..., \n",
      "   [ 0.87843137  0.87058824  0.85490196]\n",
      "   [ 0.90196078  0.89411765  0.88235294]\n",
      "   [ 0.94509804  0.94509804  0.93333333]]\n",
      "\n",
      "  [[ 0.5372549   0.51764706  0.49411765]\n",
      "   [ 0.50980392  0.49803922  0.47058824]\n",
      "   [ 0.49019608  0.4745098   0.45098039]\n",
      "   ..., \n",
      "   [ 0.70980392  0.70588235  0.69803922]\n",
      "   [ 0.79215686  0.78823529  0.77647059]\n",
      "   [ 0.83137255  0.82745098  0.81176471]]\n",
      "\n",
      "  [[ 0.47843137  0.46666667  0.44705882]\n",
      "   [ 0.4627451   0.45490196  0.43137255]\n",
      "   [ 0.47058824  0.45490196  0.43529412]\n",
      "   ..., \n",
      "   [ 0.70196078  0.69411765  0.67843137]\n",
      "   [ 0.64313725  0.64313725  0.63529412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [ 0.63921569  0.63921569  0.63137255]]]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]]\n",
      "[[[[ 0.61960784  0.43921569  0.19215686]\n",
      "   [ 0.62352941  0.43529412  0.18431373]\n",
      "   [ 0.64705882  0.45490196  0.2       ]\n",
      "   ..., \n",
      "   [ 0.5372549   0.37254902  0.14117647]\n",
      "   [ 0.49411765  0.35686275  0.14117647]\n",
      "   [ 0.45490196  0.33333333  0.12941176]]\n",
      "\n",
      "  [[ 0.59607843  0.43921569  0.2       ]\n",
      "   [ 0.59215686  0.43137255  0.15686275]\n",
      "   [ 0.62352941  0.44705882  0.17647059]\n",
      "   ..., \n",
      "   [ 0.53333333  0.37254902  0.12156863]\n",
      "   [ 0.49019608  0.35686275  0.1254902 ]\n",
      "   [ 0.46666667  0.34509804  0.13333333]]\n",
      "\n",
      "  [[ 0.59215686  0.43137255  0.18431373]\n",
      "   [ 0.59215686  0.42745098  0.12941176]\n",
      "   [ 0.61960784  0.43529412  0.14117647]\n",
      "   ..., \n",
      "   [ 0.54509804  0.38431373  0.13333333]\n",
      "   [ 0.50980392  0.37254902  0.13333333]\n",
      "   [ 0.47058824  0.34901961  0.12941176]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.26666667  0.48627451  0.69411765]\n",
      "   [ 0.16470588  0.39215686  0.58039216]\n",
      "   [ 0.12156863  0.34509804  0.5372549 ]\n",
      "   ..., \n",
      "   [ 0.14901961  0.38039216  0.57254902]\n",
      "   [ 0.05098039  0.25098039  0.42352941]\n",
      "   [ 0.15686275  0.33333333  0.49803922]]\n",
      "\n",
      "  [[ 0.23921569  0.45490196  0.65882353]\n",
      "   [ 0.19215686  0.4         0.58039216]\n",
      "   [ 0.1372549   0.33333333  0.51764706]\n",
      "   ..., \n",
      "   [ 0.10196078  0.32156863  0.50980392]\n",
      "   [ 0.11372549  0.32156863  0.49411765]\n",
      "   [ 0.07843137  0.25098039  0.41960784]]\n",
      "\n",
      "  [[ 0.21176471  0.41960784  0.62745098]\n",
      "   [ 0.21960784  0.41176471  0.58431373]\n",
      "   [ 0.17647059  0.34901961  0.51764706]\n",
      "   ..., \n",
      "   [ 0.09411765  0.30196078  0.48627451]\n",
      "   [ 0.13333333  0.32941176  0.50588235]\n",
      "   [ 0.08235294  0.2627451   0.43137255]]]\n",
      "\n",
      "\n",
      " [[[ 0.92156863  0.92156863  0.92156863]\n",
      "   [ 0.90588235  0.90588235  0.90588235]\n",
      "   [ 0.90980392  0.90980392  0.90980392]\n",
      "   ..., \n",
      "   [ 0.91372549  0.91372549  0.91372549]\n",
      "   [ 0.91372549  0.91372549  0.91372549]\n",
      "   [ 0.90980392  0.90980392  0.90980392]]\n",
      "\n",
      "  [[ 0.93333333  0.93333333  0.93333333]\n",
      "   [ 0.92156863  0.92156863  0.92156863]\n",
      "   [ 0.92156863  0.92156863  0.92156863]\n",
      "   ..., \n",
      "   [ 0.9254902   0.9254902   0.9254902 ]\n",
      "   [ 0.9254902   0.9254902   0.9254902 ]\n",
      "   [ 0.92156863  0.92156863  0.92156863]]\n",
      "\n",
      "  [[ 0.92941176  0.92941176  0.92941176]\n",
      "   [ 0.91764706  0.91764706  0.91764706]\n",
      "   [ 0.91764706  0.91764706  0.91764706]\n",
      "   ..., \n",
      "   [ 0.92156863  0.92156863  0.92156863]\n",
      "   [ 0.92156863  0.92156863  0.92156863]\n",
      "   [ 0.91764706  0.91764706  0.91764706]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.34117647  0.38823529  0.34901961]\n",
      "   [ 0.16862745  0.2         0.14509804]\n",
      "   [ 0.0745098   0.09019608  0.04313725]\n",
      "   ..., \n",
      "   [ 0.6627451   0.72156863  0.70196078]\n",
      "   [ 0.71372549  0.77254902  0.75686275]\n",
      "   [ 0.7372549   0.79215686  0.78823529]]\n",
      "\n",
      "  [[ 0.32156863  0.37647059  0.32156863]\n",
      "   [ 0.18039216  0.22352941  0.14117647]\n",
      "   [ 0.14117647  0.17254902  0.08627451]\n",
      "   ..., \n",
      "   [ 0.68235294  0.74117647  0.71764706]\n",
      "   [ 0.7254902   0.78431373  0.76862745]\n",
      "   [ 0.73333333  0.79215686  0.78431373]]\n",
      "\n",
      "  [[ 0.33333333  0.39607843  0.3254902 ]\n",
      "   [ 0.24313725  0.29411765  0.18823529]\n",
      "   [ 0.22745098  0.2627451   0.14901961]\n",
      "   ..., \n",
      "   [ 0.65882353  0.71764706  0.69803922]\n",
      "   [ 0.70588235  0.76470588  0.74901961]\n",
      "   [ 0.72941176  0.78431373  0.78039216]]]\n",
      "\n",
      "\n",
      " [[[ 0.61960784  0.74509804  0.87058824]\n",
      "   [ 0.61960784  0.73333333  0.85490196]\n",
      "   [ 0.54509804  0.65098039  0.76078431]\n",
      "   ..., \n",
      "   [ 0.89411765  0.90588235  0.91764706]\n",
      "   [ 0.92941176  0.9372549   0.95294118]\n",
      "   [ 0.93333333  0.94509804  0.96470588]]\n",
      "\n",
      "  [[ 0.66666667  0.78431373  0.89803922]\n",
      "   [ 0.6745098   0.78039216  0.88627451]\n",
      "   [ 0.59215686  0.69019608  0.78823529]\n",
      "   ..., \n",
      "   [ 0.90980392  0.90980392  0.9254902 ]\n",
      "   [ 0.96470588  0.96470588  0.98039216]\n",
      "   [ 0.96470588  0.96862745  0.98431373]]\n",
      "\n",
      "  [[ 0.68235294  0.78823529  0.88235294]\n",
      "   [ 0.69019608  0.78431373  0.87058824]\n",
      "   [ 0.61568627  0.70196078  0.78039216]\n",
      "   ..., \n",
      "   [ 0.90196078  0.89803922  0.90980392]\n",
      "   [ 0.98039216  0.97647059  0.98431373]\n",
      "   [ 0.96078431  0.95686275  0.96862745]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.12156863  0.15686275  0.17647059]\n",
      "   [ 0.11764706  0.15294118  0.17254902]\n",
      "   [ 0.10196078  0.1372549   0.15686275]\n",
      "   ..., \n",
      "   [ 0.14509804  0.15686275  0.18039216]\n",
      "   [ 0.03529412  0.05098039  0.05490196]\n",
      "   [ 0.01568627  0.02745098  0.01960784]]\n",
      "\n",
      "  [[ 0.09019608  0.13333333  0.15294118]\n",
      "   [ 0.10588235  0.14901961  0.16862745]\n",
      "   [ 0.09803922  0.14117647  0.16078431]\n",
      "   ..., \n",
      "   [ 0.0745098   0.07843137  0.09411765]\n",
      "   [ 0.01568627  0.02352941  0.01176471]\n",
      "   [ 0.01960784  0.02745098  0.01176471]]\n",
      "\n",
      "  [[ 0.10980392  0.16078431  0.18431373]\n",
      "   [ 0.11764706  0.16862745  0.19607843]\n",
      "   [ 0.1254902   0.17647059  0.20392157]\n",
      "   ..., \n",
      "   [ 0.01960784  0.02352941  0.03137255]\n",
      "   [ 0.01568627  0.01960784  0.01176471]\n",
      "   [ 0.02745098  0.03137255  0.02745098]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.07843137  0.05882353  0.04705882]\n",
      "   [ 0.0745098   0.05490196  0.04313725]\n",
      "   [ 0.05882353  0.05490196  0.04313725]\n",
      "   ..., \n",
      "   [ 0.03921569  0.03529412  0.02745098]\n",
      "   [ 0.04705882  0.04313725  0.03529412]\n",
      "   [ 0.05098039  0.04705882  0.03921569]]\n",
      "\n",
      "  [[ 0.08235294  0.0627451   0.05098039]\n",
      "   [ 0.07843137  0.0627451   0.05098039]\n",
      "   [ 0.07058824  0.06666667  0.04705882]\n",
      "   ..., \n",
      "   [ 0.03921569  0.03529412  0.02745098]\n",
      "   [ 0.03921569  0.03529412  0.02745098]\n",
      "   [ 0.04705882  0.04313725  0.03529412]]\n",
      "\n",
      "  [[ 0.08235294  0.0627451   0.05098039]\n",
      "   [ 0.08235294  0.06666667  0.04705882]\n",
      "   [ 0.07843137  0.07058824  0.04313725]\n",
      "   ..., \n",
      "   [ 0.04705882  0.04313725  0.03529412]\n",
      "   [ 0.04705882  0.04313725  0.03529412]\n",
      "   [ 0.05098039  0.04705882  0.03921569]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.12941176  0.09803922  0.05098039]\n",
      "   [ 0.13333333  0.10196078  0.05882353]\n",
      "   [ 0.13333333  0.10196078  0.05882353]\n",
      "   ..., \n",
      "   [ 0.10980392  0.09803922  0.20392157]\n",
      "   [ 0.11372549  0.09803922  0.22745098]\n",
      "   [ 0.09019608  0.07843137  0.16470588]]\n",
      "\n",
      "  [[ 0.12941176  0.09803922  0.05490196]\n",
      "   [ 0.13333333  0.10196078  0.05882353]\n",
      "   [ 0.13333333  0.10196078  0.05882353]\n",
      "   ..., \n",
      "   [ 0.10588235  0.09411765  0.20392157]\n",
      "   [ 0.10588235  0.09411765  0.21960784]\n",
      "   [ 0.09803922  0.08627451  0.18431373]]\n",
      "\n",
      "  [[ 0.12156863  0.09019608  0.04705882]\n",
      "   [ 0.1254902   0.09411765  0.05098039]\n",
      "   [ 0.12941176  0.09803922  0.05490196]\n",
      "   ..., \n",
      "   [ 0.09411765  0.09019608  0.19607843]\n",
      "   [ 0.10196078  0.09019608  0.20784314]\n",
      "   [ 0.09803922  0.07843137  0.18431373]]]\n",
      "\n",
      "\n",
      " [[[ 0.09803922  0.15686275  0.04705882]\n",
      "   [ 0.05882353  0.14117647  0.01176471]\n",
      "   [ 0.09019608  0.16078431  0.07058824]\n",
      "   ..., \n",
      "   [ 0.23921569  0.32156863  0.30588235]\n",
      "   [ 0.36078431  0.44313725  0.43921569]\n",
      "   [ 0.29411765  0.34901961  0.36078431]]\n",
      "\n",
      "  [[ 0.04705882  0.09803922  0.02352941]\n",
      "   [ 0.07843137  0.14509804  0.02745098]\n",
      "   [ 0.09411765  0.14117647  0.05882353]\n",
      "   ..., \n",
      "   [ 0.45098039  0.5254902   0.54117647]\n",
      "   [ 0.58431373  0.65882353  0.69411765]\n",
      "   [ 0.40784314  0.45882353  0.51372549]]\n",
      "\n",
      "  [[ 0.04705882  0.09803922  0.04313725]\n",
      "   [ 0.05882353  0.11372549  0.02352941]\n",
      "   [ 0.13333333  0.15686275  0.09411765]\n",
      "   ..., \n",
      "   [ 0.60392157  0.6745098   0.71372549]\n",
      "   [ 0.61568627  0.68627451  0.75294118]\n",
      "   [ 0.45490196  0.50588235  0.59215686]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.39215686  0.50588235  0.31764706]\n",
      "   [ 0.40392157  0.51764706  0.32941176]\n",
      "   [ 0.40784314  0.5254902   0.3372549 ]\n",
      "   ..., \n",
      "   [ 0.38039216  0.50196078  0.32941176]\n",
      "   [ 0.38431373  0.49411765  0.32941176]\n",
      "   [ 0.35686275  0.4745098   0.30980392]]\n",
      "\n",
      "  [[ 0.40392157  0.51764706  0.3254902 ]\n",
      "   [ 0.40784314  0.51372549  0.3254902 ]\n",
      "   [ 0.41960784  0.52941176  0.34117647]\n",
      "   ..., \n",
      "   [ 0.39607843  0.51764706  0.34117647]\n",
      "   [ 0.38823529  0.49803922  0.32941176]\n",
      "   [ 0.36078431  0.4745098   0.30980392]]\n",
      "\n",
      "  [[ 0.37254902  0.49411765  0.30588235]\n",
      "   [ 0.37254902  0.48235294  0.29803922]\n",
      "   [ 0.39607843  0.50196078  0.31764706]\n",
      "   ..., \n",
      "   [ 0.36470588  0.48627451  0.31372549]\n",
      "   [ 0.37254902  0.48235294  0.31764706]\n",
      "   [ 0.36078431  0.47058824  0.31372549]]]\n",
      "\n",
      "\n",
      " [[[ 0.28627451  0.30588235  0.29411765]\n",
      "   [ 0.38431373  0.40392157  0.44313725]\n",
      "   [ 0.38823529  0.41568627  0.44705882]\n",
      "   ..., \n",
      "   [ 0.52941176  0.58823529  0.59607843]\n",
      "   [ 0.52941176  0.58431373  0.60392157]\n",
      "   [ 0.79607843  0.84313725  0.8745098 ]]\n",
      "\n",
      "  [[ 0.27058824  0.28627451  0.2745098 ]\n",
      "   [ 0.32941176  0.34901961  0.38039216]\n",
      "   [ 0.26666667  0.29411765  0.31764706]\n",
      "   ..., \n",
      "   [ 0.33333333  0.37254902  0.34901961]\n",
      "   [ 0.27843137  0.32156863  0.31372549]\n",
      "   [ 0.47058824  0.52156863  0.52941176]]\n",
      "\n",
      "  [[ 0.27058824  0.28627451  0.2745098 ]\n",
      "   [ 0.35294118  0.37254902  0.39215686]\n",
      "   [ 0.24313725  0.27843137  0.29019608]\n",
      "   ..., \n",
      "   [ 0.29019608  0.31764706  0.2745098 ]\n",
      "   [ 0.20784314  0.24313725  0.21176471]\n",
      "   [ 0.24313725  0.29019608  0.27058824]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.48235294  0.50196078  0.37647059]\n",
      "   [ 0.51764706  0.51764706  0.4       ]\n",
      "   [ 0.50588235  0.50196078  0.39215686]\n",
      "   ..., \n",
      "   [ 0.42352941  0.41960784  0.34509804]\n",
      "   [ 0.24313725  0.23529412  0.21568627]\n",
      "   [ 0.10588235  0.10588235  0.10980392]]\n",
      "\n",
      "  [[ 0.45098039  0.4745098   0.35686275]\n",
      "   [ 0.48235294  0.48627451  0.37254902]\n",
      "   [ 0.50588235  0.49411765  0.38823529]\n",
      "   ..., \n",
      "   [ 0.45098039  0.45490196  0.36862745]\n",
      "   [ 0.25882353  0.25490196  0.23137255]\n",
      "   [ 0.10588235  0.10588235  0.10588235]]\n",
      "\n",
      "  [[ 0.45490196  0.47058824  0.35294118]\n",
      "   [ 0.4745098   0.47843137  0.36862745]\n",
      "   [ 0.50588235  0.50196078  0.39607843]\n",
      "   ..., \n",
      "   [ 0.45490196  0.45098039  0.36862745]\n",
      "   [ 0.26666667  0.25490196  0.22745098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [ 0.10588235  0.10196078  0.10196078]]]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape = [None, *image_shape], name = \"x\")\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], name = \"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name = \"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    input_channel_depth = int(x_tensor.get_shape()[3])\n",
    "    \n",
    "    weight = tf.Variable(tf.truncated_normal(\n",
    "        (conv_ksize[0], conv_ksize[1], input_channel_depth, conv_num_outputs),\n",
    "        mean=0.0,stddev=0.1,dtype=tf.float32,seed=None,name=None))\n",
    "    \n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    x = tf.nn.conv2d(x_tensor, weight, strides=[1, *conv_strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, bias)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, *pool_ksize, 1],\n",
    "        strides=[1, *pool_strides, 1],\n",
    "        padding='SAME')\n",
    "    return x\n",
    "\n",
    "    \n",
    "   \n",
    "    #weights = tf.Variable(tf.truncated_normal([*conv_ksize, input_channel_depth, conv_num_outputs], dtype=tf.float32))\n",
    "   \n",
    "    #biases = tf.Variable(tf.constant(0, shape=[conv_num_outputs], dtype=tf.float32))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Flatten/Reshape:0\", shape=(?, 1800), dtype=float32)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "   \n",
    "    print(tf.contrib.layers.flatten(x_tensor))\n",
    "    return tf.contrib.layers.flatten(x_tensor)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs, activation_fn=tf.nn.relu)\n",
    "   \n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #print(fully_conn(x_tensor, num_outputs))\n",
    "    #print(tf.contrib.layers.fully_connected(x_tensor, num_outputs))\n",
    "    \n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs,activation_fn=None)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Flatten/Reshape:0\", shape=(?, 1536), dtype=float32)\n",
      "Tensor(\"Flatten_2/Reshape:0\", shape=(?, 1536), dtype=float32)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    conv_num_outputs = 64\n",
    "    conv_ksize = [5, 5]\n",
    "    conv_strides = [1, 1]\n",
    "    pool_ksize = [2, 2]\n",
    "    pool_strides = [1, 1]\n",
    "    \n",
    "    #conv_layer = conv2d_maxpool(x, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    #flatten_layer = flatten(conv_layer)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    #fully_layer = fully_conn(flatten_layer,256)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    # dropout_layer = tf.nn.dropout(fully_layer, keep_prob)\n",
    "    #output_layer = output(dropout_layer, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    \n",
    "################################################################################################################\n",
    "   \n",
    "    conv_ksize = (3,3)\n",
    "    conv_strides = (1,1)\n",
    "    pool_ksize = (2,2)\n",
    "    pool_strides = (2,2)\n",
    "    \n",
    "    keep_prob = 0.5\n",
    "\n",
    "     # Layer 1\n",
    "    conv1 = conv2d_maxpool(x, 8 * 3, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    # Layer 2\n",
    "    conv2 = conv2d_maxpool(conv1, 16 * 3, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    # Layer 3\n",
    "    conv3 = conv2d_maxpool(conv2, 32 * 3, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    # Flatten layer\n",
    "    flatten1 = flatten(conv3)\n",
    "\n",
    "    # Fully connected layer\n",
    "    fc1 = fully_conn(flatten1, 512)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    fc2 = fully_conn(fc1, 512)\n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "    \n",
    "    out = output(fc2, 10)\n",
    "    return out\n",
    "\n",
    "    # TODO: return output\n",
    "    # return neural_net\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #x = neural_net_image_input((feature_batch.shape[1], feature_batch.shape[2], feature_batch.shape[3]))\n",
    "    #y = neural_net_label_input(label_batch.shape[1])\n",
    "    #keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x: valid_features,y: valid_labels,keep_prob: 1.})\n",
    "\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 20\n",
    "batch_size = 384\n",
    "keep_probability = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.0626 Validation Accuracy: 0.273000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.8580 Validation Accuracy: 0.361600\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.6597 Validation Accuracy: 0.388400\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.6072 Validation Accuracy: 0.424000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.4161 Validation Accuracy: 0.461400\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.3162 Validation Accuracy: 0.476600\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.2982 Validation Accuracy: 0.483000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.1032 Validation Accuracy: 0.497600\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.0333 Validation Accuracy: 0.506800\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.9520 Validation Accuracy: 0.532200\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     0.8492 Validation Accuracy: 0.517400\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     0.7397 Validation Accuracy: 0.543000\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     0.7665 Validation Accuracy: 0.547600\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.6590 Validation Accuracy: 0.553600\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.6274 Validation Accuracy: 0.552600\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.5575 Validation Accuracy: 0.572200\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.4994 Validation Accuracy: 0.572200\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.4823 Validation Accuracy: 0.560600\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.5254 Validation Accuracy: 0.545200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.4150 Validation Accuracy: 0.579000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.1233 Validation Accuracy: 0.228200\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     1.8057 Validation Accuracy: 0.322200\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.5080 Validation Accuracy: 0.358200\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.5743 Validation Accuracy: 0.410200\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.4486 Validation Accuracy: 0.445400\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.5443 Validation Accuracy: 0.458800\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.3973 Validation Accuracy: 0.491600\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.1080 Validation Accuracy: 0.492800\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.3016 Validation Accuracy: 0.518600\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.1513 Validation Accuracy: 0.518800\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.2525 Validation Accuracy: 0.538600\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.1394 Validation Accuracy: 0.557200\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     0.9772 Validation Accuracy: 0.567000\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.0162 Validation Accuracy: 0.566800\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.0510 Validation Accuracy: 0.584000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.0811 Validation Accuracy: 0.579800\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     0.9513 Validation Accuracy: 0.579400\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     0.8057 Validation Accuracy: 0.593600\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     0.8538 Validation Accuracy: 0.598600\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     0.7800 Validation Accuracy: 0.615800\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     0.9998 Validation Accuracy: 0.592400\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     0.8560 Validation Accuracy: 0.605400\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     0.7379 Validation Accuracy: 0.620400\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     0.7673 Validation Accuracy: 0.623200\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     0.6969 Validation Accuracy: 0.619800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     0.9178 Validation Accuracy: 0.625600\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     0.7737 Validation Accuracy: 0.626600\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     0.6232 Validation Accuracy: 0.628800\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     0.6716 Validation Accuracy: 0.631200\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     0.6936 Validation Accuracy: 0.639200\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     0.8083 Validation Accuracy: 0.645400\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     0.7605 Validation Accuracy: 0.649200\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     0.5615 Validation Accuracy: 0.632800\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     0.5700 Validation Accuracy: 0.652000\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     0.6118 Validation Accuracy: 0.651600\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     0.7094 Validation Accuracy: 0.662400\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     0.6453 Validation Accuracy: 0.646000\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     0.5881 Validation Accuracy: 0.652000\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     0.5487 Validation Accuracy: 0.659000\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     0.5361 Validation Accuracy: 0.654200\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     0.6245 Validation Accuracy: 0.663600\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     0.6518 Validation Accuracy: 0.640600\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     0.4351 Validation Accuracy: 0.658800\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     0.4746 Validation Accuracy: 0.668400\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     0.4821 Validation Accuracy: 0.652600\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.5795 Validation Accuracy: 0.672800\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     0.5304 Validation Accuracy: 0.650400\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     0.3660 Validation Accuracy: 0.668800\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     0.4555 Validation Accuracy: 0.668600\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     0.3734 Validation Accuracy: 0.679200\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     0.5493 Validation Accuracy: 0.672400\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     0.4874 Validation Accuracy: 0.657200\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     0.3373 Validation Accuracy: 0.671800\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     0.4116 Validation Accuracy: 0.672600\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     0.3770 Validation Accuracy: 0.671600\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     0.5471 Validation Accuracy: 0.655000\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     0.4772 Validation Accuracy: 0.672800\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     0.3382 Validation Accuracy: 0.682400\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     0.3590 Validation Accuracy: 0.681000\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     0.2958 Validation Accuracy: 0.680200\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     0.5621 Validation Accuracy: 0.646800\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     0.4257 Validation Accuracy: 0.666200\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     0.2868 Validation Accuracy: 0.676400\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     0.3509 Validation Accuracy: 0.688800\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     0.2845 Validation Accuracy: 0.668400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.4006 Validation Accuracy: 0.666200\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     0.4632 Validation Accuracy: 0.662000\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     0.2440 Validation Accuracy: 0.676200\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     0.3262 Validation Accuracy: 0.685400\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     0.3492 Validation Accuracy: 0.692400\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.3946 Validation Accuracy: 0.683400\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     0.3092 Validation Accuracy: 0.683600\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     0.2244 Validation Accuracy: 0.691000\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     0.3201 Validation Accuracy: 0.667200\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     0.2631 Validation Accuracy: 0.684800\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.3792 Validation Accuracy: 0.685600\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     0.3153 Validation Accuracy: 0.689200\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     0.2010 Validation Accuracy: 0.684000\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     0.2297 Validation Accuracy: 0.691400\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     0.2413 Validation Accuracy: 0.675000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.3234 Validation Accuracy: 0.671200\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     0.3202 Validation Accuracy: 0.681600\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     0.2082 Validation Accuracy: 0.690600\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     0.1882 Validation Accuracy: 0.682200\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     0.1789 Validation Accuracy: 0.678000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.2410 Validation Accuracy: 0.686800\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     0.2993 Validation Accuracy: 0.680200\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     0.1822 Validation Accuracy: 0.697600\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     0.2168 Validation Accuracy: 0.691600\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     0.1971 Validation Accuracy: 0.664800\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.2669 Validation Accuracy: 0.670000\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     0.2514 Validation Accuracy: 0.692600\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     0.1662 Validation Accuracy: 0.687800\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     0.2205 Validation Accuracy: 0.689600\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     0.2235 Validation Accuracy: 0.674200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.2479 Validation Accuracy: 0.658000\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     0.2812 Validation Accuracy: 0.677400\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     0.1824 Validation Accuracy: 0.689800\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     0.2386 Validation Accuracy: 0.676200\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     0.1960 Validation Accuracy: 0.676800\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.679976847436693\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2728bae5198>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
