{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 5:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1014, 1: 1014, 2: 952, 3: 1016, 4: 997, 5: 1025, 6: 980, 7: 977, 8: 1003, 9: 1022}\n",
      "First 20 Labels: [1, 8, 5, 1, 5, 7, 4, 3, 8, 2, 7, 2, 0, 1, 5, 9, 6, 2, 0, 8]\n",
      "\n",
      "Example of Image 7:\n",
      "Image - Min Value: 20 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 3 Name: cat\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwCNCXoAaEzQA0Bjgh4AGhP0ANDY/wVHLp+Km5w66AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f883f5af60>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 5\n",
    "sample_id = 7\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.87058824  0.76470588  0.11372549]\n",
      "   [ 0.37254902  0.2         0.66666667]\n",
      "   [ 0.53333333  0.88627451  0.89411765]\n",
      "   ..., \n",
      "   [ 0.59215686  0.7254902   0.60784314]\n",
      "   [ 0.29019608  0.25098039  0.87843137]\n",
      "   [ 0.2         0.3254902   0.40784314]]\n",
      "\n",
      "  [[ 0.07058824  0.0745098   0.01568627]\n",
      "   [ 0.35686275  0.47843137  0.97647059]\n",
      "   [ 0.14117647  0.44705882  0.04705882]\n",
      "   ..., \n",
      "   [ 0.57647059  0.79607843  0.80392157]\n",
      "   [ 0.75294118  0.78823529  0.16078431]\n",
      "   [ 0.23921569  0.94901961  0.67058824]]\n",
      "\n",
      "  [[ 0.91764706  0.89411765  0.43137255]\n",
      "   [ 0.51764706  0.98431373  0.04313725]\n",
      "   [ 0.50588235  0.87843137  0.34509804]\n",
      "   ..., \n",
      "   [ 0.43529412  0.56862745  0.27843137]\n",
      "   [ 0.35686275  0.02745098  0.89803922]\n",
      "   [ 0.36078431  0.64705882  0.92156863]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.55294118  0.50196078  0.21568627]\n",
      "   [ 0.39607843  0.34901961  0.72156863]\n",
      "   [ 0.67843137  0.30980392  0.43921569]\n",
      "   ..., \n",
      "   [ 0.23921569  0.57254902  0.0745098 ]\n",
      "   [ 0.65098039  0.39215686  0.42352941]\n",
      "   [ 0.49411765  0.97254902  0.21568627]]\n",
      "\n",
      "  [[ 0.4627451   0.70980392  0.90980392]\n",
      "   [ 0.80392157  0.23529412  0.35294118]\n",
      "   [ 0.57647059  0.28627451  0.72941176]\n",
      "   ..., \n",
      "   [ 0.31372549  0.47058824  0.80392157]\n",
      "   [ 0.75294118  0.66666667  0.64313725]\n",
      "   [ 0.7372549   0.30196078  0.56078431]]\n",
      "\n",
      "  [[ 0.32941176  0.58039216  0.61960784]\n",
      "   [ 0.47843137  0.1254902   0.21960784]\n",
      "   [ 0.4         0.30588235  0.66666667]\n",
      "   ..., \n",
      "   [ 0.50980392  0.80784314  0.19215686]\n",
      "   [ 0.47843137  0.95294118  0.56862745]\n",
      "   [ 0.0627451   0.4627451   0.61176471]]]\n",
      "\n",
      "\n",
      " [[[ 0.6627451   0.20392157  0.47843137]\n",
      "   [ 0.11372549  0.43921569  0.78039216]\n",
      "   [ 0.6627451   0.63921569  0.07058824]\n",
      "   ..., \n",
      "   [ 0.2745098   0.54117647  0.68235294]\n",
      "   [ 0.49411765  1.          0.91764706]\n",
      "   [ 0.27843137  0.31764706  0.15294118]]\n",
      "\n",
      "  [[ 0.58039216  0.30980392  0.88627451]\n",
      "   [ 0.78431373  0.85490196  0.01176471]\n",
      "   [ 0.35686275  0.64705882  0.18039216]\n",
      "   ..., \n",
      "   [ 0.09019608  0.85882353  0.92941176]\n",
      "   [ 0.80392157  0.03529412  0.4       ]\n",
      "   [ 0.56470588  0.35686275  1.        ]]\n",
      "\n",
      "  [[ 0.05882353  0.01176471  0.28235294]\n",
      "   [ 0.58039216  0.76078431  0.90196078]\n",
      "   [ 0.80784314  0.7372549   0.6627451 ]\n",
      "   ..., \n",
      "   [ 0.08627451  0.34901961  0.05098039]\n",
      "   [ 0.74117647  0.23137255  0.18431373]\n",
      "   [ 0.03529412  0.51764706  0.55686275]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.68627451  0.56862745  0.29411765]\n",
      "   [ 0.45882353  0.39607843  0.46666667]\n",
      "   [ 0.88627451  0.36862745  0.0627451 ]\n",
      "   ..., \n",
      "   [ 0.7372549   0.05098039  0.64705882]\n",
      "   [ 0.24705882  0.30980392  0.01568627]\n",
      "   [ 0.77254902  0.50980392  0.9372549 ]]\n",
      "\n",
      "  [[ 0.91372549  0.41960784  0.14117647]\n",
      "   [ 0.66666667  0.01960784  0.9372549 ]\n",
      "   [ 0.24313725  0.1372549   0.5254902 ]\n",
      "   ..., \n",
      "   [ 0.78823529  0.05882353  0.54117647]\n",
      "   [ 0.10588235  0.90588235  0.81960784]\n",
      "   [ 0.40784314  0.84313725  0.73333333]]\n",
      "\n",
      "  [[ 0.7254902   0.07058824  0.48627451]\n",
      "   [ 0.58823529  0.43529412  0.47843137]\n",
      "   [ 0.97254902  0.22352941  0.01568627]\n",
      "   ..., \n",
      "   [ 0.2745098   0.81568627  0.67843137]\n",
      "   [ 0.49411765  0.09411765  0.95294118]\n",
      "   [ 0.6745098   0.48235294  0.7372549 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.45490196  0.52941176  0.        ]\n",
      "   [ 0.84313725  0.34509804  0.58431373]\n",
      "   [ 0.31372549  0.37254902  0.6627451 ]\n",
      "   ..., \n",
      "   [ 0.30588235  0.80784314  0.38431373]\n",
      "   [ 0.68627451  0.30588235  0.47058824]\n",
      "   [ 0.86666667  0.03137255  0.59215686]]\n",
      "\n",
      "  [[ 0.3372549   0.21568627  0.87058824]\n",
      "   [ 0.30588235  0.87843137  0.34901961]\n",
      "   [ 0.98431373  0.23921569  0.01568627]\n",
      "   ..., \n",
      "   [ 0.36862745  0.15294118  0.78823529]\n",
      "   [ 0.39215686  0.91764706  0.41568627]\n",
      "   [ 0.78039216  0.34901961  0.81960784]]\n",
      "\n",
      "  [[ 0.84313725  0.95294118  0.62352941]\n",
      "   [ 0.48235294  0.63921569  0.04313725]\n",
      "   [ 0.8         0.68235294  0.34509804]\n",
      "   ..., \n",
      "   [ 0.78039216  0.39215686  0.19607843]\n",
      "   [ 0.43137255  0.50196078  0.09411765]\n",
      "   [ 0.3372549   0.2         0.00392157]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.19215686  0.67058824  0.3372549 ]\n",
      "   [ 0.00784314  0.81568627  0.72941176]\n",
      "   [ 0.49803922  0.66666667  0.49019608]\n",
      "   ..., \n",
      "   [ 0.02352941  0.15294118  0.85882353]\n",
      "   [ 0.67843137  0.53333333  0.52156863]\n",
      "   [ 0.82745098  0.95294118  0.17254902]]\n",
      "\n",
      "  [[ 0.8745098   0.43921569  0.10980392]\n",
      "   [ 0.76862745  0.72156863  0.57254902]\n",
      "   [ 0.99607843  0.9254902   0.70196078]\n",
      "   ..., \n",
      "   [ 0.30980392  0.75686275  0.56078431]\n",
      "   [ 0.47058824  0.95686275  0.63921569]\n",
      "   [ 0.14117647  0.58431373  0.71764706]]\n",
      "\n",
      "  [[ 0.76862745  0.03529412  0.99607843]\n",
      "   [ 0.98823529  0.96470588  0.83137255]\n",
      "   [ 0.74117647  0.08235294  0.72941176]\n",
      "   ..., \n",
      "   [ 0.57254902  0.7372549   0.8       ]\n",
      "   [ 0.32156863  0.7372549   0.82745098]\n",
      "   [ 0.4745098   0.41960784  0.65490196]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.15294118  0.38039216  0.98823529]\n",
      "   [ 0.45098039  0.28627451  0.2627451 ]\n",
      "   [ 0.17647059  0.1254902   0.36078431]\n",
      "   ..., \n",
      "   [ 0.8745098   0.16862745  0.6745098 ]\n",
      "   [ 0.86666667  0.89411765  0.49411765]\n",
      "   [ 0.78431373  0.18431373  0.54117647]]\n",
      "\n",
      "  [[ 0.4627451   0.47843137  0.94901961]\n",
      "   [ 0.64313725  0.96078431  0.53333333]\n",
      "   [ 0.29411765  0.29411765  0.2627451 ]\n",
      "   ..., \n",
      "   [ 0.10588235  0.57647059  0.61568627]\n",
      "   [ 0.18039216  0.09019608  0.12156863]\n",
      "   [ 0.58039216  0.21568627  0.16078431]]\n",
      "\n",
      "  [[ 0.75294118  0.25098039  0.17254902]\n",
      "   [ 0.35294118  0.54117647  0.37254902]\n",
      "   [ 0.07843137  0.27058824  0.45098039]\n",
      "   ..., \n",
      "   [ 0.2627451   0.23137255  0.58823529]\n",
      "   [ 0.92941176  0.38039216  0.61960784]\n",
      "   [ 0.55686275  0.91764706  0.20392157]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.48627451  0.43921569  0.36862745]\n",
      "   [ 0.43529412  0.25882353  0.1254902 ]\n",
      "   [ 0.16078431  0.87843137  0.45490196]\n",
      "   ..., \n",
      "   [ 0.34117647  0.94117647  0.01568627]\n",
      "   [ 0.63529412  0.43137255  0.6745098 ]\n",
      "   [ 0.97254902  0.86666667  0.4745098 ]]\n",
      "\n",
      "  [[ 0.41176471  0.85490196  0.63529412]\n",
      "   [ 0.77254902  0.45098039  0.0627451 ]\n",
      "   [ 0.98823529  0.72156863  0.99607843]\n",
      "   ..., \n",
      "   [ 0.65490196  0.94901961  0.95686275]\n",
      "   [ 0.74117647  0.5372549   0.25490196]\n",
      "   [ 0.55294118  0.34117647  0.95294118]]\n",
      "\n",
      "  [[ 0.35294118  0.47058824  0.62352941]\n",
      "   [ 0.91764706  0.85882353  0.12941176]\n",
      "   [ 0.64705882  0.95686275  0.69019608]\n",
      "   ..., \n",
      "   [ 0.41568627  0.68627451  0.56470588]\n",
      "   [ 0.25882353  0.9254902   0.47058824]\n",
      "   [ 0.89803922  0.14117647  0.69411765]]]\n",
      "\n",
      "\n",
      " [[[ 0.85882353  0.9372549   0.21176471]\n",
      "   [ 0.04313725  0.84705882  0.36470588]\n",
      "   [ 0.72941176  0.18039216  0.50980392]\n",
      "   ..., \n",
      "   [ 0.34117647  0.09803922  0.70980392]\n",
      "   [ 0.80784314  0.91764706  0.88627451]\n",
      "   [ 0.09803922  1.          0.45098039]]\n",
      "\n",
      "  [[ 0.01568627  0.25098039  0.35686275]\n",
      "   [ 0.25882353  0.4627451   0.35686275]\n",
      "   [ 0.57254902  0.77254902  0.56470588]\n",
      "   ..., \n",
      "   [ 0.6745098   0.90980392  0.04313725]\n",
      "   [ 0.00784314  0.44313725  0.75686275]\n",
      "   [ 0.14117647  0.4627451   0.17254902]]\n",
      "\n",
      "  [[ 0.27058824  0.34901961  0.54117647]\n",
      "   [ 0.77254902  0.4         0.65098039]\n",
      "   [ 0.34117647  0.85098039  0.7254902 ]\n",
      "   ..., \n",
      "   [ 0.49803922  0.44313725  0.80784314]\n",
      "   [ 0.48235294  0.50980392  0.03529412]\n",
      "   [ 0.51764706  0.35686275  0.23529412]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.83921569  0.91764706  0.02352941]\n",
      "   [ 0.61176471  0.09803922  0.32156863]\n",
      "   [ 0.68235294  0.29803922  0.61960784]\n",
      "   ..., \n",
      "   [ 0.84313725  0.14509804  0.37647059]\n",
      "   [ 0.92941176  0.58823529  0.14901961]\n",
      "   [ 0.14901961  0.92156863  0.01960784]]\n",
      "\n",
      "  [[ 0.63529412  0.15686275  0.89019608]\n",
      "   [ 0.65490196  0.09803922  0.09019608]\n",
      "   [ 0.8627451   0.67843137  0.8627451 ]\n",
      "   ..., \n",
      "   [ 0.19215686  0.00784314  0.31764706]\n",
      "   [ 0.23921569  0.29411765  1.        ]\n",
      "   [ 0.4627451   0.45490196  0.61176471]]\n",
      "\n",
      "  [[ 0.59607843  0.89411765  0.93333333]\n",
      "   [ 0.40784314  0.85490196  0.27058824]\n",
      "   [ 0.68627451  0.07843137  0.72156863]\n",
      "   ..., \n",
      "   [ 0.92941176  0.75294118  0.49019608]\n",
      "   [ 0.80392157  0.8627451   0.86666667]\n",
      "   [ 0.72156863  0.81960784  0.76862745]]]\n",
      "\n",
      "\n",
      " [[[ 0.29803922  0.47843137  0.97254902]\n",
      "   [ 0.1254902   0.56862745  0.31764706]\n",
      "   [ 0.32156863  0.07058824  0.8       ]\n",
      "   ..., \n",
      "   [ 0.6         0.87058824  0.96078431]\n",
      "   [ 0.72156863  0.69803922  0.52941176]\n",
      "   [ 0.60392157  0.72941176  0.35686275]]\n",
      "\n",
      "  [[ 0.88235294  0.09019608  0.29019608]\n",
      "   [ 0.69411765  0.43137255  0.8627451 ]\n",
      "   [ 0.83529412  0.79607843  0.7254902 ]\n",
      "   ..., \n",
      "   [ 0.17254902  0.05882353  0.83921569]\n",
      "   [ 0.31764706  0.89411765  0.6627451 ]\n",
      "   [ 0.74509804  0.61568627  0.55686275]]\n",
      "\n",
      "  [[ 0.96862745  0.5372549   0.10980392]\n",
      "   [ 0.62745098  0.53333333  0.74117647]\n",
      "   [ 0.49019608  0.44705882  0.82745098]\n",
      "   ..., \n",
      "   [ 0.49803922  0.31372549  0.55294118]\n",
      "   [ 0.72156863  0.25098039  0.43921569]\n",
      "   [ 0.01176471  0.10980392  0.32156863]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.68235294  0.7254902   0.73333333]\n",
      "   [ 0.10196078  0.17254902  0.80784314]\n",
      "   [ 0.63921569  0.18431373  0.05098039]\n",
      "   ..., \n",
      "   [ 0.48627451  0.25490196  0.90196078]\n",
      "   [ 0.43529412  0.75294118  0.37254902]\n",
      "   [ 0.33333333  0.37254902  0.78431373]]\n",
      "\n",
      "  [[ 0.84313725  0.91372549  0.46666667]\n",
      "   [ 0.07058824  0.48627451  0.63529412]\n",
      "   [ 0.74509804  0.28627451  0.52941176]\n",
      "   ..., \n",
      "   [ 0.4         0.15294118  0.26666667]\n",
      "   [ 0.31372549  0.2745098   0.42352941]\n",
      "   [ 0.04705882  0.89803922  0.52941176]]\n",
      "\n",
      "  [[ 0.84313725  0.2         0.83529412]\n",
      "   [ 0.2745098   0.71372549  0.74901961]\n",
      "   [ 0.38431373  0.16470588  0.90196078]\n",
      "   ..., \n",
      "   [ 0.24313725  0.52156863  0.74901961]\n",
      "   [ 0.82352941  0.50588235  0.39215686]\n",
      "   [ 0.84313725  0.85098039  0.65490196]]]]\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function \n",
    "    normal=np.ndarray(x.shape,dtype=float)\n",
    "    normal[:] = x\n",
    "    for a in np.nditer(normal, op_flags=['readwrite']):\n",
    "        a[...] = a/255.0\n",
    "    print(normal)\n",
    "    ##########################################################\n",
    "    x_min = np.min(x)\n",
    "    x_max = np.max(x)\n",
    "    return (x - x_min) / (x_max - x_min)\n",
    "    \n",
    "    \n",
    "    # return normal\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  1.  0.  0.]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]]\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    one_hot = np.zeros(shape=(len(x), 10))\n",
    "    for i in range(len(x)):\n",
    "        for j in range(10):\n",
    "            one_hot[i][j] = (j == x[i])\n",
    "\n",
    "    print(one_hot)        \n",
    "    return one_hot\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 0.23137255  0.24313725  0.24705882]\n",
      "   [ 0.16862745  0.18039216  0.17647059]\n",
      "   [ 0.19607843  0.18823529  0.16862745]\n",
      "   ..., \n",
      "   [ 0.61960784  0.51764706  0.42352941]\n",
      "   [ 0.59607843  0.49019608  0.4       ]\n",
      "   [ 0.58039216  0.48627451  0.40392157]]\n",
      "\n",
      "  [[ 0.0627451   0.07843137  0.07843137]\n",
      "   [ 0.          0.          0.        ]\n",
      "   [ 0.07058824  0.03137255  0.        ]\n",
      "   ..., \n",
      "   [ 0.48235294  0.34509804  0.21568627]\n",
      "   [ 0.46666667  0.3254902   0.19607843]\n",
      "   [ 0.47843137  0.34117647  0.22352941]]\n",
      "\n",
      "  [[ 0.09803922  0.09411765  0.08235294]\n",
      "   [ 0.0627451   0.02745098  0.        ]\n",
      "   [ 0.19215686  0.10588235  0.03137255]\n",
      "   ..., \n",
      "   [ 0.4627451   0.32941176  0.19607843]\n",
      "   [ 0.47058824  0.32941176  0.19607843]\n",
      "   [ 0.42745098  0.28627451  0.16470588]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.81568627  0.66666667  0.37647059]\n",
      "   [ 0.78823529  0.6         0.13333333]\n",
      "   [ 0.77647059  0.63137255  0.10196078]\n",
      "   ..., \n",
      "   [ 0.62745098  0.52156863  0.2745098 ]\n",
      "   [ 0.21960784  0.12156863  0.02745098]\n",
      "   [ 0.20784314  0.13333333  0.07843137]]\n",
      "\n",
      "  [[ 0.70588235  0.54509804  0.37647059]\n",
      "   [ 0.67843137  0.48235294  0.16470588]\n",
      "   [ 0.72941176  0.56470588  0.11764706]\n",
      "   ..., \n",
      "   [ 0.72156863  0.58039216  0.36862745]\n",
      "   [ 0.38039216  0.24313725  0.13333333]\n",
      "   [ 0.3254902   0.20784314  0.13333333]]\n",
      "\n",
      "  [[ 0.69411765  0.56470588  0.45490196]\n",
      "   [ 0.65882353  0.50588235  0.36862745]\n",
      "   [ 0.70196078  0.55686275  0.34117647]\n",
      "   ..., \n",
      "   [ 0.84705882  0.72156863  0.54901961]\n",
      "   [ 0.59215686  0.4627451   0.32941176]\n",
      "   [ 0.48235294  0.36078431  0.28235294]]]\n",
      "\n",
      "\n",
      " [[[ 0.60392157  0.69411765  0.73333333]\n",
      "   [ 0.49411765  0.5372549   0.53333333]\n",
      "   [ 0.41176471  0.40784314  0.37254902]\n",
      "   ..., \n",
      "   [ 0.35686275  0.37254902  0.27843137]\n",
      "   [ 0.34117647  0.35294118  0.27843137]\n",
      "   [ 0.30980392  0.31764706  0.2745098 ]]\n",
      "\n",
      "  [[ 0.54901961  0.62745098  0.6627451 ]\n",
      "   [ 0.56862745  0.6         0.60392157]\n",
      "   [ 0.49019608  0.49019608  0.4627451 ]\n",
      "   ..., \n",
      "   [ 0.37647059  0.38823529  0.30588235]\n",
      "   [ 0.30196078  0.31372549  0.24313725]\n",
      "   [ 0.27843137  0.28627451  0.23921569]]\n",
      "\n",
      "  [[ 0.54901961  0.60784314  0.64313725]\n",
      "   [ 0.54509804  0.57254902  0.58431373]\n",
      "   [ 0.45098039  0.45098039  0.43921569]\n",
      "   ..., \n",
      "   [ 0.30980392  0.32156863  0.25098039]\n",
      "   [ 0.26666667  0.2745098   0.21568627]\n",
      "   [ 0.2627451   0.27058824  0.21568627]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.68627451  0.65490196  0.65098039]\n",
      "   [ 0.61176471  0.60392157  0.62745098]\n",
      "   [ 0.60392157  0.62745098  0.66666667]\n",
      "   ..., \n",
      "   [ 0.16470588  0.13333333  0.14117647]\n",
      "   [ 0.23921569  0.20784314  0.22352941]\n",
      "   [ 0.36470588  0.3254902   0.35686275]]\n",
      "\n",
      "  [[ 0.64705882  0.60392157  0.50196078]\n",
      "   [ 0.61176471  0.59607843  0.50980392]\n",
      "   [ 0.62352941  0.63137255  0.55686275]\n",
      "   ..., \n",
      "   [ 0.40392157  0.36470588  0.37647059]\n",
      "   [ 0.48235294  0.44705882  0.47058824]\n",
      "   [ 0.51372549  0.4745098   0.51372549]]\n",
      "\n",
      "  [[ 0.63921569  0.58039216  0.47058824]\n",
      "   [ 0.61960784  0.58039216  0.47843137]\n",
      "   [ 0.63921569  0.61176471  0.52156863]\n",
      "   ..., \n",
      "   [ 0.56078431  0.52156863  0.54509804]\n",
      "   [ 0.56078431  0.5254902   0.55686275]\n",
      "   [ 0.56078431  0.52156863  0.56470588]]]\n",
      "\n",
      "\n",
      " [[[ 1.          1.          1.        ]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   [ 0.99215686  0.99215686  0.99215686]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ..., \n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 0.99607843  0.99607843  0.99607843]\n",
      "   [ 0.99607843  0.99607843  0.99607843]\n",
      "   ..., \n",
      "   [ 0.99607843  0.99607843  0.99607843]\n",
      "   [ 0.99607843  0.99607843  0.99607843]\n",
      "   [ 0.99607843  0.99607843  0.99607843]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.44313725  0.47058824  0.43921569]\n",
      "   [ 0.43529412  0.4627451   0.43529412]\n",
      "   [ 0.41176471  0.43921569  0.41568627]\n",
      "   ..., \n",
      "   [ 0.28235294  0.31764706  0.31372549]\n",
      "   [ 0.28235294  0.31372549  0.30980392]\n",
      "   [ 0.28235294  0.31372549  0.30980392]]\n",
      "\n",
      "  [[ 0.43529412  0.4627451   0.43137255]\n",
      "   [ 0.40784314  0.43529412  0.40784314]\n",
      "   [ 0.38823529  0.41568627  0.38431373]\n",
      "   ..., \n",
      "   [ 0.26666667  0.29411765  0.28627451]\n",
      "   [ 0.2745098   0.29803922  0.29411765]\n",
      "   [ 0.30588235  0.32941176  0.32156863]]\n",
      "\n",
      "  [[ 0.41568627  0.44313725  0.41176471]\n",
      "   [ 0.38823529  0.41568627  0.38431373]\n",
      "   [ 0.37254902  0.4         0.36862745]\n",
      "   ..., \n",
      "   [ 0.30588235  0.33333333  0.3254902 ]\n",
      "   [ 0.30980392  0.33333333  0.3254902 ]\n",
      "   [ 0.31372549  0.3372549   0.32941176]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.27058824  0.27843137  0.20392157]\n",
      "   [ 0.24313725  0.24313725  0.19215686]\n",
      "   [ 0.22745098  0.22352941  0.18823529]\n",
      "   ..., \n",
      "   [ 0.4627451   0.49019608  0.31372549]\n",
      "   [ 0.4745098   0.49019608  0.28627451]\n",
      "   [ 0.48235294  0.50588235  0.29019608]]\n",
      "\n",
      "  [[ 0.2745098   0.27843137  0.19215686]\n",
      "   [ 0.23137255  0.22745098  0.18431373]\n",
      "   [ 0.2         0.19215686  0.16862745]\n",
      "   ..., \n",
      "   [ 0.48235294  0.48235294  0.3254902 ]\n",
      "   [ 0.45882353  0.47843137  0.29803922]\n",
      "   [ 0.41568627  0.43921569  0.25490196]]\n",
      "\n",
      "  [[ 0.28627451  0.28235294  0.18431373]\n",
      "   [ 0.25490196  0.24705882  0.17647059]\n",
      "   [ 0.20392157  0.19607843  0.17254902]\n",
      "   ..., \n",
      "   [ 0.47058824  0.46666667  0.30980392]\n",
      "   [ 0.45098039  0.45098039  0.27058824]\n",
      "   [ 0.42745098  0.43529412  0.26666667]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.76862745  0.82352941  0.37254902]\n",
      "   [ 0.79215686  0.82745098  0.42745098]\n",
      "   [ 0.76078431  0.78823529  0.41176471]\n",
      "   ..., \n",
      "   [ 0.77647059  0.84313725  0.35294118]\n",
      "   [ 0.81568627  0.85882353  0.42352941]\n",
      "   [ 0.83137255  0.88235294  0.43529412]]\n",
      "\n",
      "  [[ 0.74509804  0.80784314  0.36862745]\n",
      "   [ 0.74901961  0.80784314  0.37254902]\n",
      "   [ 0.74509804  0.80392157  0.36470588]\n",
      "   ..., \n",
      "   [ 0.77647059  0.83921569  0.36862745]\n",
      "   [ 0.76470588  0.81568627  0.37254902]\n",
      "   [ 0.80784314  0.8627451   0.41960784]]\n",
      "\n",
      "  [[ 0.71764706  0.76470588  0.36470588]\n",
      "   [ 0.72156863  0.77254902  0.37647059]\n",
      "   [ 0.71372549  0.75686275  0.36078431]\n",
      "   ..., \n",
      "   [ 0.75686275  0.81176471  0.35686275]\n",
      "   [ 0.74117647  0.8         0.34117647]\n",
      "   [ 0.77647059  0.82745098  0.39215686]]]\n",
      "\n",
      "\n",
      " [[[ 0.61960784  0.61960784  0.61960784]\n",
      "   [ 0.61960784  0.61960784  0.61568627]\n",
      "   [ 0.61960784  0.62352941  0.60392157]\n",
      "   ..., \n",
      "   [ 0.61176471  0.61568627  0.59607843]\n",
      "   [ 0.61176471  0.61568627  0.59607843]\n",
      "   [ 0.61176471  0.61176471  0.59215686]]\n",
      "\n",
      "  [[ 0.61568627  0.61568627  0.61568627]\n",
      "   [ 0.61960784  0.61960784  0.61568627]\n",
      "   [ 0.61568627  0.61568627  0.60784314]\n",
      "   ..., \n",
      "   [ 0.61176471  0.61568627  0.6       ]\n",
      "   [ 0.61176471  0.61568627  0.59607843]\n",
      "   [ 0.61176471  0.61176471  0.59607843]]\n",
      "\n",
      "  [[ 0.61176471  0.61176471  0.61176471]\n",
      "   [ 0.61568627  0.61568627  0.61176471]\n",
      "   [ 0.61568627  0.61568627  0.60784314]\n",
      "   ..., \n",
      "   [ 0.60784314  0.60784314  0.6       ]\n",
      "   [ 0.60784314  0.60784314  0.6       ]\n",
      "   [ 0.60784314  0.60784314  0.6       ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.22745098  0.26666667  0.26666667]\n",
      "   [ 0.24313725  0.28235294  0.29019608]\n",
      "   [ 0.21960784  0.25882353  0.2627451 ]\n",
      "   ..., \n",
      "   [ 0.24313725  0.2745098   0.30196078]\n",
      "   [ 0.18823529  0.22352941  0.23137255]\n",
      "   [ 0.22352941  0.25882353  0.26666667]]\n",
      "\n",
      "  [[ 0.20392157  0.24313725  0.23921569]\n",
      "   [ 0.23529412  0.27058824  0.27843137]\n",
      "   [ 0.16862745  0.20392157  0.20392157]\n",
      "   ..., \n",
      "   [ 0.25882353  0.29803922  0.30980392]\n",
      "   [ 0.21568627  0.25882353  0.2627451 ]\n",
      "   [ 0.23529412  0.2745098   0.29019608]]\n",
      "\n",
      "  [[ 0.19607843  0.22745098  0.23137255]\n",
      "   [ 0.2         0.21960784  0.21960784]\n",
      "   [ 0.20784314  0.23529412  0.23921569]\n",
      "   ..., \n",
      "   [ 0.18039216  0.21176471  0.21176471]\n",
      "   [ 0.22745098  0.25882353  0.26666667]\n",
      "   [ 0.23921569  0.28235294  0.29019608]]]\n",
      "\n",
      "\n",
      " [[[ 0.76862745  0.67058824  0.51372549]\n",
      "   [ 0.76862745  0.6745098   0.51372549]\n",
      "   [ 0.75686275  0.65882353  0.50196078]\n",
      "   ..., \n",
      "   [ 0.69411765  0.6         0.50980392]\n",
      "   [ 0.67058824  0.57647059  0.48627451]\n",
      "   [ 0.64705882  0.55294118  0.45882353]]\n",
      "\n",
      "  [[ 0.77647059  0.67843137  0.52156863]\n",
      "   [ 0.77647059  0.67843137  0.52156863]\n",
      "   [ 0.76470588  0.6627451   0.50588235]\n",
      "   ..., \n",
      "   [ 0.69803922  0.60784314  0.51764706]\n",
      "   [ 0.6745098   0.58431373  0.49411765]\n",
      "   [ 0.65490196  0.56470588  0.47058824]]\n",
      "\n",
      "  [[ 0.76862745  0.67058824  0.51764706]\n",
      "   [ 0.76862745  0.67058824  0.51764706]\n",
      "   [ 0.75294118  0.65490196  0.50196078]\n",
      "   ..., \n",
      "   [ 0.69019608  0.60392157  0.51764706]\n",
      "   [ 0.66666667  0.58431373  0.49411765]\n",
      "   [ 0.64705882  0.56078431  0.4745098 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.7372549   0.61960784  0.40392157]\n",
      "   [ 0.7372549   0.62745098  0.40392157]\n",
      "   [ 0.74117647  0.62745098  0.4       ]\n",
      "   ..., \n",
      "   [ 0.8         0.74509804  0.69803922]\n",
      "   [ 0.78431373  0.74117647  0.70196078]\n",
      "   [ 0.76862745  0.71764706  0.68235294]]\n",
      "\n",
      "  [[ 0.74117647  0.62352941  0.40392157]\n",
      "   [ 0.74117647  0.62745098  0.40784314]\n",
      "   [ 0.74509804  0.63137255  0.4       ]\n",
      "   ..., \n",
      "   [ 0.80392157  0.74509804  0.68627451]\n",
      "   [ 0.78431373  0.73333333  0.69019608]\n",
      "   [ 0.77254902  0.71764706  0.67843137]]\n",
      "\n",
      "  [[ 0.72156863  0.60392157  0.39215686]\n",
      "   [ 0.72156863  0.61176471  0.39215686]\n",
      "   [ 0.72156863  0.60784314  0.38039216]\n",
      "   ..., \n",
      "   [ 0.78039216  0.71372549  0.64705882]\n",
      "   [ 0.76862745  0.70588235  0.65490196]\n",
      "   [ 0.75686275  0.69411765  0.65098039]]]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n",
      "[[[[ 0.1372549   0.09803922  0.10196078]\n",
      "   [ 0.10588235  0.08235294  0.08235294]\n",
      "   [ 0.09803922  0.07843137  0.0745098 ]\n",
      "   ..., \n",
      "   [ 0.51764706  0.50588235  0.50588235]\n",
      "   [ 0.52156863  0.4745098   0.45490196]\n",
      "   [ 0.49411765  0.45098039  0.44313725]]\n",
      "\n",
      "  [[ 0.24705882  0.21568627  0.19607843]\n",
      "   [ 0.1254902   0.10588235  0.08235294]\n",
      "   [ 0.06666667  0.05098039  0.03137255]\n",
      "   ..., \n",
      "   [ 0.4         0.37254902  0.34509804]\n",
      "   [ 0.41176471  0.34901961  0.29803922]\n",
      "   [ 0.39215686  0.3372549   0.30196078]]\n",
      "\n",
      "  [[ 0.38823529  0.35686275  0.32941176]\n",
      "   [ 0.19215686  0.17647059  0.14509804]\n",
      "   [ 0.05882353  0.04705882  0.01960784]\n",
      "   ..., \n",
      "   [ 0.18039216  0.16862745  0.15294118]\n",
      "   [ 0.20392157  0.16078431  0.13333333]\n",
      "   [ 0.20392157  0.17254902  0.16078431]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.65098039  0.64705882  0.67058824]\n",
      "   [ 0.64313725  0.63921569  0.65098039]\n",
      "   [ 0.64313725  0.64313725  0.64705882]\n",
      "   ..., \n",
      "   [ 0.67843137  0.6745098   0.66666667]\n",
      "   [ 0.66666667  0.66666667  0.65882353]\n",
      "   [ 0.65490196  0.65490196  0.65490196]]\n",
      "\n",
      "  [[ 0.6627451   0.65882353  0.69019608]\n",
      "   [ 0.6627451   0.65882353  0.67843137]\n",
      "   [ 0.65882353  0.65882353  0.67058824]\n",
      "   ..., \n",
      "   [ 0.6745098   0.67058824  0.66666667]\n",
      "   [ 0.65882353  0.65490196  0.65490196]\n",
      "   [ 0.64705882  0.64705882  0.65098039]]\n",
      "\n",
      "  [[ 0.67843137  0.6745098   0.70196078]\n",
      "   [ 0.68627451  0.68235294  0.69803922]\n",
      "   [ 0.67843137  0.67843137  0.68627451]\n",
      "   ..., \n",
      "   [ 0.66666667  0.65882353  0.6627451 ]\n",
      "   [ 0.65882353  0.65490196  0.65882353]\n",
      "   [ 0.65098039  0.65098039  0.65882353]]]\n",
      "\n",
      "\n",
      " [[[ 0.07843137  0.05882353  0.04705882]\n",
      "   [ 0.07843137  0.05882353  0.04705882]\n",
      "   [ 0.07058824  0.05098039  0.03921569]\n",
      "   ..., \n",
      "   [ 0.07843137  0.0627451   0.0627451 ]\n",
      "   [ 0.08235294  0.0627451   0.05490196]\n",
      "   [ 0.08235294  0.0627451   0.05098039]]\n",
      "\n",
      "  [[ 0.07843137  0.05882353  0.04705882]\n",
      "   [ 0.07843137  0.05882353  0.04705882]\n",
      "   [ 0.07058824  0.05098039  0.03921569]\n",
      "   ..., \n",
      "   [ 0.07843137  0.0627451   0.05882353]\n",
      "   [ 0.08235294  0.0627451   0.05098039]\n",
      "   [ 0.08235294  0.0627451   0.05098039]]\n",
      "\n",
      "  [[ 0.07843137  0.05882353  0.04705882]\n",
      "   [ 0.07843137  0.05882353  0.04705882]\n",
      "   [ 0.07058824  0.05098039  0.03921569]\n",
      "   ..., \n",
      "   [ 0.07843137  0.0627451   0.05490196]\n",
      "   [ 0.08235294  0.0627451   0.05098039]\n",
      "   [ 0.08235294  0.0627451   0.05098039]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.25882353  0.21176471  0.16078431]\n",
      "   [ 0.31372549  0.2627451   0.20784314]\n",
      "   [ 0.18431373  0.1372549   0.0745098 ]\n",
      "   ..., \n",
      "   [ 0.5254902   0.5254902   0.39215686]\n",
      "   [ 0.43137255  0.44313725  0.30196078]\n",
      "   [ 0.38431373  0.4         0.25882353]]\n",
      "\n",
      "  [[ 0.23529412  0.18823529  0.12941176]\n",
      "   [ 0.21568627  0.16862745  0.10588235]\n",
      "   [ 0.19607843  0.14901961  0.08627451]\n",
      "   ..., \n",
      "   [ 0.48235294  0.49019608  0.3254902 ]\n",
      "   [ 0.30980392  0.31764706  0.16470588]\n",
      "   [ 0.28235294  0.29019608  0.14901961]]\n",
      "\n",
      "  [[ 0.25098039  0.21176471  0.14901961]\n",
      "   [ 0.21568627  0.17647059  0.11372549]\n",
      "   [ 0.18823529  0.14901961  0.08235294]\n",
      "   ..., \n",
      "   [ 0.60784314  0.61568627  0.43529412]\n",
      "   [ 0.53333333  0.5372549   0.38039216]\n",
      "   [ 0.34509804  0.34901961  0.2       ]]]\n",
      "\n",
      "\n",
      " [[[ 0.45490196  0.40392157  0.21960784]\n",
      "   [ 0.45098039  0.41176471  0.23137255]\n",
      "   [ 0.60784314  0.50196078  0.32156863]\n",
      "   ..., \n",
      "   [ 0.68627451  0.51764706  0.30196078]\n",
      "   [ 0.6627451   0.52156863  0.28235294]\n",
      "   [ 0.55686275  0.46666667  0.20784314]]\n",
      "\n",
      "  [[ 0.45490196  0.4         0.22745098]\n",
      "   [ 0.47843137  0.42352941  0.25490196]\n",
      "   [ 0.6         0.4745098   0.30980392]\n",
      "   ..., \n",
      "   [ 0.58823529  0.43529412  0.22352941]\n",
      "   [ 0.56862745  0.4745098   0.23529412]\n",
      "   [ 0.52156863  0.48235294  0.21176471]]\n",
      "\n",
      "  [[ 0.37254902  0.3372549   0.16078431]\n",
      "   [ 0.38431373  0.32941176  0.17254902]\n",
      "   [ 0.55294118  0.41568627  0.2627451 ]\n",
      "   ..., \n",
      "   [ 0.56862745  0.43921569  0.22745098]\n",
      "   [ 0.49411765  0.43529412  0.2       ]\n",
      "   [ 0.49803922  0.49019608  0.24313725]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.30196078  0.24705882  0.11372549]\n",
      "   [ 0.34509804  0.28235294  0.14509804]\n",
      "   [ 0.2745098   0.23137255  0.10588235]\n",
      "   ..., \n",
      "   [ 0.18823529  0.15294118  0.07843137]\n",
      "   [ 0.45490196  0.42352941  0.32941176]\n",
      "   [ 0.62352941  0.55686275  0.47843137]]\n",
      "\n",
      "  [[ 0.21568627  0.14509804  0.0627451 ]\n",
      "   [ 0.25490196  0.18039216  0.09411765]\n",
      "   [ 0.26666667  0.20784314  0.11764706]\n",
      "   ..., \n",
      "   [ 0.16470588  0.11764706  0.05098039]\n",
      "   [ 0.49411765  0.44705882  0.35294118]\n",
      "   [ 0.62745098  0.57647059  0.49019608]]\n",
      "\n",
      "  [[ 0.30588235  0.22352941  0.14509804]\n",
      "   [ 0.28235294  0.19607843  0.11764706]\n",
      "   [ 0.2627451   0.19607843  0.1254902 ]\n",
      "   ..., \n",
      "   [ 0.20392157  0.14509804  0.07058824]\n",
      "   [ 0.48627451  0.43137255  0.32941176]\n",
      "   [ 0.60784314  0.56470588  0.48627451]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.41568627  0.3372549   0.61176471]\n",
      "   [ 0.48235294  0.4         0.50588235]\n",
      "   [ 0.43529412  0.33333333  0.49019608]\n",
      "   ..., \n",
      "   [ 0.51372549  0.4627451   0.61568627]\n",
      "   [ 0.42745098  0.39215686  0.55686275]\n",
      "   [ 0.55294118  0.52941176  0.61960784]]\n",
      "\n",
      "  [[ 0.60784314  0.5254902   0.63529412]\n",
      "   [ 0.6745098   0.57254902  0.44313725]\n",
      "   [ 0.51372549  0.43529412  0.48627451]\n",
      "   ..., \n",
      "   [ 0.51764706  0.46666667  0.60784314]\n",
      "   [ 0.39215686  0.34901961  0.50980392]\n",
      "   [ 0.56862745  0.5372549   0.63529412]]\n",
      "\n",
      "  [[ 0.63529412  0.5254902   0.68235294]\n",
      "   [ 0.62745098  0.49803922  0.43137255]\n",
      "   [ 0.44313725  0.34509804  0.5254902 ]\n",
      "   ..., \n",
      "   [ 0.73333333  0.71372549  0.65490196]\n",
      "   [ 0.69411765  0.6745098   0.65882353]\n",
      "   [ 0.78823529  0.77254902  0.71764706]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.35686275  0.03921569  0.5254902 ]\n",
      "   [ 0.34509804  0.03529412  0.49803922]\n",
      "   [ 0.34509804  0.05098039  0.49803922]\n",
      "   ..., \n",
      "   [ 0.40784314  0.24705882  0.49411765]\n",
      "   [ 0.43529412  0.28235294  0.52156863]\n",
      "   [ 0.43921569  0.25490196  0.53333333]]\n",
      "\n",
      "  [[ 0.29803922  0.02352941  0.50196078]\n",
      "   [ 0.30588235  0.01568627  0.47058824]\n",
      "   [ 0.35686275  0.08235294  0.51764706]\n",
      "   ..., \n",
      "   [ 0.42745098  0.27058824  0.49803922]\n",
      "   [ 0.41960784  0.26666667  0.50980392]\n",
      "   [ 0.44705882  0.24705882  0.54509804]]\n",
      "\n",
      "  [[ 0.2627451   0.03137255  0.50196078]\n",
      "   [ 0.26666667  0.02352941  0.47058824]\n",
      "   [ 0.30980392  0.07058824  0.49803922]\n",
      "   ..., \n",
      "   [ 0.45882353  0.28627451  0.5254902 ]\n",
      "   [ 0.43137255  0.25098039  0.52156863]\n",
      "   [ 0.38823529  0.16470588  0.49019608]]]\n",
      "\n",
      "\n",
      " [[[ 0.96862745  0.96470588  0.97254902]\n",
      "   [ 0.96078431  0.97647059  0.98823529]\n",
      "   [ 0.95686275  0.97254902  0.97647059]\n",
      "   ..., \n",
      "   [ 0.45882353  0.38039216  0.32941176]\n",
      "   [ 0.49803922  0.41960784  0.37647059]\n",
      "   [ 0.61960784  0.56470588  0.54117647]]\n",
      "\n",
      "  [[ 0.95294118  0.95686275  0.96862745]\n",
      "   [ 0.95294118  0.96862745  0.97647059]\n",
      "   [ 0.95294118  0.96078431  0.95686275]\n",
      "   ..., \n",
      "   [ 0.44313725  0.35686275  0.29803922]\n",
      "   [ 0.47843137  0.4         0.34509804]\n",
      "   [ 0.63137255  0.56862745  0.52941176]]\n",
      "\n",
      "  [[ 0.95686275  0.96078431  0.97647059]\n",
      "   [ 0.96078431  0.97647059  0.98039216]\n",
      "   [ 0.96862745  0.96862745  0.95686275]\n",
      "   ..., \n",
      "   [ 0.52941176  0.42745098  0.36470588]\n",
      "   [ 0.4745098   0.37647059  0.31764706]\n",
      "   [ 0.50588235  0.43137255  0.38823529]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.71372549  0.6627451   0.63529412]\n",
      "   [ 0.77647059  0.7254902   0.69803922]\n",
      "   [ 0.85490196  0.80392157  0.77647059]\n",
      "   ..., \n",
      "   [ 0.61568627  0.54901961  0.44313725]\n",
      "   [ 0.36862745  0.30588235  0.21960784]\n",
      "   [ 0.50980392  0.45882353  0.41176471]]\n",
      "\n",
      "  [[ 0.54509804  0.4627451   0.41960784]\n",
      "   [ 0.49411765  0.40392157  0.35686275]\n",
      "   [ 0.5254902   0.43529412  0.38431373]\n",
      "   ..., \n",
      "   [ 0.61960784  0.55686275  0.43921569]\n",
      "   [ 0.46666667  0.40784314  0.31372549]\n",
      "   [ 0.45490196  0.40784314  0.35294118]]\n",
      "\n",
      "  [[ 0.76862745  0.70196078  0.62745098]\n",
      "   [ 0.7254902   0.63921569  0.54509804]\n",
      "   [ 0.69019608  0.58823529  0.48235294]\n",
      "   ..., \n",
      "   [ 0.59607843  0.54901961  0.42352941]\n",
      "   [ 0.69411765  0.64313725  0.5372549 ]\n",
      "   [ 0.63529412  0.59607843  0.52156863]]]\n",
      "\n",
      "\n",
      " [[[ 0.74117647  0.89803922  0.94117647]\n",
      "   [ 0.76470588  0.90980392  0.94901961]\n",
      "   [ 0.79607843  0.93333333  0.96470588]\n",
      "   ..., \n",
      "   [ 0.65882353  0.75686275  0.81176471]\n",
      "   [ 0.65882353  0.74901961  0.79215686]\n",
      "   [ 0.65882353  0.7372549   0.78039216]]\n",
      "\n",
      "  [[ 0.79607843  0.9372549   0.96470588]\n",
      "   [ 0.83137255  0.96470588  0.98431373]\n",
      "   [ 0.82352941  0.94901961  0.96862745]\n",
      "   ..., \n",
      "   [ 0.58431373  0.67843137  0.76470588]\n",
      "   [ 0.59215686  0.6745098   0.76470588]\n",
      "   [ 0.60784314  0.67843137  0.77254902]]\n",
      "\n",
      "  [[ 0.83529412  0.96862745  0.98431373]\n",
      "   [ 0.81568627  0.94509804  0.96078431]\n",
      "   [ 0.82745098  0.94509804  0.95686275]\n",
      "   ..., \n",
      "   [ 0.58431373  0.6745098   0.76862745]\n",
      "   [ 0.57647059  0.65490196  0.76470588]\n",
      "   [ 0.56470588  0.63137255  0.75686275]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.29019608  0.31764706  0.35294118]\n",
      "   [ 0.21176471  0.32156863  0.47843137]\n",
      "   [ 0.15294118  0.40784314  0.62352941]\n",
      "   ..., \n",
      "   [ 0.18039216  0.15294118  0.18039216]\n",
      "   [ 0.19607843  0.16862745  0.2       ]\n",
      "   [ 0.27058824  0.24705882  0.25098039]]\n",
      "\n",
      "  [[ 0.25490196  0.2627451   0.28627451]\n",
      "   [ 0.16470588  0.22745098  0.35686275]\n",
      "   [ 0.17647059  0.36078431  0.50980392]\n",
      "   ..., \n",
      "   [ 0.14509804  0.08627451  0.17647059]\n",
      "   [ 0.17254902  0.10588235  0.18431373]\n",
      "   [ 0.22352941  0.17254902  0.2       ]]\n",
      "\n",
      "  [[ 0.20784314  0.22745098  0.24705882]\n",
      "   [ 0.15294118  0.2         0.25490196]\n",
      "   [ 0.24705882  0.30588235  0.36862745]\n",
      "   ..., \n",
      "   [ 0.18039216  0.10196078  0.19215686]\n",
      "   [ 0.23137255  0.14901961  0.18431373]\n",
      "   [ 0.29411765  0.23921569  0.2       ]]]]\n",
      "[[ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  1.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]]\n",
      "[[[[ 0.10196078  0.09019608  0.1254902 ]\n",
      "   [ 0.06666667  0.05490196  0.09803922]\n",
      "   [ 0.05098039  0.03529412  0.09411765]\n",
      "   ..., \n",
      "   [ 0.05882353  0.05490196  0.10980392]\n",
      "   [ 0.09411765  0.09411765  0.14509804]\n",
      "   [ 0.08627451  0.08235294  0.13333333]]\n",
      "\n",
      "  [[ 0.07843137  0.06666667  0.10196078]\n",
      "   [ 0.05098039  0.03921569  0.08627451]\n",
      "   [ 0.05098039  0.03529412  0.09411765]\n",
      "   ..., \n",
      "   [ 0.0745098   0.06666667  0.1372549 ]\n",
      "   [ 0.08235294  0.07843137  0.1372549 ]\n",
      "   [ 0.11372549  0.11372549  0.15294118]]\n",
      "\n",
      "  [[ 0.05490196  0.04313725  0.07843137]\n",
      "   [ 0.05098039  0.03921569  0.08235294]\n",
      "   [ 0.05098039  0.03529412  0.09019608]\n",
      "   ..., \n",
      "   [ 0.06666667  0.0627451   0.1254902 ]\n",
      "   [ 0.09803922  0.09411765  0.14901961]\n",
      "   [ 0.12156863  0.12156863  0.16470588]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.35294118  0.42745098  0.5372549 ]\n",
      "   [ 0.13333333  0.25098039  0.37254902]\n",
      "   [ 0.10980392  0.21176471  0.35294118]\n",
      "   ..., \n",
      "   [ 0.09019608  0.07843137  0.14509804]\n",
      "   [ 0.0627451   0.05098039  0.11764706]\n",
      "   [ 0.03529412  0.02352941  0.09019608]]\n",
      "\n",
      "  [[ 0.30980392  0.41176471  0.55294118]\n",
      "   [ 0.22745098  0.37647059  0.54509804]\n",
      "   [ 0.1254902   0.26666667  0.43137255]\n",
      "   ..., \n",
      "   [ 0.05490196  0.04313725  0.10980392]\n",
      "   [ 0.0627451   0.05098039  0.11764706]\n",
      "   [ 0.03921569  0.02745098  0.09411765]]\n",
      "\n",
      "  [[ 0.50196078  0.61568627  0.76862745]\n",
      "   [ 0.22745098  0.36470588  0.58431373]\n",
      "   [ 0.09803922  0.23529412  0.41568627]\n",
      "   ..., \n",
      "   [ 0.05098039  0.03921569  0.10588235]\n",
      "   [ 0.04705882  0.03529412  0.10196078]\n",
      "   [ 0.05098039  0.03921569  0.10588235]]]\n",
      "\n",
      "\n",
      " [[[ 0.36862745  0.3372549   0.22745098]\n",
      "   [ 0.39607843  0.35686275  0.23921569]\n",
      "   [ 0.37254902  0.33333333  0.21176471]\n",
      "   ..., \n",
      "   [ 0.56862745  0.54117647  0.41568627]\n",
      "   [ 0.56862745  0.54901961  0.42352941]\n",
      "   [ 0.4745098   0.45882353  0.35294118]]\n",
      "\n",
      "  [[ 0.34901961  0.32941176  0.21568627]\n",
      "   [ 0.38039216  0.34901961  0.23137255]\n",
      "   [ 0.39607843  0.35686275  0.23529412]\n",
      "   ..., \n",
      "   [ 0.57254902  0.5372549   0.41568627]\n",
      "   [ 0.57254902  0.54509804  0.41960784]\n",
      "   [ 0.47843137  0.45882353  0.35294118]]\n",
      "\n",
      "  [[ 0.3372549   0.32941176  0.21176471]\n",
      "   [ 0.36862745  0.34509804  0.22352941]\n",
      "   [ 0.41960784  0.38431373  0.2627451 ]\n",
      "   ..., \n",
      "   [ 0.57254902  0.53333333  0.41568627]\n",
      "   [ 0.57647059  0.54117647  0.41960784]\n",
      "   [ 0.48235294  0.45490196  0.35294118]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.80392157  0.80392157  0.8       ]\n",
      "   [ 0.81568627  0.81568627  0.81176471]\n",
      "   [ 0.78823529  0.78823529  0.78431373]\n",
      "   ..., \n",
      "   [ 0.56862745  0.58431373  0.58431373]\n",
      "   [ 0.58431373  0.59607843  0.61568627]\n",
      "   [ 0.49019608  0.50196078  0.52941176]]\n",
      "\n",
      "  [[ 0.78823529  0.78823529  0.78823529]\n",
      "   [ 0.80392157  0.80392157  0.80392157]\n",
      "   [ 0.77647059  0.77647059  0.77647059]\n",
      "   ..., \n",
      "   [ 0.60392157  0.61960784  0.6627451 ]\n",
      "   [ 0.61960784  0.63529412  0.69411765]\n",
      "   [ 0.5254902   0.54117647  0.6       ]]\n",
      "\n",
      "  [[ 0.74509804  0.74509804  0.74117647]\n",
      "   [ 0.7372549   0.7372549   0.73333333]\n",
      "   [ 0.68627451  0.68627451  0.67843137]\n",
      "   ..., \n",
      "   [ 0.63529412  0.64313725  0.71372549]\n",
      "   [ 0.63921569  0.65098039  0.72156863]\n",
      "   [ 0.52941176  0.5372549   0.60784314]]]\n",
      "\n",
      "\n",
      " [[[ 0.71764706  0.72941176  0.69803922]\n",
      "   [ 0.61960784  0.65490196  0.59607843]\n",
      "   [ 0.65098039  0.6745098   0.62745098]\n",
      "   ..., \n",
      "   [ 0.55686275  0.57647059  0.56470588]\n",
      "   [ 0.5372549   0.57254902  0.55294118]\n",
      "   [ 0.56470588  0.58823529  0.57254902]]\n",
      "\n",
      "  [[ 0.49019608  0.5254902   0.47058824]\n",
      "   [ 0.38039216  0.43529412  0.35294118]\n",
      "   [ 0.39215686  0.43921569  0.37254902]\n",
      "   ..., \n",
      "   [ 0.24705882  0.29019608  0.26666667]\n",
      "   [ 0.23137255  0.29019608  0.2627451 ]\n",
      "   [ 0.2627451   0.30980392  0.28235294]]\n",
      "\n",
      "  [[ 0.41960784  0.4745098   0.40392157]\n",
      "   [ 0.33333333  0.40784314  0.30980392]\n",
      "   [ 0.34509804  0.40784314  0.3254902 ]\n",
      "   ..., \n",
      "   [ 0.24705882  0.30980392  0.27843137]\n",
      "   [ 0.20784314  0.28627451  0.25098039]\n",
      "   [ 0.23529412  0.30196078  0.27058824]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.42352941  0.45490196  0.40392157]\n",
      "   [ 0.38431373  0.41960784  0.34117647]\n",
      "   [ 0.46666667  0.50980392  0.41176471]\n",
      "   ..., \n",
      "   [ 0.44705882  0.49019608  0.44313725]\n",
      "   [ 0.40784314  0.45098039  0.40392157]\n",
      "   [ 0.35686275  0.39607843  0.35294118]]\n",
      "\n",
      "  [[ 0.78039216  0.80392157  0.77254902]\n",
      "   [ 0.77254902  0.79607843  0.74509804]\n",
      "   [ 0.81176471  0.83921569  0.76862745]\n",
      "   ..., \n",
      "   [ 0.79607843  0.81960784  0.79215686]\n",
      "   [ 0.78431373  0.80392157  0.78039216]\n",
      "   [ 0.74117647  0.76078431  0.7372549 ]]\n",
      "\n",
      "  [[ 0.98431373  1.          0.98823529]\n",
      "   [ 0.97254902  0.98823529  0.96470588]\n",
      "   [ 0.97647059  0.99215686  0.95686275]\n",
      "   ..., \n",
      "   [ 0.98039216  0.98431373  0.98039216]\n",
      "   [ 0.98039216  0.98039216  0.98039216]\n",
      "   [ 0.98039216  0.98431373  0.98039216]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.6745098   0.67843137  0.59607843]\n",
      "   [ 0.67058824  0.6745098   0.59607843]\n",
      "   [ 0.69803922  0.69803922  0.61960784]\n",
      "   ..., \n",
      "   [ 0.41960784  0.41176471  0.30196078]\n",
      "   [ 0.41568627  0.40392157  0.30980392]\n",
      "   [ 0.4         0.38823529  0.30588235]]\n",
      "\n",
      "  [[ 0.64705882  0.63921569  0.56078431]\n",
      "   [ 0.62352941  0.61568627  0.54117647]\n",
      "   [ 0.70588235  0.69803922  0.62352941]\n",
      "   ..., \n",
      "   [ 0.45882353  0.43921569  0.3254902 ]\n",
      "   [ 0.45882353  0.43921569  0.3372549 ]\n",
      "   [ 0.43529412  0.41568627  0.3254902 ]]\n",
      "\n",
      "  [[ 0.68235294  0.6627451   0.58823529]\n",
      "   [ 0.61176471  0.59215686  0.51764706]\n",
      "   [ 0.68235294  0.6627451   0.58823529]\n",
      "   ..., \n",
      "   [ 0.47058824  0.44705882  0.3254902 ]\n",
      "   [ 0.4745098   0.44705882  0.3372549 ]\n",
      "   [ 0.46666667  0.43921569  0.34509804]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.47843137  0.45882353  0.36862745]\n",
      "   [ 0.47058824  0.45098039  0.36470588]\n",
      "   [ 0.45490196  0.43921569  0.34901961]\n",
      "   ..., \n",
      "   [ 0.48627451  0.49803922  0.39215686]\n",
      "   [ 0.4745098   0.49411765  0.39215686]\n",
      "   [ 0.45882353  0.47843137  0.38039216]]\n",
      "\n",
      "  [[ 0.43529412  0.41176471  0.30588235]\n",
      "   [ 0.43921569  0.41960784  0.3254902 ]\n",
      "   [ 0.48235294  0.48627451  0.39607843]\n",
      "   ..., \n",
      "   [ 0.47843137  0.45490196  0.32941176]\n",
      "   [ 0.45882353  0.4627451   0.35294118]\n",
      "   [ 0.44313725  0.45882353  0.35294118]]\n",
      "\n",
      "  [[ 0.43921569  0.41176471  0.30196078]\n",
      "   [ 0.45098039  0.42352941  0.32941176]\n",
      "   [ 0.4627451   0.47058824  0.37647059]\n",
      "   ..., \n",
      "   [ 0.48627451  0.45098039  0.31372549]\n",
      "   [ 0.43137255  0.43137255  0.31764706]\n",
      "   [ 0.4         0.41568627  0.30980392]]]\n",
      "\n",
      "\n",
      " [[[ 0.37254902  0.34509804  0.2       ]\n",
      "   [ 0.36078431  0.34509804  0.19215686]\n",
      "   [ 0.35686275  0.34117647  0.19607843]\n",
      "   ..., \n",
      "   [ 0.20784314  0.20392157  0.11764706]\n",
      "   [ 0.20392157  0.2         0.11764706]\n",
      "   [ 0.21176471  0.21176471  0.1254902 ]]\n",
      "\n",
      "  [[ 0.4         0.36862745  0.20784314]\n",
      "   [ 0.41568627  0.38039216  0.2       ]\n",
      "   [ 0.41960784  0.38431373  0.21176471]\n",
      "   ..., \n",
      "   [ 0.20392157  0.20392157  0.1254902 ]\n",
      "   [ 0.19215686  0.18823529  0.10588235]\n",
      "   [ 0.23137255  0.22745098  0.1254902 ]]\n",
      "\n",
      "  [[ 0.41960784  0.38431373  0.20392157]\n",
      "   [ 0.42745098  0.38823529  0.20392157]\n",
      "   [ 0.41176471  0.38039216  0.20392157]\n",
      "   ..., \n",
      "   [ 0.20784314  0.20784314  0.1254902 ]\n",
      "   [ 0.21568627  0.20784314  0.11764706]\n",
      "   [ 0.24313725  0.23529412  0.1254902 ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.37647059  0.36078431  0.23529412]\n",
      "   [ 0.24313725  0.23921569  0.15686275]\n",
      "   [ 0.20784314  0.21176471  0.14117647]\n",
      "   ..., \n",
      "   [ 0.19607843  0.19607843  0.12941176]\n",
      "   [ 0.21568627  0.21568627  0.14117647]\n",
      "   [ 0.23529412  0.22745098  0.15294118]]\n",
      "\n",
      "  [[ 0.31372549  0.29803922  0.2       ]\n",
      "   [ 0.23137255  0.22745098  0.15294118]\n",
      "   [ 0.19607843  0.2         0.12941176]\n",
      "   ..., \n",
      "   [ 0.21960784  0.20392157  0.13333333]\n",
      "   [ 0.25098039  0.23529412  0.15294118]\n",
      "   [ 0.25098039  0.23529412  0.14901961]]\n",
      "\n",
      "  [[ 0.18431373  0.18039216  0.1254902 ]\n",
      "   [ 0.15294118  0.15686275  0.10980392]\n",
      "   [ 0.15294118  0.15686275  0.09803922]\n",
      "   ..., \n",
      "   [ 0.30980392  0.29019608  0.17647059]\n",
      "   [ 0.25098039  0.23137255  0.14901961]\n",
      "   [ 0.23921569  0.22352941  0.14901961]]]\n",
      "\n",
      "\n",
      " [[[ 0.60784314  0.40392157  0.43137255]\n",
      "   [ 0.59607843  0.39215686  0.41960784]\n",
      "   [ 0.60784314  0.40392157  0.43137255]\n",
      "   ..., \n",
      "   [ 0.23137255  0.14901961  0.17254902]\n",
      "   [ 0.22352941  0.15686275  0.18039216]\n",
      "   [ 0.22352941  0.16078431  0.19607843]]\n",
      "\n",
      "  [[ 0.60784314  0.40784314  0.43529412]\n",
      "   [ 0.58039216  0.38039216  0.40784314]\n",
      "   [ 0.6         0.4         0.42745098]\n",
      "   ..., \n",
      "   [ 0.28627451  0.18823529  0.20784314]\n",
      "   [ 0.21960784  0.15294118  0.17647059]\n",
      "   [ 0.21960784  0.16078431  0.19215686]]\n",
      "\n",
      "  [[ 0.61176471  0.41176471  0.43921569]\n",
      "   [ 0.58823529  0.38823529  0.41568627]\n",
      "   [ 0.58039216  0.38039216  0.40784314]\n",
      "   ..., \n",
      "   [ 0.41176471  0.30980392  0.3254902 ]\n",
      "   [ 0.23137255  0.16470588  0.18823529]\n",
      "   [ 0.2         0.14117647  0.17254902]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.45490196  0.43921569  0.5254902 ]\n",
      "   [ 0.44313725  0.43529412  0.50980392]\n",
      "   [ 0.44313725  0.44313725  0.50196078]\n",
      "   ..., \n",
      "   [ 0.42745098  0.38039216  0.44705882]\n",
      "   [ 0.28235294  0.23921569  0.29803922]\n",
      "   [ 0.42352941  0.37647059  0.43529412]]\n",
      "\n",
      "  [[ 0.45490196  0.44313725  0.52156863]\n",
      "   [ 0.44705882  0.43529412  0.50980392]\n",
      "   [ 0.45098039  0.43921569  0.51372549]\n",
      "   ..., \n",
      "   [ 0.43137255  0.41176471  0.48627451]\n",
      "   [ 0.23137255  0.19607843  0.26666667]\n",
      "   [ 0.29411765  0.23921569  0.30980392]]\n",
      "\n",
      "  [[ 0.46666667  0.45490196  0.52941176]\n",
      "   [ 0.45490196  0.44313725  0.51764706]\n",
      "   [ 0.45490196  0.44313725  0.51764706]\n",
      "   ..., \n",
      "   [ 0.47058824  0.45882353  0.5372549 ]\n",
      "   [ 0.39607843  0.37254902  0.44705882]\n",
      "   [ 0.24705882  0.19607843  0.26666667]]]]\n",
      "[[ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[[[ 0.69803922  0.69019608  0.74117647]\n",
      "   [ 0.69803922  0.69019608  0.74117647]\n",
      "   [ 0.69803922  0.69019608  0.74117647]\n",
      "   ..., \n",
      "   [ 0.66666667  0.65882353  0.70588235]\n",
      "   [ 0.65882353  0.65098039  0.69411765]\n",
      "   [ 0.64705882  0.63921569  0.68235294]]\n",
      "\n",
      "  [[ 0.70588235  0.69803922  0.74901961]\n",
      "   [ 0.70196078  0.69411765  0.74509804]\n",
      "   [ 0.70588235  0.69803922  0.74901961]\n",
      "   ..., \n",
      "   [ 0.67843137  0.67058824  0.71372549]\n",
      "   [ 0.67058824  0.6627451   0.70588235]\n",
      "   [ 0.65882353  0.65098039  0.69411765]]\n",
      "\n",
      "  [[ 0.69411765  0.68627451  0.7372549 ]\n",
      "   [ 0.69411765  0.68627451  0.7372549 ]\n",
      "   [ 0.69803922  0.69019608  0.74117647]\n",
      "   ..., \n",
      "   [ 0.67058824  0.6627451   0.70588235]\n",
      "   [ 0.6627451   0.65490196  0.69803922]\n",
      "   [ 0.65490196  0.64705882  0.69019608]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.43921569  0.41960784  0.41960784]\n",
      "   [ 0.44313725  0.42745098  0.42352941]\n",
      "   [ 0.44705882  0.43137255  0.43137255]\n",
      "   ..., \n",
      "   [ 0.39215686  0.38039216  0.36862745]\n",
      "   [ 0.38431373  0.36862745  0.36470588]\n",
      "   [ 0.39607843  0.37254902  0.37254902]]\n",
      "\n",
      "  [[ 0.43921569  0.4         0.39607843]\n",
      "   [ 0.43921569  0.40392157  0.4       ]\n",
      "   [ 0.44313725  0.40392157  0.40392157]\n",
      "   ..., \n",
      "   [ 0.4         0.37254902  0.36470588]\n",
      "   [ 0.4         0.36470588  0.35686275]\n",
      "   [ 0.4         0.36078431  0.35686275]]\n",
      "\n",
      "  [[ 0.40392157  0.37647059  0.36078431]\n",
      "   [ 0.39215686  0.36470588  0.35294118]\n",
      "   [ 0.40392157  0.37254902  0.36862745]\n",
      "   ..., \n",
      "   [ 0.36078431  0.32941176  0.31372549]\n",
      "   [ 0.36470588  0.3372549   0.31372549]\n",
      "   [ 0.35686275  0.32941176  0.30196078]]]\n",
      "\n",
      "\n",
      " [[[ 0.11372549  0.16862745  0.03921569]\n",
      "   [ 0.08627451  0.14117647  0.01568627]\n",
      "   [ 0.09803922  0.14509804  0.0627451 ]\n",
      "   ..., \n",
      "   [ 0.77254902  0.85882353  0.5372549 ]\n",
      "   [ 0.77647059  0.85882353  0.5372549 ]\n",
      "   [ 0.78039216  0.87058824  0.54901961]]\n",
      "\n",
      "  [[ 0.12156863  0.18039216  0.03529412]\n",
      "   [ 0.10588235  0.16078431  0.02352941]\n",
      "   [ 0.06666667  0.11372549  0.02352941]\n",
      "   ..., \n",
      "   [ 0.82352941  0.90980392  0.58039216]\n",
      "   [ 0.81960784  0.90588235  0.58039216]\n",
      "   [ 0.81960784  0.90588235  0.58039216]]\n",
      "\n",
      "  [[ 0.15686275  0.21568627  0.0627451 ]\n",
      "   [ 0.12156863  0.17647059  0.03137255]\n",
      "   [ 0.07843137  0.12941176  0.02745098]\n",
      "   ..., \n",
      "   [ 0.82352941  0.90980392  0.58823529]\n",
      "   [ 0.82352941  0.90980392  0.58431373]\n",
      "   [ 0.82352941  0.90980392  0.58431373]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.17647059  0.14901961  0.09019608]\n",
      "   [ 0.09411765  0.08235294  0.04313725]\n",
      "   [ 0.0627451   0.05490196  0.02745098]\n",
      "   ..., \n",
      "   [ 0.09803922  0.11372549  0.1254902 ]\n",
      "   [ 0.09411765  0.10980392  0.12156863]\n",
      "   [ 0.09411765  0.10980392  0.12156863]]\n",
      "\n",
      "  [[ 0.08235294  0.07058824  0.02745098]\n",
      "   [ 0.07058824  0.05098039  0.01176471]\n",
      "   [ 0.10588235  0.0627451   0.01960784]\n",
      "   ..., \n",
      "   [ 0.10196078  0.11764706  0.12941176]\n",
      "   [ 0.11372549  0.12941176  0.14117647]\n",
      "   [ 0.10980392  0.1254902   0.1372549 ]]\n",
      "\n",
      "  [[ 0.20784314  0.15686275  0.09019608]\n",
      "   [ 0.31764706  0.24313725  0.14901961]\n",
      "   [ 0.38039216  0.2745098   0.16862745]\n",
      "   ..., \n",
      "   [ 0.08627451  0.10196078  0.11372549]\n",
      "   [ 0.09411765  0.10980392  0.12156863]\n",
      "   [ 0.09019608  0.10588235  0.11764706]]]\n",
      "\n",
      "\n",
      " [[[ 0.14117647  0.25490196  0.4       ]\n",
      "   [ 0.12941176  0.21568627  0.42352941]\n",
      "   [ 0.08235294  0.18431373  0.4627451 ]\n",
      "   ..., \n",
      "   [ 0.10196078  0.1254902   0.15686275]\n",
      "   [ 0.10196078  0.12156863  0.12156863]\n",
      "   [ 0.11372549  0.11372549  0.12156863]]\n",
      "\n",
      "  [[ 0.21568627  0.41960784  0.47058824]\n",
      "   [ 0.18431373  0.36862745  0.42352941]\n",
      "   [ 0.05882353  0.24705882  0.44313725]\n",
      "   ..., \n",
      "   [ 0.08627451  0.2         0.41176471]\n",
      "   [ 0.09019608  0.19215686  0.39215686]\n",
      "   [ 0.08235294  0.18039216  0.38039216]]\n",
      "\n",
      "  [[ 0.32156863  0.45490196  0.44705882]\n",
      "   [ 0.36862745  0.49803922  0.4       ]\n",
      "   [ 0.30980392  0.45882353  0.42352941]\n",
      "   ..., \n",
      "   [ 0.18431373  0.3254902   0.6       ]\n",
      "   [ 0.18431373  0.3372549   0.61176471]\n",
      "   [ 0.17647059  0.33333333  0.6       ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.62352941  0.62745098  0.58039216]\n",
      "   [ 0.63529412  0.62352941  0.58431373]\n",
      "   [ 0.65098039  0.62745098  0.59215686]\n",
      "   ..., \n",
      "   [ 0.73333333  0.70588235  0.69411765]\n",
      "   [ 0.7254902   0.69019608  0.68235294]\n",
      "   [ 0.71764706  0.68235294  0.6745098 ]]\n",
      "\n",
      "  [[ 0.65098039  0.6627451   0.62745098]\n",
      "   [ 0.66666667  0.6627451   0.63137255]\n",
      "   [ 0.67843137  0.6627451   0.63529412]\n",
      "   ..., \n",
      "   [ 0.71764706  0.69019608  0.68235294]\n",
      "   [ 0.70980392  0.67843137  0.67058824]\n",
      "   [ 0.70588235  0.6745098   0.67058824]]\n",
      "\n",
      "  [[ 0.65882353  0.68235294  0.65098039]\n",
      "   [ 0.67058824  0.67843137  0.65490196]\n",
      "   [ 0.68627451  0.67843137  0.65882353]\n",
      "   ..., \n",
      "   [ 0.71372549  0.69019608  0.67843137]\n",
      "   [ 0.70980392  0.6745098   0.66666667]\n",
      "   [ 0.70588235  0.6745098   0.66666667]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.27058824  0.34509804  0.44705882]\n",
      "   [ 0.35294118  0.4745098   0.58823529]\n",
      "   [ 0.35294118  0.49803922  0.61960784]\n",
      "   ..., \n",
      "   [ 0.00784314  0.01176471  0.07058824]\n",
      "   [ 0.00784314  0.00784314  0.0627451 ]\n",
      "   [ 0.00784314  0.00784314  0.05882353]]\n",
      "\n",
      "  [[ 0.11372549  0.15294118  0.25098039]\n",
      "   [ 0.05882353  0.10588235  0.20784314]\n",
      "   [ 0.05098039  0.09803922  0.2       ]\n",
      "   ..., \n",
      "   [ 0.00392157  0.          0.00784314]\n",
      "   [ 0.          0.          0.00392157]\n",
      "   [ 0.          0.00392157  0.00784314]]\n",
      "\n",
      "  [[ 0.01568627  0.01176471  0.01960784]\n",
      "   [ 0.01568627  0.00392157  0.00784314]\n",
      "   [ 0.01176471  0.00392157  0.00784314]\n",
      "   ..., \n",
      "   [ 0.          0.          0.00392157]\n",
      "   [ 0.          0.          0.00784314]\n",
      "   [ 0.          0.          0.01176471]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.00392157  0.00392157  0.01960784]\n",
      "   [ 0.          0.          0.00392157]\n",
      "   [ 0.          0.          0.        ]\n",
      "   ..., \n",
      "   [ 0.03921569  0.03137255  0.04313725]\n",
      "   [ 0.00784314  0.00784314  0.01568627]\n",
      "   [ 0.00392157  0.00392157  0.01568627]]\n",
      "\n",
      "  [[ 0.03137255  0.0627451   0.12941176]\n",
      "   [ 0.00392157  0.01568627  0.05098039]\n",
      "   [ 0.          0.00392157  0.01176471]\n",
      "   ..., \n",
      "   [ 0.02745098  0.03921569  0.09019608]\n",
      "   [ 0.01176471  0.01568627  0.03921569]\n",
      "   [ 0.00392157  0.00392157  0.01176471]]\n",
      "\n",
      "  [[ 0.14509804  0.25098039  0.42352941]\n",
      "   [ 0.09411765  0.16862745  0.30196078]\n",
      "   [ 0.03921569  0.0745098   0.15294118]\n",
      "   ..., \n",
      "   [ 0.07843137  0.11764706  0.23921569]\n",
      "   [ 0.05098039  0.07843137  0.16862745]\n",
      "   [ 0.02352941  0.03921569  0.09019608]]]\n",
      "\n",
      "\n",
      " [[[ 0.7254902   0.79215686  0.81176471]\n",
      "   [ 0.67843137  0.77647059  0.80392157]\n",
      "   [ 0.69019608  0.81176471  0.85098039]\n",
      "   ..., \n",
      "   [ 0.14509804  0.17647059  0.24313725]\n",
      "   [ 0.10196078  0.1372549   0.2       ]\n",
      "   [ 0.12941176  0.19607843  0.27058824]]\n",
      "\n",
      "  [[ 0.42745098  0.47058824  0.46666667]\n",
      "   [ 0.4627451   0.52941176  0.52941176]\n",
      "   [ 0.4745098   0.56078431  0.56470588]\n",
      "   ..., \n",
      "   [ 0.16862745  0.19607843  0.23529412]\n",
      "   [ 0.12941176  0.13333333  0.16862745]\n",
      "   [ 0.15686275  0.18823529  0.22745098]]\n",
      "\n",
      "  [[ 0.20392157  0.22745098  0.21568627]\n",
      "   [ 0.22745098  0.26666667  0.25098039]\n",
      "   [ 0.22745098  0.28235294  0.2627451 ]\n",
      "   ..., \n",
      "   [ 0.18039216  0.22745098  0.26666667]\n",
      "   [ 0.15686275  0.18431373  0.22745098]\n",
      "   [ 0.18431373  0.22745098  0.26666667]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.63529412  0.62745098  0.6745098 ]\n",
      "   [ 0.61960784  0.61176471  0.65490196]\n",
      "   [ 0.62352941  0.61568627  0.65882353]\n",
      "   ..., \n",
      "   [ 0.05882353  0.05098039  0.09019608]\n",
      "   [ 0.05490196  0.04705882  0.09019608]\n",
      "   [ 0.07058824  0.0627451   0.10588235]]\n",
      "\n",
      "  [[ 0.61176471  0.60392157  0.65882353]\n",
      "   [ 0.59607843  0.58823529  0.63921569]\n",
      "   [ 0.59607843  0.58823529  0.63921569]\n",
      "   ..., \n",
      "   [ 0.05098039  0.04313725  0.08235294]\n",
      "   [ 0.05882353  0.05098039  0.09411765]\n",
      "   [ 0.1254902   0.11764706  0.16078431]]\n",
      "\n",
      "  [[ 0.58431373  0.57647059  0.63137255]\n",
      "   [ 0.56470588  0.55686275  0.61176471]\n",
      "   [ 0.57254902  0.56470588  0.61960784]\n",
      "   ..., \n",
      "   [ 0.0627451   0.05490196  0.09411765]\n",
      "   [ 0.20392157  0.19607843  0.23921569]\n",
      "   [ 0.38431373  0.37647059  0.41960784]]]\n",
      "\n",
      "\n",
      " [[[ 0.76470588  0.71764706  0.67058824]\n",
      "   [ 0.75686275  0.70980392  0.6627451 ]\n",
      "   [ 0.76078431  0.71372549  0.66666667]\n",
      "   ..., \n",
      "   [ 0.22352941  0.22352941  0.22352941]\n",
      "   [ 0.20392157  0.20392157  0.20392157]\n",
      "   [ 0.03137255  0.03137255  0.03137255]]\n",
      "\n",
      "  [[ 0.77254902  0.72156863  0.67843137]\n",
      "   [ 0.76470588  0.71764706  0.6745098 ]\n",
      "   [ 0.77254902  0.7254902   0.68235294]\n",
      "   ..., \n",
      "   [ 0.34117647  0.34117647  0.34117647]\n",
      "   [ 0.31372549  0.31372549  0.31372549]\n",
      "   [ 0.03921569  0.03921569  0.03921569]]\n",
      "\n",
      "  [[ 0.77254902  0.72156863  0.68627451]\n",
      "   [ 0.76862745  0.71764706  0.68235294]\n",
      "   [ 0.77647059  0.7254902   0.69411765]\n",
      "   ..., \n",
      "   [ 0.43137255  0.43137255  0.43137255]\n",
      "   [ 0.41568627  0.41568627  0.41568627]\n",
      "   [ 0.04705882  0.04705882  0.04705882]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.78039216  0.7254902   0.69411765]\n",
      "   [ 0.76862745  0.72156863  0.68627451]\n",
      "   [ 0.78039216  0.74117647  0.69803922]\n",
      "   ..., \n",
      "   [ 0.13333333  0.10980392  0.08235294]\n",
      "   [ 0.10980392  0.09019608  0.07058824]\n",
      "   [ 0.08627451  0.0745098   0.0627451 ]]\n",
      "\n",
      "  [[ 0.77254902  0.7254902   0.69019608]\n",
      "   [ 0.76470588  0.71764706  0.68235294]\n",
      "   [ 0.77254902  0.72941176  0.69411765]\n",
      "   ..., \n",
      "   [ 0.15294118  0.12156863  0.08235294]\n",
      "   [ 0.14509804  0.12156863  0.08627451]\n",
      "   [ 0.1372549   0.11372549  0.08627451]]\n",
      "\n",
      "  [[ 0.75686275  0.71764706  0.68235294]\n",
      "   [ 0.75686275  0.70588235  0.6745098 ]\n",
      "   [ 0.76470588  0.70980392  0.67843137]\n",
      "   ..., \n",
      "   [ 0.16470588  0.12941176  0.08235294]\n",
      "   [ 0.16862745  0.12941176  0.09019608]\n",
      "   [ 0.16078431  0.1254902   0.09411765]]]]\n",
      "[[ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[[[ 1.          1.          0.99607843]\n",
      "   [ 0.98823529  0.98823529  0.98823529]\n",
      "   [ 0.99215686  0.98823529  0.99607843]\n",
      "   ..., \n",
      "   [ 0.64705882  0.69411765  0.72156863]\n",
      "   [ 0.95294118  0.96470588  0.96862745]\n",
      "   [ 0.99607843  0.99215686  0.98823529]]\n",
      "\n",
      "  [[ 1.          1.          0.99607843]\n",
      "   [ 0.98823529  0.98823529  0.98823529]\n",
      "   [ 0.99607843  0.99607843  1.        ]\n",
      "   ..., \n",
      "   [ 0.50980392  0.56470588  0.63137255]\n",
      "   [ 0.88235294  0.90980392  0.9372549 ]\n",
      "   [ 0.99215686  1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 0.99607843  0.99607843  0.99607843]\n",
      "   [ 0.97254902  0.96862745  0.97647059]\n",
      "   ..., \n",
      "   [ 0.55294118  0.60784314  0.68627451]\n",
      "   [ 0.8627451   0.89019608  0.92156863]\n",
      "   [ 0.99215686  1.          1.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.91372549  0.91764706  0.91764706]\n",
      "   [ 0.84705882  0.84705882  0.84705882]\n",
      "   [ 0.94509804  0.94509804  0.94509804]\n",
      "   ..., \n",
      "   [ 0.03529412  0.04313725  0.04313725]\n",
      "   [ 0.07058824  0.0745098   0.0745098 ]\n",
      "   [ 0.6627451   0.67058824  0.66666667]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.08235294  0.09019608  0.08627451]\n",
      "   [ 0.44313725  0.45098039  0.44705882]\n",
      "   [ 0.92156863  0.92941176  0.9254902 ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 0.98431373  0.98431373  0.98431373]\n",
      "   [ 0.99215686  0.99215686  0.99215686]\n",
      "   ..., \n",
      "   [ 0.6745098   0.68235294  0.67843137]\n",
      "   [ 0.90196078  0.90980392  0.90588235]\n",
      "   [ 0.96862745  0.97254902  0.97254902]]]\n",
      "\n",
      "\n",
      " [[[ 0.49803922  0.56862745  0.65490196]\n",
      "   [ 0.49411765  0.56470588  0.65098039]\n",
      "   [ 0.49803922  0.56862745  0.65490196]\n",
      "   ..., \n",
      "   [ 0.49019608  0.55686275  0.62352941]\n",
      "   [ 0.49019608  0.55686275  0.62352941]\n",
      "   [ 0.48627451  0.55294118  0.61960784]]\n",
      "\n",
      "  [[ 0.49019608  0.56078431  0.64313725]\n",
      "   [ 0.49019608  0.56078431  0.63921569]\n",
      "   [ 0.49411765  0.56470588  0.64313725]\n",
      "   ..., \n",
      "   [ 0.49019608  0.55686275  0.61568627]\n",
      "   [ 0.48627451  0.55686275  0.61176471]\n",
      "   [ 0.48627451  0.55294118  0.61176471]]\n",
      "\n",
      "  [[ 0.49411765  0.56862745  0.63529412]\n",
      "   [ 0.48627451  0.56078431  0.62745098]\n",
      "   [ 0.49411765  0.56862745  0.63529412]\n",
      "   ..., \n",
      "   [ 0.48627451  0.56078431  0.61176471]\n",
      "   [ 0.48235294  0.55294118  0.60784314]\n",
      "   [ 0.48235294  0.55294118  0.60784314]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.32941176  0.40784314  0.4627451 ]\n",
      "   [ 0.33333333  0.40784314  0.4627451 ]\n",
      "   [ 0.34117647  0.41568627  0.47058824]\n",
      "   ..., \n",
      "   [ 0.25490196  0.3254902   0.37254902]\n",
      "   [ 0.30980392  0.38039216  0.42745098]\n",
      "   [ 0.34509804  0.41568627  0.4627451 ]]\n",
      "\n",
      "  [[ 0.3372549   0.41176471  0.47058824]\n",
      "   [ 0.3254902   0.4         0.45490196]\n",
      "   [ 0.3254902   0.4         0.45490196]\n",
      "   ..., \n",
      "   [ 0.28627451  0.35686275  0.40392157]\n",
      "   [ 0.3254902   0.39607843  0.44313725]\n",
      "   [ 0.34117647  0.41176471  0.45882353]]\n",
      "\n",
      "  [[ 0.33333333  0.40784314  0.4627451 ]\n",
      "   [ 0.33333333  0.40392157  0.45882353]\n",
      "   [ 0.3254902   0.4         0.45490196]\n",
      "   ..., \n",
      "   [ 0.28235294  0.35294118  0.4       ]\n",
      "   [ 0.30588235  0.37647059  0.42352941]\n",
      "   [ 0.32156863  0.39215686  0.43921569]]]\n",
      "\n",
      "\n",
      " [[[ 0.45490196  0.27843137  0.10196078]\n",
      "   [ 0.25098039  0.13333333  0.03921569]\n",
      "   [ 0.0745098   0.02352941  0.00784314]\n",
      "   ..., \n",
      "   [ 0.58039216  0.32941176  0.14901961]\n",
      "   [ 0.6627451   0.37647059  0.18039216]\n",
      "   [ 0.7372549   0.44705882  0.23137255]]\n",
      "\n",
      "  [[ 0.44705882  0.26666667  0.08627451]\n",
      "   [ 0.25098039  0.1372549   0.04313725]\n",
      "   [ 0.07058824  0.02352941  0.00784314]\n",
      "   ..., \n",
      "   [ 0.58431373  0.32941176  0.16862745]\n",
      "   [ 0.63921569  0.36862745  0.17647059]\n",
      "   [ 0.7254902   0.44705882  0.23137255]]\n",
      "\n",
      "  [[ 0.44705882  0.25882353  0.09019608]\n",
      "   [ 0.24313725  0.13333333  0.04313725]\n",
      "   [ 0.06666667  0.02352941  0.00784314]\n",
      "   ..., \n",
      "   [ 0.61568627  0.35294118  0.18431373]\n",
      "   [ 0.68627451  0.4         0.2       ]\n",
      "   [ 0.7254902   0.44705882  0.22745098]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.94509804  0.94117647  0.91764706]\n",
      "   [ 0.95294118  0.94901961  0.9254902 ]\n",
      "   [ 0.94509804  0.94509804  0.9254902 ]\n",
      "   ..., \n",
      "   [ 0.12156863  0.07058824  0.01568627]\n",
      "   [ 0.1372549   0.07843137  0.01960784]\n",
      "   [ 0.15294118  0.07843137  0.01960784]]\n",
      "\n",
      "  [[ 0.84313725  0.82745098  0.78823529]\n",
      "   [ 0.90196078  0.89019608  0.8627451 ]\n",
      "   [ 0.92941176  0.92156863  0.90196078]\n",
      "   ..., \n",
      "   [ 0.09019608  0.05098039  0.01176471]\n",
      "   [ 0.09803922  0.05098039  0.00784314]\n",
      "   [ 0.10196078  0.05098039  0.01176471]]\n",
      "\n",
      "  [[ 0.47058824  0.42352941  0.37254902]\n",
      "   [ 0.54117647  0.49803922  0.45098039]\n",
      "   [ 0.60784314  0.57254902  0.5254902 ]\n",
      "   ..., \n",
      "   [ 0.17254902  0.09803922  0.02745098]\n",
      "   [ 0.16078431  0.08627451  0.02352941]\n",
      "   [ 0.14901961  0.0745098   0.01960784]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.23921569  0.28627451  0.29803922]\n",
      "   [ 0.18039216  0.22745098  0.26666667]\n",
      "   [ 0.15294118  0.19215686  0.25882353]\n",
      "   ..., \n",
      "   [ 0.27843137  0.35294118  0.31372549]\n",
      "   [ 0.24313725  0.30588235  0.29411765]\n",
      "   [ 0.17647059  0.22745098  0.23921569]]\n",
      "\n",
      "  [[ 0.24705882  0.29411765  0.30196078]\n",
      "   [ 0.17647059  0.22745098  0.2627451 ]\n",
      "   [ 0.1254902   0.16862745  0.22745098]\n",
      "   ..., \n",
      "   [ 0.28627451  0.34901961  0.32156863]\n",
      "   [ 0.27843137  0.32941176  0.31372549]\n",
      "   [ 0.19607843  0.23529412  0.24313725]]\n",
      "\n",
      "  [[ 0.24705882  0.31372549  0.30196078]\n",
      "   [ 0.22352941  0.29411765  0.29411765]\n",
      "   [ 0.24705882  0.30980392  0.31764706]\n",
      "   ..., \n",
      "   [ 0.32156863  0.37647059  0.35686275]\n",
      "   [ 0.29803922  0.34509804  0.32156863]\n",
      "   [ 0.20784314  0.24705882  0.24313725]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.51372549  0.52156863  0.4       ]\n",
      "   [ 0.61176471  0.60392157  0.4627451 ]\n",
      "   [ 0.63137255  0.61568627  0.4745098 ]\n",
      "   ..., \n",
      "   [ 0.91764706  0.8745098   0.67843137]\n",
      "   [ 0.8627451   0.8         0.61176471]\n",
      "   [ 0.70980392  0.65098039  0.49411765]]\n",
      "\n",
      "  [[ 0.41176471  0.42352941  0.3254902 ]\n",
      "   [ 0.41960784  0.42352941  0.30980392]\n",
      "   [ 0.45098039  0.45098039  0.32941176]\n",
      "   ..., \n",
      "   [ 0.92156863  0.86666667  0.6745098 ]\n",
      "   [ 0.89803922  0.81568627  0.63137255]\n",
      "   [ 0.74901961  0.66666667  0.51372549]]\n",
      "\n",
      "  [[ 0.2627451   0.29019608  0.23921569]\n",
      "   [ 0.30588235  0.3254902   0.26666667]\n",
      "   [ 0.43921569  0.45098039  0.35294118]\n",
      "   ..., \n",
      "   [ 0.89019608  0.80784314  0.58823529]\n",
      "   [ 0.85098039  0.75294118  0.54509804]\n",
      "   [ 0.72156863  0.62745098  0.45882353]]]\n",
      "\n",
      "\n",
      " [[[ 0.03921569  0.01568627  0.05490196]\n",
      "   [ 0.04313725  0.02352941  0.05882353]\n",
      "   [ 0.07843137  0.08627451  0.09019608]\n",
      "   ..., \n",
      "   [ 0.23137255  0.27843137  0.21568627]\n",
      "   [ 0.22352941  0.2745098   0.21568627]\n",
      "   [ 0.20784314  0.26666667  0.23137255]]\n",
      "\n",
      "  [[ 0.03921569  0.01568627  0.05490196]\n",
      "   [ 0.04313725  0.03529412  0.05882353]\n",
      "   [ 0.09803922  0.1254902   0.10980392]\n",
      "   ..., \n",
      "   [ 0.21568627  0.23921569  0.18823529]\n",
      "   [ 0.25882353  0.29803922  0.22745098]\n",
      "   [ 0.18823529  0.24705882  0.21176471]]\n",
      "\n",
      "  [[ 0.04705882  0.02352941  0.0627451 ]\n",
      "   [ 0.04313725  0.03921569  0.05882353]\n",
      "   [ 0.14901961  0.18431373  0.14901961]\n",
      "   ..., \n",
      "   [ 0.18431373  0.20392157  0.16470588]\n",
      "   [ 0.22352941  0.25882353  0.19215686]\n",
      "   [ 0.20392157  0.25098039  0.2       ]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.69411765  0.6627451   0.71764706]\n",
      "   [ 0.70588235  0.6627451   0.72156863]\n",
      "   [ 0.72156863  0.6745098   0.74509804]\n",
      "   ..., \n",
      "   [ 0.6745098   0.62352941  0.68235294]\n",
      "   [ 0.66666667  0.61568627  0.67058824]\n",
      "   [ 0.64313725  0.58823529  0.64705882]]\n",
      "\n",
      "  [[ 0.62352941  0.61568627  0.69019608]\n",
      "   [ 0.63529412  0.61568627  0.69411765]\n",
      "   [ 0.65490196  0.63529412  0.71764706]\n",
      "   ..., \n",
      "   [ 0.72156863  0.69803922  0.78431373]\n",
      "   [ 0.70980392  0.68627451  0.77254902]\n",
      "   [ 0.69803922  0.67843137  0.76470588]]\n",
      "\n",
      "  [[ 0.61960784  0.61960784  0.72941176]\n",
      "   [ 0.62352941  0.62352941  0.73333333]\n",
      "   [ 0.63921569  0.63921569  0.74509804]\n",
      "   ..., \n",
      "   [ 0.70980392  0.70588235  0.82745098]\n",
      "   [ 0.70196078  0.69411765  0.81568627]\n",
      "   [ 0.68627451  0.68235294  0.80392157]]]\n",
      "\n",
      "\n",
      " [[[ 0.68627451  0.75686275  0.89803922]\n",
      "   [ 0.6745098   0.75294118  0.9254902 ]\n",
      "   [ 0.67058824  0.75686275  0.94117647]\n",
      "   ..., \n",
      "   [ 0.75686275  0.80784314  0.93333333]\n",
      "   [ 0.76862745  0.80784314  0.90588235]\n",
      "   [ 0.76078431  0.79607843  0.89019608]]\n",
      "\n",
      "  [[ 0.65490196  0.73333333  0.88627451]\n",
      "   [ 0.64313725  0.73333333  0.90196078]\n",
      "   [ 0.64313725  0.7372549   0.90980392]\n",
      "   ..., \n",
      "   [ 0.70196078  0.75686275  0.88235294]\n",
      "   [ 0.69803922  0.74901961  0.85098039]\n",
      "   [ 0.69019608  0.73333333  0.83137255]]\n",
      "\n",
      "  [[ 0.65490196  0.72156863  0.86666667]\n",
      "   [ 0.65490196  0.72941176  0.87058824]\n",
      "   [ 0.67058824  0.72941176  0.85098039]\n",
      "   ..., \n",
      "   [ 0.69019608  0.74901961  0.87843137]\n",
      "   [ 0.68235294  0.74117647  0.85098039]\n",
      "   [ 0.67058824  0.72156863  0.82745098]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.33333333  0.32941176  0.39607843]\n",
      "   [ 0.33333333  0.32156863  0.36470588]\n",
      "   [ 0.36078431  0.32941176  0.32156863]\n",
      "   ..., \n",
      "   [ 0.4745098   0.44313725  0.47058824]\n",
      "   [ 0.41960784  0.40392157  0.46666667]\n",
      "   [ 0.45882353  0.43921569  0.50588235]]\n",
      "\n",
      "  [[ 0.33333333  0.34117647  0.4       ]\n",
      "   [ 0.32941176  0.31764706  0.34901961]\n",
      "   [ 0.34117647  0.30980392  0.30588235]\n",
      "   ..., \n",
      "   [ 0.30196078  0.28235294  0.32941176]\n",
      "   [ 0.43137255  0.40392157  0.47058824]\n",
      "   [ 0.44705882  0.41960784  0.48627451]]\n",
      "\n",
      "  [[ 0.32156863  0.32941176  0.37647059]\n",
      "   [ 0.29411765  0.29019608  0.32156863]\n",
      "   [ 0.22352941  0.19607843  0.21568627]\n",
      "   ..., \n",
      "   [ 0.30196078  0.26666667  0.30588235]\n",
      "   [ 0.35686275  0.30588235  0.35294118]\n",
      "   [ 0.35686275  0.30588235  0.35294118]]]]\n",
      "[[ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "[[[[ 0.54901961  0.49019608  0.45098039]\n",
      "   [ 0.57254902  0.50980392  0.47843137]\n",
      "   [ 0.56078431  0.49803922  0.47843137]\n",
      "   ..., \n",
      "   [ 0.66666667  0.56862745  0.51372549]\n",
      "   [ 0.69019608  0.58823529  0.5254902 ]\n",
      "   [ 0.66666667  0.57647059  0.52156863]]\n",
      "\n",
      "  [[ 0.4745098   0.42352941  0.50588235]\n",
      "   [ 0.50980392  0.4627451   0.54509804]\n",
      "   [ 0.5254902   0.4745098   0.56078431]\n",
      "   ..., \n",
      "   [ 0.63921569  0.55294118  0.61568627]\n",
      "   [ 0.66666667  0.57254902  0.63137255]\n",
      "   [ 0.66666667  0.58039216  0.63137255]]\n",
      "\n",
      "  [[ 0.59607843  0.54509804  0.68235294]\n",
      "   [ 0.61568627  0.56862745  0.70196078]\n",
      "   [ 0.60784314  0.56078431  0.68627451]\n",
      "   ..., \n",
      "   [ 0.69411765  0.60392157  0.75686275]\n",
      "   [ 0.70980392  0.61176471  0.76078431]\n",
      "   [ 0.71764706  0.62745098  0.76078431]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.49019608  0.43137255  0.4       ]\n",
      "   [ 0.50588235  0.43921569  0.40392157]\n",
      "   [ 0.29803922  0.2627451   0.18431373]\n",
      "   ..., \n",
      "   [ 0.65882353  0.5372549   0.47058824]\n",
      "   [ 0.61960784  0.49411765  0.40392157]\n",
      "   [ 0.57254902  0.45490196  0.34117647]]\n",
      "\n",
      "  [[ 0.33333333  0.30196078  0.2745098 ]\n",
      "   [ 0.36862745  0.31764706  0.27843137]\n",
      "   [ 0.29019608  0.25490196  0.17647059]\n",
      "   ..., \n",
      "   [ 0.63529412  0.51764706  0.41568627]\n",
      "   [ 0.65098039  0.5254902   0.39215686]\n",
      "   [ 0.61960784  0.50196078  0.36078431]]\n",
      "\n",
      "  [[ 0.49019608  0.43921569  0.43529412]\n",
      "   [ 0.50980392  0.44313725  0.43529412]\n",
      "   [ 0.41176471  0.35686275  0.29411765]\n",
      "   ..., \n",
      "   [ 0.51764706  0.41568627  0.30588235]\n",
      "   [ 0.50980392  0.39607843  0.25098039]\n",
      "   [ 0.55686275  0.45098039  0.30588235]]]\n",
      "\n",
      "\n",
      " [[[ 0.39215686  0.42745098  0.32941176]\n",
      "   [ 0.47843137  0.49411765  0.42745098]\n",
      "   [ 0.34117647  0.34117647  0.29803922]\n",
      "   ..., \n",
      "   [ 0.29411765  0.30588235  0.27058824]\n",
      "   [ 0.2745098   0.28627451  0.25098039]\n",
      "   [ 0.2745098   0.28627451  0.25098039]]\n",
      "\n",
      "  [[ 0.3372549   0.38823529  0.27843137]\n",
      "   [ 0.29803922  0.32941176  0.25882353]\n",
      "   [ 0.23529412  0.25098039  0.21176471]\n",
      "   ..., \n",
      "   [ 0.30588235  0.31764706  0.28235294]\n",
      "   [ 0.29803922  0.30980392  0.2745098 ]\n",
      "   [ 0.32156863  0.33333333  0.29803922]]\n",
      "\n",
      "  [[ 0.32941176  0.39215686  0.28627451]\n",
      "   [ 0.3254902   0.37254902  0.29411765]\n",
      "   [ 0.30196078  0.3372549   0.28235294]\n",
      "   ..., \n",
      "   [ 0.29019608  0.30196078  0.26666667]\n",
      "   [ 0.28627451  0.29803922  0.2627451 ]\n",
      "   [ 0.3254902   0.3372549   0.30196078]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.25098039  0.30196078  0.30980392]\n",
      "   [ 0.47843137  0.52156863  0.56470588]\n",
      "   [ 0.5254902   0.56862745  0.61176471]\n",
      "   ..., \n",
      "   [ 0.41176471  0.48235294  0.47058824]\n",
      "   [ 0.32941176  0.40392157  0.35686275]\n",
      "   [ 0.23529412  0.34509804  0.24705882]]\n",
      "\n",
      "  [[ 0.17254902  0.2         0.21960784]\n",
      "   [ 0.30588235  0.32941176  0.36862745]\n",
      "   [ 0.37647059  0.39607843  0.43137255]\n",
      "   ..., \n",
      "   [ 0.57647059  0.64705882  0.69803922]\n",
      "   [ 0.49411765  0.56078431  0.58431373]\n",
      "   [ 0.36862745  0.45882353  0.44313725]]\n",
      "\n",
      "  [[ 0.14117647  0.1372549   0.15294118]\n",
      "   [ 0.23137255  0.22745098  0.25882353]\n",
      "   [ 0.32156863  0.31764706  0.33333333]\n",
      "   ..., \n",
      "   [ 0.5254902   0.6         0.62745098]\n",
      "   [ 0.54117647  0.59607843  0.61960784]\n",
      "   [ 0.50980392  0.58039216  0.58823529]]]\n",
      "\n",
      "\n",
      " [[[ 0.0745098   0.1254902   0.05882353]\n",
      "   [ 0.08235294  0.14901961  0.08235294]\n",
      "   [ 0.10588235  0.19215686  0.1254902 ]\n",
      "   ..., \n",
      "   [ 0.29411765  0.48627451  0.51372549]\n",
      "   [ 0.29803922  0.48627451  0.50980392]\n",
      "   [ 0.27843137  0.4627451   0.48627451]]\n",
      "\n",
      "  [[ 0.09019608  0.12156863  0.05490196]\n",
      "   [ 0.08235294  0.11764706  0.04705882]\n",
      "   [ 0.09019608  0.1372549   0.05490196]\n",
      "   ..., \n",
      "   [ 0.28235294  0.4627451   0.49411765]\n",
      "   [ 0.29411765  0.46666667  0.48627451]\n",
      "   [ 0.26666667  0.43529412  0.44705882]]\n",
      "\n",
      "  [[ 0.09411765  0.14509804  0.06666667]\n",
      "   [ 0.08627451  0.1372549   0.0627451 ]\n",
      "   [ 0.09411765  0.14117647  0.07058824]\n",
      "   ..., \n",
      "   [ 0.25098039  0.42745098  0.43921569]\n",
      "   [ 0.2627451   0.42745098  0.43529412]\n",
      "   [ 0.25098039  0.41176471  0.41176471]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.24313725  0.18039216  0.09019608]\n",
      "   [ 0.23529412  0.18039216  0.10588235]\n",
      "   [ 0.21568627  0.18823529  0.10980392]\n",
      "   ..., \n",
      "   [ 0.05098039  0.02352941  0.01568627]\n",
      "   [ 0.04705882  0.05490196  0.03137255]\n",
      "   [ 0.09803922  0.15686275  0.11764706]]\n",
      "\n",
      "  [[ 0.24705882  0.20784314  0.11764706]\n",
      "   [ 0.19215686  0.17647059  0.08627451]\n",
      "   [ 0.17647059  0.18039216  0.09019608]\n",
      "   ..., \n",
      "   [ 0.11372549  0.1372549   0.12156863]\n",
      "   [ 0.11764706  0.16470588  0.14509804]\n",
      "   [ 0.10588235  0.19607843  0.16862745]]\n",
      "\n",
      "  [[ 0.27058824  0.20392157  0.11372549]\n",
      "   [ 0.19215686  0.14901961  0.07843137]\n",
      "   [ 0.21176471  0.18039216  0.10588235]\n",
      "   ..., \n",
      "   [ 0.25882353  0.34509804  0.33333333]\n",
      "   [ 0.15686275  0.26666667  0.25098039]\n",
      "   [ 0.11372549  0.24313725  0.22745098]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.1372549   0.69803922  0.92156863]\n",
      "   [ 0.15686275  0.69019608  0.9372549 ]\n",
      "   [ 0.16470588  0.69019608  0.94509804]\n",
      "   ..., \n",
      "   [ 0.38823529  0.69411765  0.85882353]\n",
      "   [ 0.30980392  0.57647059  0.77254902]\n",
      "   [ 0.34901961  0.58039216  0.74117647]]\n",
      "\n",
      "  [[ 0.22352941  0.71372549  0.91764706]\n",
      "   [ 0.17254902  0.72156863  0.98039216]\n",
      "   [ 0.19607843  0.71764706  0.94117647]\n",
      "   ..., \n",
      "   [ 0.61176471  0.71372549  0.78431373]\n",
      "   [ 0.55294118  0.69411765  0.80784314]\n",
      "   [ 0.45490196  0.58431373  0.68627451]]\n",
      "\n",
      "  [[ 0.38431373  0.77254902  0.92941176]\n",
      "   [ 0.25098039  0.74117647  0.98823529]\n",
      "   [ 0.27058824  0.75294118  0.96078431]\n",
      "   ..., \n",
      "   [ 0.7372549   0.76470588  0.80784314]\n",
      "   [ 0.46666667  0.52941176  0.57647059]\n",
      "   [ 0.23921569  0.30980392  0.35294118]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.28627451  0.30980392  0.30196078]\n",
      "   [ 0.20784314  0.24705882  0.26666667]\n",
      "   [ 0.21176471  0.26666667  0.31372549]\n",
      "   ..., \n",
      "   [ 0.06666667  0.15686275  0.25098039]\n",
      "   [ 0.08235294  0.14117647  0.2       ]\n",
      "   [ 0.12941176  0.18823529  0.19215686]]\n",
      "\n",
      "  [[ 0.23921569  0.26666667  0.29411765]\n",
      "   [ 0.21568627  0.2745098   0.3372549 ]\n",
      "   [ 0.22352941  0.30980392  0.40392157]\n",
      "   ..., \n",
      "   [ 0.09411765  0.18823529  0.28235294]\n",
      "   [ 0.06666667  0.1372549   0.20784314]\n",
      "   [ 0.02745098  0.09019608  0.1254902 ]]\n",
      "\n",
      "  [[ 0.17254902  0.21960784  0.28627451]\n",
      "   [ 0.18039216  0.25882353  0.34509804]\n",
      "   [ 0.19215686  0.30196078  0.41176471]\n",
      "   ..., \n",
      "   [ 0.10588235  0.20392157  0.30196078]\n",
      "   [ 0.08235294  0.16862745  0.25882353]\n",
      "   [ 0.04705882  0.12156863  0.19607843]]]\n",
      "\n",
      "\n",
      " [[[ 0.74117647  0.82745098  0.94117647]\n",
      "   [ 0.72941176  0.81568627  0.9254902 ]\n",
      "   [ 0.7254902   0.81176471  0.92156863]\n",
      "   ..., \n",
      "   [ 0.68627451  0.76470588  0.87843137]\n",
      "   [ 0.6745098   0.76078431  0.87058824]\n",
      "   [ 0.6627451   0.76078431  0.8627451 ]]\n",
      "\n",
      "  [[ 0.76078431  0.82352941  0.9372549 ]\n",
      "   [ 0.74901961  0.81176471  0.9254902 ]\n",
      "   [ 0.74509804  0.80784314  0.92156863]\n",
      "   ..., \n",
      "   [ 0.67843137  0.75294118  0.8627451 ]\n",
      "   [ 0.67058824  0.74901961  0.85490196]\n",
      "   [ 0.65490196  0.74509804  0.84705882]]\n",
      "\n",
      "  [[ 0.81568627  0.85882353  0.95686275]\n",
      "   [ 0.80392157  0.84705882  0.94117647]\n",
      "   [ 0.8         0.84313725  0.9372549 ]\n",
      "   ..., \n",
      "   [ 0.68627451  0.74901961  0.85098039]\n",
      "   [ 0.6745098   0.74509804  0.84705882]\n",
      "   [ 0.6627451   0.74901961  0.84313725]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.81176471  0.78039216  0.70980392]\n",
      "   [ 0.79607843  0.76470588  0.68627451]\n",
      "   [ 0.79607843  0.76862745  0.67843137]\n",
      "   ..., \n",
      "   [ 0.52941176  0.51764706  0.49803922]\n",
      "   [ 0.63529412  0.61960784  0.58823529]\n",
      "   [ 0.65882353  0.63921569  0.59215686]]\n",
      "\n",
      "  [[ 0.77647059  0.74509804  0.66666667]\n",
      "   [ 0.74117647  0.70980392  0.62352941]\n",
      "   [ 0.70588235  0.6745098   0.57647059]\n",
      "   ..., \n",
      "   [ 0.69803922  0.67058824  0.62745098]\n",
      "   [ 0.68627451  0.6627451   0.61176471]\n",
      "   [ 0.68627451  0.6627451   0.60392157]]\n",
      "\n",
      "  [[ 0.77647059  0.74117647  0.67843137]\n",
      "   [ 0.74117647  0.70980392  0.63529412]\n",
      "   [ 0.69803922  0.66666667  0.58431373]\n",
      "   ..., \n",
      "   [ 0.76470588  0.72156863  0.6627451 ]\n",
      "   [ 0.76862745  0.74117647  0.67058824]\n",
      "   [ 0.76470588  0.74509804  0.67058824]]]\n",
      "\n",
      "\n",
      " [[[ 0.89803922  0.89803922  0.9372549 ]\n",
      "   [ 0.9254902   0.92941176  0.96862745]\n",
      "   [ 0.91764706  0.9254902   0.96862745]\n",
      "   ..., \n",
      "   [ 0.85098039  0.85882353  0.91372549]\n",
      "   [ 0.86666667  0.8745098   0.91764706]\n",
      "   [ 0.87058824  0.8745098   0.91372549]]\n",
      "\n",
      "  [[ 0.87058824  0.86666667  0.89803922]\n",
      "   [ 0.9372549   0.9372549   0.97647059]\n",
      "   [ 0.91372549  0.91764706  0.96470588]\n",
      "   ..., \n",
      "   [ 0.8745098   0.8745098   0.9254902 ]\n",
      "   [ 0.89019608  0.89411765  0.93333333]\n",
      "   [ 0.82352941  0.82745098  0.8627451 ]]\n",
      "\n",
      "  [[ 0.83529412  0.80784314  0.82745098]\n",
      "   [ 0.91764706  0.90980392  0.9372549 ]\n",
      "   [ 0.90588235  0.91372549  0.95686275]\n",
      "   ..., \n",
      "   [ 0.8627451   0.8627451   0.90980392]\n",
      "   [ 0.8627451   0.85882353  0.90980392]\n",
      "   [ 0.79215686  0.79607843  0.84313725]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.58823529  0.56078431  0.52941176]\n",
      "   [ 0.54901961  0.52941176  0.49803922]\n",
      "   [ 0.51764706  0.49803922  0.47058824]\n",
      "   ..., \n",
      "   [ 0.87843137  0.87058824  0.85490196]\n",
      "   [ 0.90196078  0.89411765  0.88235294]\n",
      "   [ 0.94509804  0.94509804  0.93333333]]\n",
      "\n",
      "  [[ 0.5372549   0.51764706  0.49411765]\n",
      "   [ 0.50980392  0.49803922  0.47058824]\n",
      "   [ 0.49019608  0.4745098   0.45098039]\n",
      "   ..., \n",
      "   [ 0.70980392  0.70588235  0.69803922]\n",
      "   [ 0.79215686  0.78823529  0.77647059]\n",
      "   [ 0.83137255  0.82745098  0.81176471]]\n",
      "\n",
      "  [[ 0.47843137  0.46666667  0.44705882]\n",
      "   [ 0.4627451   0.45490196  0.43137255]\n",
      "   [ 0.47058824  0.45490196  0.43529412]\n",
      "   ..., \n",
      "   [ 0.70196078  0.69411765  0.67843137]\n",
      "   [ 0.64313725  0.64313725  0.63529412]\n",
      "   [ 0.63921569  0.63921569  0.63137255]]]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]]\n",
      "[[[[ 0.61960784  0.43921569  0.19215686]\n",
      "   [ 0.62352941  0.43529412  0.18431373]\n",
      "   [ 0.64705882  0.45490196  0.2       ]\n",
      "   ..., \n",
      "   [ 0.5372549   0.37254902  0.14117647]\n",
      "   [ 0.49411765  0.35686275  0.14117647]\n",
      "   [ 0.45490196  0.33333333  0.12941176]]\n",
      "\n",
      "  [[ 0.59607843  0.43921569  0.2       ]\n",
      "   [ 0.59215686  0.43137255  0.15686275]\n",
      "   [ 0.62352941  0.44705882  0.17647059]\n",
      "   ..., \n",
      "   [ 0.53333333  0.37254902  0.12156863]\n",
      "   [ 0.49019608  0.35686275  0.1254902 ]\n",
      "   [ 0.46666667  0.34509804  0.13333333]]\n",
      "\n",
      "  [[ 0.59215686  0.43137255  0.18431373]\n",
      "   [ 0.59215686  0.42745098  0.12941176]\n",
      "   [ 0.61960784  0.43529412  0.14117647]\n",
      "   ..., \n",
      "   [ 0.54509804  0.38431373  0.13333333]\n",
      "   [ 0.50980392  0.37254902  0.13333333]\n",
      "   [ 0.47058824  0.34901961  0.12941176]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.26666667  0.48627451  0.69411765]\n",
      "   [ 0.16470588  0.39215686  0.58039216]\n",
      "   [ 0.12156863  0.34509804  0.5372549 ]\n",
      "   ..., \n",
      "   [ 0.14901961  0.38039216  0.57254902]\n",
      "   [ 0.05098039  0.25098039  0.42352941]\n",
      "   [ 0.15686275  0.33333333  0.49803922]]\n",
      "\n",
      "  [[ 0.23921569  0.45490196  0.65882353]\n",
      "   [ 0.19215686  0.4         0.58039216]\n",
      "   [ 0.1372549   0.33333333  0.51764706]\n",
      "   ..., \n",
      "   [ 0.10196078  0.32156863  0.50980392]\n",
      "   [ 0.11372549  0.32156863  0.49411765]\n",
      "   [ 0.07843137  0.25098039  0.41960784]]\n",
      "\n",
      "  [[ 0.21176471  0.41960784  0.62745098]\n",
      "   [ 0.21960784  0.41176471  0.58431373]\n",
      "   [ 0.17647059  0.34901961  0.51764706]\n",
      "   ..., \n",
      "   [ 0.09411765  0.30196078  0.48627451]\n",
      "   [ 0.13333333  0.32941176  0.50588235]\n",
      "   [ 0.08235294  0.2627451   0.43137255]]]\n",
      "\n",
      "\n",
      " [[[ 0.92156863  0.92156863  0.92156863]\n",
      "   [ 0.90588235  0.90588235  0.90588235]\n",
      "   [ 0.90980392  0.90980392  0.90980392]\n",
      "   ..., \n",
      "   [ 0.91372549  0.91372549  0.91372549]\n",
      "   [ 0.91372549  0.91372549  0.91372549]\n",
      "   [ 0.90980392  0.90980392  0.90980392]]\n",
      "\n",
      "  [[ 0.93333333  0.93333333  0.93333333]\n",
      "   [ 0.92156863  0.92156863  0.92156863]\n",
      "   [ 0.92156863  0.92156863  0.92156863]\n",
      "   ..., \n",
      "   [ 0.9254902   0.9254902   0.9254902 ]\n",
      "   [ 0.9254902   0.9254902   0.9254902 ]\n",
      "   [ 0.92156863  0.92156863  0.92156863]]\n",
      "\n",
      "  [[ 0.92941176  0.92941176  0.92941176]\n",
      "   [ 0.91764706  0.91764706  0.91764706]\n",
      "   [ 0.91764706  0.91764706  0.91764706]\n",
      "   ..., \n",
      "   [ 0.92156863  0.92156863  0.92156863]\n",
      "   [ 0.92156863  0.92156863  0.92156863]\n",
      "   [ 0.91764706  0.91764706  0.91764706]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.34117647  0.38823529  0.34901961]\n",
      "   [ 0.16862745  0.2         0.14509804]\n",
      "   [ 0.0745098   0.09019608  0.04313725]\n",
      "   ..., \n",
      "   [ 0.6627451   0.72156863  0.70196078]\n",
      "   [ 0.71372549  0.77254902  0.75686275]\n",
      "   [ 0.7372549   0.79215686  0.78823529]]\n",
      "\n",
      "  [[ 0.32156863  0.37647059  0.32156863]\n",
      "   [ 0.18039216  0.22352941  0.14117647]\n",
      "   [ 0.14117647  0.17254902  0.08627451]\n",
      "   ..., \n",
      "   [ 0.68235294  0.74117647  0.71764706]\n",
      "   [ 0.7254902   0.78431373  0.76862745]\n",
      "   [ 0.73333333  0.79215686  0.78431373]]\n",
      "\n",
      "  [[ 0.33333333  0.39607843  0.3254902 ]\n",
      "   [ 0.24313725  0.29411765  0.18823529]\n",
      "   [ 0.22745098  0.2627451   0.14901961]\n",
      "   ..., \n",
      "   [ 0.65882353  0.71764706  0.69803922]\n",
      "   [ 0.70588235  0.76470588  0.74901961]\n",
      "   [ 0.72941176  0.78431373  0.78039216]]]\n",
      "\n",
      "\n",
      " [[[ 0.61960784  0.74509804  0.87058824]\n",
      "   [ 0.61960784  0.73333333  0.85490196]\n",
      "   [ 0.54509804  0.65098039  0.76078431]\n",
      "   ..., \n",
      "   [ 0.89411765  0.90588235  0.91764706]\n",
      "   [ 0.92941176  0.9372549   0.95294118]\n",
      "   [ 0.93333333  0.94509804  0.96470588]]\n",
      "\n",
      "  [[ 0.66666667  0.78431373  0.89803922]\n",
      "   [ 0.6745098   0.78039216  0.88627451]\n",
      "   [ 0.59215686  0.69019608  0.78823529]\n",
      "   ..., \n",
      "   [ 0.90980392  0.90980392  0.9254902 ]\n",
      "   [ 0.96470588  0.96470588  0.98039216]\n",
      "   [ 0.96470588  0.96862745  0.98431373]]\n",
      "\n",
      "  [[ 0.68235294  0.78823529  0.88235294]\n",
      "   [ 0.69019608  0.78431373  0.87058824]\n",
      "   [ 0.61568627  0.70196078  0.78039216]\n",
      "   ..., \n",
      "   [ 0.90196078  0.89803922  0.90980392]\n",
      "   [ 0.98039216  0.97647059  0.98431373]\n",
      "   [ 0.96078431  0.95686275  0.96862745]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.12156863  0.15686275  0.17647059]\n",
      "   [ 0.11764706  0.15294118  0.17254902]\n",
      "   [ 0.10196078  0.1372549   0.15686275]\n",
      "   ..., \n",
      "   [ 0.14509804  0.15686275  0.18039216]\n",
      "   [ 0.03529412  0.05098039  0.05490196]\n",
      "   [ 0.01568627  0.02745098  0.01960784]]\n",
      "\n",
      "  [[ 0.09019608  0.13333333  0.15294118]\n",
      "   [ 0.10588235  0.14901961  0.16862745]\n",
      "   [ 0.09803922  0.14117647  0.16078431]\n",
      "   ..., \n",
      "   [ 0.0745098   0.07843137  0.09411765]\n",
      "   [ 0.01568627  0.02352941  0.01176471]\n",
      "   [ 0.01960784  0.02745098  0.01176471]]\n",
      "\n",
      "  [[ 0.10980392  0.16078431  0.18431373]\n",
      "   [ 0.11764706  0.16862745  0.19607843]\n",
      "   [ 0.1254902   0.17647059  0.20392157]\n",
      "   ..., \n",
      "   [ 0.01960784  0.02352941  0.03137255]\n",
      "   [ 0.01568627  0.01960784  0.01176471]\n",
      "   [ 0.02745098  0.03137255  0.02745098]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.07843137  0.05882353  0.04705882]\n",
      "   [ 0.0745098   0.05490196  0.04313725]\n",
      "   [ 0.05882353  0.05490196  0.04313725]\n",
      "   ..., \n",
      "   [ 0.03921569  0.03529412  0.02745098]\n",
      "   [ 0.04705882  0.04313725  0.03529412]\n",
      "   [ 0.05098039  0.04705882  0.03921569]]\n",
      "\n",
      "  [[ 0.08235294  0.0627451   0.05098039]\n",
      "   [ 0.07843137  0.0627451   0.05098039]\n",
      "   [ 0.07058824  0.06666667  0.04705882]\n",
      "   ..., \n",
      "   [ 0.03921569  0.03529412  0.02745098]\n",
      "   [ 0.03921569  0.03529412  0.02745098]\n",
      "   [ 0.04705882  0.04313725  0.03529412]]\n",
      "\n",
      "  [[ 0.08235294  0.0627451   0.05098039]\n",
      "   [ 0.08235294  0.06666667  0.04705882]\n",
      "   [ 0.07843137  0.07058824  0.04313725]\n",
      "   ..., \n",
      "   [ 0.04705882  0.04313725  0.03529412]\n",
      "   [ 0.04705882  0.04313725  0.03529412]\n",
      "   [ 0.05098039  0.04705882  0.03921569]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.12941176  0.09803922  0.05098039]\n",
      "   [ 0.13333333  0.10196078  0.05882353]\n",
      "   [ 0.13333333  0.10196078  0.05882353]\n",
      "   ..., \n",
      "   [ 0.10980392  0.09803922  0.20392157]\n",
      "   [ 0.11372549  0.09803922  0.22745098]\n",
      "   [ 0.09019608  0.07843137  0.16470588]]\n",
      "\n",
      "  [[ 0.12941176  0.09803922  0.05490196]\n",
      "   [ 0.13333333  0.10196078  0.05882353]\n",
      "   [ 0.13333333  0.10196078  0.05882353]\n",
      "   ..., \n",
      "   [ 0.10588235  0.09411765  0.20392157]\n",
      "   [ 0.10588235  0.09411765  0.21960784]\n",
      "   [ 0.09803922  0.08627451  0.18431373]]\n",
      "\n",
      "  [[ 0.12156863  0.09019608  0.04705882]\n",
      "   [ 0.1254902   0.09411765  0.05098039]\n",
      "   [ 0.12941176  0.09803922  0.05490196]\n",
      "   ..., \n",
      "   [ 0.09411765  0.09019608  0.19607843]\n",
      "   [ 0.10196078  0.09019608  0.20784314]\n",
      "   [ 0.09803922  0.07843137  0.18431373]]]\n",
      "\n",
      "\n",
      " [[[ 0.09803922  0.15686275  0.04705882]\n",
      "   [ 0.05882353  0.14117647  0.01176471]\n",
      "   [ 0.09019608  0.16078431  0.07058824]\n",
      "   ..., \n",
      "   [ 0.23921569  0.32156863  0.30588235]\n",
      "   [ 0.36078431  0.44313725  0.43921569]\n",
      "   [ 0.29411765  0.34901961  0.36078431]]\n",
      "\n",
      "  [[ 0.04705882  0.09803922  0.02352941]\n",
      "   [ 0.07843137  0.14509804  0.02745098]\n",
      "   [ 0.09411765  0.14117647  0.05882353]\n",
      "   ..., \n",
      "   [ 0.45098039  0.5254902   0.54117647]\n",
      "   [ 0.58431373  0.65882353  0.69411765]\n",
      "   [ 0.40784314  0.45882353  0.51372549]]\n",
      "\n",
      "  [[ 0.04705882  0.09803922  0.04313725]\n",
      "   [ 0.05882353  0.11372549  0.02352941]\n",
      "   [ 0.13333333  0.15686275  0.09411765]\n",
      "   ..., \n",
      "   [ 0.60392157  0.6745098   0.71372549]\n",
      "   [ 0.61568627  0.68627451  0.75294118]\n",
      "   [ 0.45490196  0.50588235  0.59215686]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.39215686  0.50588235  0.31764706]\n",
      "   [ 0.40392157  0.51764706  0.32941176]\n",
      "   [ 0.40784314  0.5254902   0.3372549 ]\n",
      "   ..., \n",
      "   [ 0.38039216  0.50196078  0.32941176]\n",
      "   [ 0.38431373  0.49411765  0.32941176]\n",
      "   [ 0.35686275  0.4745098   0.30980392]]\n",
      "\n",
      "  [[ 0.40392157  0.51764706  0.3254902 ]\n",
      "   [ 0.40784314  0.51372549  0.3254902 ]\n",
      "   [ 0.41960784  0.52941176  0.34117647]\n",
      "   ..., \n",
      "   [ 0.39607843  0.51764706  0.34117647]\n",
      "   [ 0.38823529  0.49803922  0.32941176]\n",
      "   [ 0.36078431  0.4745098   0.30980392]]\n",
      "\n",
      "  [[ 0.37254902  0.49411765  0.30588235]\n",
      "   [ 0.37254902  0.48235294  0.29803922]\n",
      "   [ 0.39607843  0.50196078  0.31764706]\n",
      "   ..., \n",
      "   [ 0.36470588  0.48627451  0.31372549]\n",
      "   [ 0.37254902  0.48235294  0.31764706]\n",
      "   [ 0.36078431  0.47058824  0.31372549]]]\n",
      "\n",
      "\n",
      " [[[ 0.28627451  0.30588235  0.29411765]\n",
      "   [ 0.38431373  0.40392157  0.44313725]\n",
      "   [ 0.38823529  0.41568627  0.44705882]\n",
      "   ..., \n",
      "   [ 0.52941176  0.58823529  0.59607843]\n",
      "   [ 0.52941176  0.58431373  0.60392157]\n",
      "   [ 0.79607843  0.84313725  0.8745098 ]]\n",
      "\n",
      "  [[ 0.27058824  0.28627451  0.2745098 ]\n",
      "   [ 0.32941176  0.34901961  0.38039216]\n",
      "   [ 0.26666667  0.29411765  0.31764706]\n",
      "   ..., \n",
      "   [ 0.33333333  0.37254902  0.34901961]\n",
      "   [ 0.27843137  0.32156863  0.31372549]\n",
      "   [ 0.47058824  0.52156863  0.52941176]]\n",
      "\n",
      "  [[ 0.27058824  0.28627451  0.2745098 ]\n",
      "   [ 0.35294118  0.37254902  0.39215686]\n",
      "   [ 0.24313725  0.27843137  0.29019608]\n",
      "   ..., \n",
      "   [ 0.29019608  0.31764706  0.2745098 ]\n",
      "   [ 0.20784314  0.24313725  0.21176471]\n",
      "   [ 0.24313725  0.29019608  0.27058824]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.48235294  0.50196078  0.37647059]\n",
      "   [ 0.51764706  0.51764706  0.4       ]\n",
      "   [ 0.50588235  0.50196078  0.39215686]\n",
      "   ..., \n",
      "   [ 0.42352941  0.41960784  0.34509804]\n",
      "   [ 0.24313725  0.23529412  0.21568627]\n",
      "   [ 0.10588235  0.10588235  0.10980392]]\n",
      "\n",
      "  [[ 0.45098039  0.4745098   0.35686275]\n",
      "   [ 0.48235294  0.48627451  0.37254902]\n",
      "   [ 0.50588235  0.49411765  0.38823529]\n",
      "   ..., \n",
      "   [ 0.45098039  0.45490196  0.36862745]\n",
      "   [ 0.25882353  0.25490196  0.23137255]\n",
      "   [ 0.10588235  0.10588235  0.10588235]]\n",
      "\n",
      "  [[ 0.45490196  0.47058824  0.35294118]\n",
      "   [ 0.4745098   0.47843137  0.36862745]\n",
      "   [ 0.50588235  0.50196078  0.39607843]\n",
      "   ..., \n",
      "   [ 0.45490196  0.45098039  0.36862745]\n",
      "   [ 0.26666667  0.25490196  0.22745098]\n",
      "   [ 0.10588235  0.10196078  0.10196078]]]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape = [None, *image_shape], name = \"x\")\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes], name = \"y\")\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name = \"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    input_channel_depth = int(x_tensor.get_shape()[3])\n",
    "    \n",
    "    weight = tf.Variable(tf.truncated_normal(\n",
    "        (conv_ksize[0], conv_ksize[1], input_channel_depth, conv_num_outputs),\n",
    "        mean=0.0,stddev=0.1,dtype=tf.float32,seed=None,name=None))\n",
    "    \n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    x = tf.nn.conv2d(x_tensor, weight, strides=[1, *conv_strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, bias)\n",
    "    x = tf.nn.relu(x)\n",
    "    x = tf.nn.max_pool(\n",
    "        x,\n",
    "        ksize=[1, *pool_ksize, 1],\n",
    "        strides=[1, *pool_strides, 1],\n",
    "        padding='SAME')\n",
    "    return x\n",
    "\n",
    "    \n",
    "   \n",
    "    #weights = tf.Variable(tf.truncated_normal([*conv_ksize, input_channel_depth, conv_num_outputs], dtype=tf.float32))\n",
    "   \n",
    "    #biases = tf.Variable(tf.constant(0, shape=[conv_num_outputs], dtype=tf.float32))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Flatten/Reshape:0\", shape=(?, 1800), dtype=float32)\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "   \n",
    "    print(tf.contrib.layers.flatten(x_tensor))\n",
    "    return tf.contrib.layers.flatten(x_tensor)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs, activation_fn=tf.nn.relu)\n",
    "   \n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #print(fully_conn(x_tensor, num_outputs))\n",
    "    #print(tf.contrib.layers.fully_connected(x_tensor, num_outputs))\n",
    "    \n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Flatten/Reshape:0\", shape=(?, 1536), dtype=float32)\n",
      "Tensor(\"Flatten_2/Reshape:0\", shape=(?, 1536), dtype=float32)\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    conv_num_outputs = 64\n",
    "    conv_ksize = [5, 5]\n",
    "    conv_strides = [1, 1]\n",
    "    pool_ksize = [2, 2]\n",
    "    pool_strides = [1, 1]\n",
    "    \n",
    "    #conv_layer = conv2d_maxpool(x, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    #flatten_layer = flatten(conv_layer)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    #fully_layer = fully_conn(flatten_layer,256)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    # dropout_layer = tf.nn.dropout(fully_layer, keep_prob)\n",
    "    #output_layer = output(dropout_layer, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    \n",
    "################################################################################################################\n",
    "   \n",
    "    conv_ksize = (3,3)\n",
    "    conv_strides = (1,1)\n",
    "    pool_ksize = (2,2)\n",
    "    pool_strides = (2,2)\n",
    "    \n",
    "    keep_prob = 0.5\n",
    "\n",
    "     # Layer 1\n",
    "    conv1 = conv2d_maxpool(x, 8 * 3, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    # Layer 2\n",
    "    conv2 = conv2d_maxpool(conv1, 16 * 3, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    # Layer 3\n",
    "    conv3 = conv2d_maxpool(conv2, 32 * 3, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    # Flatten layer\n",
    "    flatten1 = flatten(conv3)\n",
    "\n",
    "    # Fully connected layer\n",
    "    fc1 = fully_conn(flatten1, 512)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "    fc2 = fully_conn(fc1, 512)\n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "    \n",
    "    out = output(fc2, 10)\n",
    "    return out\n",
    "\n",
    "    # TODO: return output\n",
    "    # return neural_net\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #x = neural_net_image_input((feature_batch.shape[1], feature_batch.shape[2], feature_batch.shape[3]))\n",
    "    #y = neural_net_label_input(label_batch.shape[1])\n",
    "    #keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x: valid_features,y: valid_labels,keep_prob: 1.})\n",
    "\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 20\n",
    "batch_size = 384\n",
    "keep_probability = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2723 Validation Accuracy: 0.142800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.1807 Validation Accuracy: 0.224800\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.0793 Validation Accuracy: 0.259200\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.9551 Validation Accuracy: 0.361200\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.7069 Validation Accuracy: 0.413000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.6010 Validation Accuracy: 0.418800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.4504 Validation Accuracy: 0.434200\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.2973 Validation Accuracy: 0.475800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.2616 Validation Accuracy: 0.475400\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.0792 Validation Accuracy: 0.497200\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.0405 Validation Accuracy: 0.505800\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.0630 Validation Accuracy: 0.500400\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.0155 Validation Accuracy: 0.516800\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.8004 Validation Accuracy: 0.539000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.6832 Validation Accuracy: 0.555600\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.6611 Validation Accuracy: 0.560400\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.6482 Validation Accuracy: 0.558200\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.5959 Validation Accuracy: 0.564200\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.5462 Validation Accuracy: 0.549200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.4798 Validation Accuracy: 0.565000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2191 Validation Accuracy: 0.154200\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.0077 Validation Accuracy: 0.280000\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     1.7061 Validation Accuracy: 0.352000\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.4924 Validation Accuracy: 0.404400\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     1.4449 Validation Accuracy: 0.436800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     1.5675 Validation Accuracy: 0.461600\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     1.4780 Validation Accuracy: 0.482600\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.1156 Validation Accuracy: 0.488800\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.2105 Validation Accuracy: 0.506200\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.1573 Validation Accuracy: 0.518000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     1.3335 Validation Accuracy: 0.525200\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.2666 Validation Accuracy: 0.531800\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     0.9758 Validation Accuracy: 0.552600\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.0722 Validation Accuracy: 0.554400\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     0.9735 Validation Accuracy: 0.564000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.1382 Validation Accuracy: 0.556800\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     0.9896 Validation Accuracy: 0.588800\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     0.8104 Validation Accuracy: 0.588800\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     0.8869 Validation Accuracy: 0.588800\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     0.8077 Validation Accuracy: 0.608600\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.1106 Validation Accuracy: 0.572600\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     0.9283 Validation Accuracy: 0.606200\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     0.6825 Validation Accuracy: 0.609400\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     0.7278 Validation Accuracy: 0.622600\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     0.7584 Validation Accuracy: 0.621200\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     0.9351 Validation Accuracy: 0.619600\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     0.8182 Validation Accuracy: 0.621800\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     0.6062 Validation Accuracy: 0.629000\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     0.7182 Validation Accuracy: 0.637600\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     0.6528 Validation Accuracy: 0.638800\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     0.8336 Validation Accuracy: 0.646800\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     0.6355 Validation Accuracy: 0.641200\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     0.5421 Validation Accuracy: 0.634400\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     0.6688 Validation Accuracy: 0.654800\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     0.5949 Validation Accuracy: 0.652000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     0.7976 Validation Accuracy: 0.648000\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     0.5457 Validation Accuracy: 0.653400\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     0.4947 Validation Accuracy: 0.657200\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     0.5779 Validation Accuracy: 0.660800\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     0.5208 Validation Accuracy: 0.656800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     0.6893 Validation Accuracy: 0.660400\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     0.5311 Validation Accuracy: 0.660000\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     0.4698 Validation Accuracy: 0.651200\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     0.4710 Validation Accuracy: 0.667800\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     0.3845 Validation Accuracy: 0.661800\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     0.6573 Validation Accuracy: 0.666600\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     0.4746 Validation Accuracy: 0.660800\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     0.4427 Validation Accuracy: 0.653400\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     0.4788 Validation Accuracy: 0.666200\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     0.3525 Validation Accuracy: 0.673800\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     0.5805 Validation Accuracy: 0.678200\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     0.4786 Validation Accuracy: 0.654200\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     0.3421 Validation Accuracy: 0.675400\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     0.4544 Validation Accuracy: 0.675000\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     0.3349 Validation Accuracy: 0.658800\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     0.5049 Validation Accuracy: 0.675600\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     0.4112 Validation Accuracy: 0.658600\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     0.3527 Validation Accuracy: 0.676200\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     0.3936 Validation Accuracy: 0.675400\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     0.3397 Validation Accuracy: 0.665800\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     0.5690 Validation Accuracy: 0.644600\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     0.3556 Validation Accuracy: 0.658000\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     0.3410 Validation Accuracy: 0.674400\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     0.3829 Validation Accuracy: 0.679600\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     0.3170 Validation Accuracy: 0.683000\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     0.5296 Validation Accuracy: 0.651600\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     0.4028 Validation Accuracy: 0.663600\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     0.2624 Validation Accuracy: 0.679200\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     0.3434 Validation Accuracy: 0.681600\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     0.2901 Validation Accuracy: 0.673600\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     0.4050 Validation Accuracy: 0.673800\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     0.3270 Validation Accuracy: 0.675600\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     0.2881 Validation Accuracy: 0.684200\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     0.2783 Validation Accuracy: 0.683000\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     0.2744 Validation Accuracy: 0.673200\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     0.4624 Validation Accuracy: 0.672200\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     0.2754 Validation Accuracy: 0.680000\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     0.2720 Validation Accuracy: 0.666000\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     0.2919 Validation Accuracy: 0.668600\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     0.2185 Validation Accuracy: 0.675000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     0.3594 Validation Accuracy: 0.685600\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     0.2646 Validation Accuracy: 0.681600\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     0.2311 Validation Accuracy: 0.685000\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     0.2697 Validation Accuracy: 0.678000\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     0.1935 Validation Accuracy: 0.674600\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     0.3568 Validation Accuracy: 0.673200\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     0.2087 Validation Accuracy: 0.675400\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     0.1985 Validation Accuracy: 0.680200\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     0.2929 Validation Accuracy: 0.672600\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     0.2482 Validation Accuracy: 0.664600\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     0.2986 Validation Accuracy: 0.684400\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     0.2337 Validation Accuracy: 0.666400\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     0.2478 Validation Accuracy: 0.673200\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     0.2569 Validation Accuracy: 0.673400\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     0.2024 Validation Accuracy: 0.664000\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     0.2918 Validation Accuracy: 0.671200\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     0.2651 Validation Accuracy: 0.677200\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     0.1730 Validation Accuracy: 0.683000\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     0.2436 Validation Accuracy: 0.668800\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     0.1831 Validation Accuracy: 0.679600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6822916865348816\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZFIwbGIiIiISKTgWEREREQk+l8hFHgkfGux9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f88f005ba8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
